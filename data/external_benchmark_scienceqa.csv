id,Name,Score,Shots,Model version,Source,Source link,Notes
recLopbrj5TBktvMC,Mutimodal-T-SciQ_Large 🥇,96.18%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recOGCVuZeah5X381,MC-CoT_F-Large 🥈,94.88%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recZR5TdHfWbXwIU9,Honeybee (Vicuna-13B) 🥉,94.39%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recnX4OE6ycLUTzeW,Enigma-COT_Large,94.11%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec6v6LwHJJt6eLil,MC-CoT_Large,93.37%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recinmVkDPlFOptRb,DPMM-CoT_Large,93.35%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recRJHhq4bBccxhcA,LLaVA (GPT-4 judge),92.53%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec5L3QjKocihpbmV,CoMD (Vicuna-7B),91.94%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recg6gUpd9FOOmaHL,Mutimodal-T-SciQ_Base,91.75%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recbQs5adB0CGRt2K,Multimodal-CoT_Large,91.68%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recqkD9cDT4eDb46V,PILL (LLaMA-7B),91.23%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
reccFtq7H6YfKhQlj,LLaVA (ViT-L/16-224),91.20%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recv0LDUxWdweDfPf,DPMM-CoT_Base,90.97%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recl9Nqm1sqioM4Os,LLaVA,90.92%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec7ZhGrM0cfAuKy3,LaVIN-13B,90.83%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recauyPQ0CSqJyX8Y,MC-CoT_F-Base,90.73%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recChhNugt6Y2PL2M,MC-CoT_Base,90.64%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recovI1aUX9LeIS3v,LLaMA-SciTune,90.03%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recTemmuKYUVH2SCP,LaVIN-7B,89.41%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recUyCU3pNgYTNCXG,Flan-T5-XL (LoRA),89.29%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recDWs4xXiWFxyA7v,Chat-UniVi,88.78%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recBmajDL8mFbh0Jl,DDCoT (T5),87.34%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recyM4e94d5nC0zjp,LG-VQA (CLIP),87.22%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recrG5DAKJ0yrh1Vq,Chameleon (GPT-4),86.54%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec5nzXN7HHab8Yhg,LG-VQA (BLIP-2),86.32%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recw29lIbum3aYhnS,LLaMA-SciTune,86.11%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recNWBcZUPVddtJgI,Enigma-COT_Base,85.59%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recndFmBnvWQ496e1,LLaMA-Adapter,85.19%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recpqiTSrPVksuYtT,Multimodal-CoT_Base,84.91%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rectmed9q9mkF4zJQ,IMMO SL+RL,84.80%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec9XZkZQdx2hYTNu,CoT GPT-4,83.99%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recH8OdAVaEj0t628,HoT-T5_Large,83.38%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recm7zANvRODJlEMK,HoT-T5_Base,81.42%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recrgRfu8nU0ae7Iv,DDCoT (ChatGPT),80.15%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recBbLQnbkpFKFwof,Chameleon (ChatGPT),79.93%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rechbkl66cHSi3G5A,CoT GPT-3 + Doc,79.91%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recB36zZ5oHCrh1YZ,UnifiedQA-T-SciQ_Base,79.41%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recuz9H65SL9FtlRa,CoT ChatGPT,78.31%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recG12fs7sG8h1K8m,DDCoT (GPT-3),78.09%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec9HmYZ0zCjB9svp,LaVIN-13B,77.54%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec4cGRTOBmTYjfnT,CoT GPT-3 (ALE),75.17%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recJyYaW6IPuernBQ,LaVIN-7B,75.11%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec5b01M85oWpg6W3,CoT GPT-3 (AE),74.61%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
reckMv8O8r13skE3P,BLIP-2,74.17%,,blip2-opt-2.7b,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec4VRcGm4zK2v5Dj,CoT UnifiedQA,74.11%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recL8mZMJvVlv3aVD,GPT-3 (0-shot),74.04%,,text-davinci-001,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec6clTwByWcSogei,GPT-3 (2-shot),73.97%,,text-davinci-001,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recWR49ZkYI9byoxt,InstructBLIP,73.33%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recf6mG8bQiDmcW4D,UnifiedQA,70.12%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec697K7JWz7FNWcm,ChatGPT,69.41%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recIUfgLsK37otmEb,MetaCLIP,68.77%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recZOnTYR5SKK2ygZ,OpenCLIP,67.53%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recaAazpkdFvRdMzC,Flan-T5-XXL,67.43%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
receYuEjYS6tpQDjq,SAM,67.08%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recBI7fIOITHnB3WS,DINOv2,64.60%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec53ya3IFTPg0eMz,VisualBERT,61.87%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recKSkayv2Fh7QAPP,Patch-TRM,61.42%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec5NmvwvmIx8NzJV,ViLT,61.14%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recV5wkOXWcZGeOX1,DFAF,60.72%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recvLcqXsTT6WjkAa,Chat-UniVi,59.96%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec9x7DimSNygwLgL,BAN,59.37%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recqeXl27TK126leH,Top-Down,59.02%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recpfo5ymhK5bO0j6,MiniGPT4,58.70%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec4f1Hv3tHKZwpM3,LLaMA2-13B,55.78%,,Llama-2-13b,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recUdhYeDHAwi3X6c,DDCoT (MiniGPT-4),55.67%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recp5X8sOPJosA46a,QVix,55.00%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recrEOVkdcgPOMUFD,MCAN,54.54%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recIEQFKjFceIOjNl,LLaMA-Adapter-V2,54.44%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recJqZTHlc4gW8JPP,VLIS,50.20%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rectJWMSHVswFd10a,LLaVA-13B,47.74%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recOHgMYoICgxmquf,VPGTrans,47.00%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recjW6DBpR9R5D5yJ,MiniGPT-4,44.71%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
reckv5UwxSlzuqqxU,LLaMA1-13B,43.33%,,LLaMA-13B,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recst4vtvBflTNIt5,LLaMA2-7B,43.08%,,Llama-2-7b,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recTn4QaVzh4slrCE,LLaVA-7B,41.10%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recGdUJxthS9RJmp0,OpenFlamingo,39.27%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec7yI2ICo58RPYPB,Lynx,38.28%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recgsYCmwiGedIncx,mPLUG-Owl,37.93%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recH0YEkxqbbhujEB,MultiGPT,36.29%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recOWTFKlhYYIQazU,LLaMA1-7B,36.19%,,LLaMA-7B,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
recGqSoocZkzpDpzg,Fromage,34.51%,,,ScienceQA leaderboard,https://scienceqa.github.io/leaderboard.html,
rec0npY7rc711egAe,Phi-3.5-Vision 4.2b    ,91.30%,,Phi-3.5-vision-instruct,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recFXgM2b1MxXJ0GW,MM1-3B-Chat 3.6b       ,69.40%,,MM1-3B-Chat,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recOtCxq6HmvnIucp,MM1-7B-Chat 7.6b       ,72.60%,,MM1-7B-Chat,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recUUhaZd0PNJBznr,LLaVA-1.6 Vicuna-7b    ,70.60%,,llava-v1.6-vicuna-7b,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
rec4WiZfQpgoA4nv2,LLaVA-Next Llama3-8b   ,73.70%,,llama3-llava-next-8b,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recxtuT8rYMP8wp87,Qwen-VL-Chat 9.6b      ,67.20%,,Qwen-VL-Chat,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
reccDSd3p2ZJ5XIgq,Claude 3 haiku         ,72.00%,,claude-3-haiku-20240307,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recSwZQTEaQUGeWS6,Gemini 1.0 Pro V       ,79.70%,,gemini-1.0-pro-vision,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
rec0F1EWXSFmyhqsG,GPT-4O 2024-05-13      ,88.50%,,gpt-4o-2024-05-13,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
rec6Px3f23pIK410C,Falcon2-11B VLM,74.90%,,falcon-11B-vlm,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recLQWTFD7gZEc4Pd,LLaVA1.6-Vicuna-7B,70.10%,,llava-v1.6-vicuna-7b,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recMzgZXL1CtfmhvN,LLaVA1.6-Vicuna-13B,73.60%,,llava-v1.6-vicuna-13b,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recHkwW8HkY5EvWuw,LLaVA1.6-Mistral-7B,72.80%,,llava-v1.6-mistral-7b,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recrqpiBC2wq4jXQS,InstructBLIP-7B (Vicuna),60.50%,,instructblip-vicuna-7b,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recfjqnJ0LLGYRCzA,InstructBLIP-13B (Vicuna),63.10%,,instructblip-vicuna-13b,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recvidEkZ2TJ7PLNe,Qwen-VL-Chat,68.20%,,Qwen-VL-Chat,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recwNwS3zW5ZnI8my,InternVL-7B,66.20%,,InternVL-Chat-ViT-6B-Vicuna-7B,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recLjjaIU4o6tkfTL,InternVL-13B,70.10%,,InternVL-Chat-ViT-6B-Vicuna-13B,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
rec0ww4tyLYeEjUZ3,LLaVA-1.5-7B,66.80%,,llava-v1.5-7b,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
rec7TPNXwoHgJh2mt,LLaVA-NeXT-7B,70.10%,,,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recwjcp8zqAA4oe7V,LLaVA-NeXT-13B,73.60%,,,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recoLkEWa8RivHrne,VisionLLM v2-Chat,94.40%,,,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,
recJASlfaEdfdwMre,VisionLLM v2,94.20%,,,VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks,https://proceedings.neurips.cc/paper_files/paper/2024/file/81a60d18e010b27b36cd465c6604b915-Paper-Conference.pdf,