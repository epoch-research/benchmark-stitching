id,Name,Challenge score,Easy score,Model version,Shots,Source,Source link,Notes
recBDxFxuSKRTNMCm,Yi 6b,50.3%,,Yi-6B,25-shot,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recqf9Jh0xFM1IXnC,Yi 9b,55.6%,,Yi-9B,25-shot,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recbeIMXP2c5ukqiJ,PaLM,60.1%,,PaLM 540B,2-shot,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recekhdpsUQa4s2Hm,PaLM 2-S,59.6%,,PaLM 2-S,2-shot,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recuxZiJTrnM847mA,PaLM 2-M,64.9%,,PaLM 2-M,2-shot,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recWEx4BOQTar2SBJ,PaLM 2-L,69.2%,,PaLM 2-L,2-shot,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recyedY0eMSNaxyzQ,Falcon 180B,67.8%,,falcon-180B,2-shot,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recon4Hh3kTsbzIUH,GPT-3,51.4%,68.8%,text-davinci-001,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recPA0ga3kjdYrNvX,PaLM,53.0%,76.6%,PaLM 540B,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recMgIDIjScfAKlAK,LLaMA-2 7B,45.9%,75.2%,Llama-2-7b,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
reccokU2BaZ83v8sC,LLaMA-2 13B,49.4%,77.3%,Llama-2-13b,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recCQAtSkG6833htq,LLaMA-2 34B,54.5%,79.4%,Llama-2-34b,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recWxdEsOORwjod7s,LLaMA-2 70B,57.4%,80.2%,Llama-2-70b-hf ,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recTQceLSvuKmSReV,Falcon 7B,44.5%,73.6%,falcon-7b,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recTUiYeh3GLxrG9E,Falcon 40B,56.7%,81.2%,falcon-40b,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
rec7VFstStJ24o6LM,Falcon 180B,63.7%,84.7%,falcon-180B,,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recpTlvsgRj6K0TU9,MPT 7B,42.6%,,mpt-7b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recx3YFpGEIXLrY5E,Falcon 7B,42.4%,,falcon-7b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recXAARbHOX9VJjNY,ChatGLM2 6B,61.0%,,chatglm2-6b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
rec1k3Qvpm4E2qFw2,InternLM 7B,69.5%,,internlm-7b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recAO3NVZ8A3ac9a3,InternLM 20B,81.7%,,internlm-20b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
rec9IABwNbrfCP4NR,Baichuan2 7B,32.5%,,Baichuan-2-7B-Base,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recpRCQEqtiQDGRiB,Baichuan2 13B,38.0%,,Baichuan-2-13B-Base,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recNvbTr84ONFah46,LLaMA 7B,47.6%,,LLaMA-7B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recOtuOh1YwJucfwl,LLaMA 13B,52.7%,,LLaMA-13B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recoTYayUgTAlaU57,LLaMA 33B,67.5%,,LLaMA-33B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
reclOJSyiTKHZfjyb,LLaMA 65B,69.5%,,LLaMA-65B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recuJuGMJDq55ts5K,LLAMA 2 7B,45.9%,,Llama-2-7b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recF3fmFjfDHG8vQC,LLAMA 2 13B,60.3%,,Llama-2-13b,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recsMnkbkzX4mZGhQ,LLAMA 2 70B,78.3%,,Llama-2-70b-hf ,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
reca6kz5FN4kqYoLL,StableBeluga2 70B,86.1%,,StableBeluga2,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recTH4MZO44wHEljJ,QWEN 1.8B,53.2%,,Qwen-1_8B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recGHH7EGCn0ZpKha,QWEN 7B,75.3%,,Qwen-7B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recb3dKzs466t5yxc,QWEN 14B,84.4%,,Qwen-14B,0-shot,Qwen Technical Report,https://arxiv.org/abs/2309.16609,
recoZOE4lE6gjLj0D,PaLM,60.1%,85.0%,PaLM 540B,1-shot,PaLM 2 Technical Report,http://arxiv.org/abs/2305.10403,
rec6sY7Z0wdEAbFCL,PaLM 2-S,59.6%,85.6%,PaLM 2-S,1-shot,PaLM 2 Technical Report,http://arxiv.org/abs/2305.10403,
recr4wf65U2XCfXQt,PaLM 2-M,64.9%,88.0%,PaLM 2-M,1-shot,PaLM 2 Technical Report,http://arxiv.org/abs/2305.10403,
recojP6HTbGGTVbzk,PaLM 2-L,69.2%,89.7%,PaLM 2-L,1-shot,PaLM 2 Technical Report,http://arxiv.org/abs/2305.10403,
recvbbV1ndfleEaFI,LLaMA-2 13B,49.4%,77.3%,Llama-2-13b,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recE3lvgrGObdJyUb,LLaMA-2 34B,54.5%,79.4%,Llama-2-34b,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recPlkIgHY3AIp4VA,Qwen 14B,84.4%,90.3%,Qwen-14B,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recywSGJNH0NxjYpT,Mistral 7B,55.5%,80.0%,Mistral-7B-v0.1,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recnxE0Ob3qfuAUIo,Gemma 7B,53.2%,81.5%,gemma-7b,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recKztdCp2jstcKfc,Nemotron-4 15B,55.5%,80.9%,Nemotron-4 15B,0-shot,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recS3RjfIU600rOkX,Falcon 7B,43.4%,74.7%,falcon-7b,0-shot,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recP3Y7YbGtlvVoLz,Falcon 7B,47.9%,,falcon-7b,25-shot,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recJlXiNWhl3fA6kY,Falcon 40B,54.7%,81.9%,falcon-40b,0-shot,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recct3WooWBjSgf7i,Falcon 40B,61.9%,,falcon-40b,25-shot,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recIwq5o7M0MzTSOQ,MPT 7B,42.6%,70.2%,mpt-7b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
receG6c5LTBxKHwK3,MPT 30B,50.6%,76.5%,mpt-30b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recLxwQkk6elP9rvJ,Falcon 7B,42.4%,70.0%,falcon-7b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recyiJ5QhobNkgTh8,Falcon 40B,54.5%,79.2%,falcon-40b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recfekftkllVQjldP,LLAMA 1 7B,47.6%,72.8%,LLaMA-7B,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recTN8LK88YmYWoJe,LLAMA 1 13B,52.7%,74.8%,LLaMA-13B,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
rec5EHyTp1YUNUlIV,LLAMA 1 33B,57.8%,80.0%,LLaMA-33B,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recBTk09y2SlTwbse,LLAMA 1 65B,56.0%,78.9%,LLaMA-65B,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recMlVcLfzfIeByw5,LLAMA 2 7B,45.9%,75.2%,Llama-2-7b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
rec4odRrMQ8MiCOBG,LLAMA 2 13B,49.4%,77.3%,Llama-2-13b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recdrH9ADacP1cq1N,LLAMA 2 34B,54.5%,79.4%,Llama-2-34b,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recCunGxbV5MxvAIQ,LLAMA 2 70B,57.4%,80.2%,Llama-2-70b-hf ,0-shot,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recHNTbNvpxyoh4wP,GPT-3 175B,51.4%,51.4%,text-davinci-001,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recL1vBgiMBZ5R4DU,PaLM 62B,52.5%,52.5%,PaLM 62B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
reccXZcXgV6vDCk2y,PaLM 540B,53.0%,53.0%,PaLM 540B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recG8mIav5orjHdDC,LLaMA 7B,47.6%,47.6%,LLaMA-7B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recCVeGPJ1aSElADj,LLaMA 13B,52.7%,52.7%,LLaMA-13B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recIDEycNEywpwdkf,LLaMA 33B,57.8%,57.8%,LLaMA-33B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rec1kNbH3eKsesiQn,LLaMA 65B,56.0%,56.0%,LLaMA-65B,0-shot,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rech3PGmSJM5UVUj1,DeepSeek-V2 Base       ,92.2%,97.6%,DeepSeek-V2,25-shot,DeepSeek-V3 Technical Report,http://arxiv.org/abs/2412.19437,
rec0eZFhwFqf505ep,Qwen2.5 72B Base       ,94.5%,98.4%,Qwen2.5-72B,25-shot,DeepSeek-V3 Technical Report,http://arxiv.org/abs/2412.19437,
recqQq5QZQFh9wVBf,LLaMA-3.1 405B Base    ,95.3%,98.4%,Llama-3.1-405B,25-shot,DeepSeek-V3 Technical Report,http://arxiv.org/abs/2412.19437,
recJdOZPC2C12w8XY,DeepSeek-V3 Base       ,95.3%,98.9%,DeepSeek-V3,25-shot,DeepSeek-V3 Technical Report,http://arxiv.org/abs/2412.19437,
recCVgWGnaJ4pJcjb,LLaMA 2 7B     ,43.2%,68.7%,Llama-2-7b,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recxm6VEU7XA7OetW,LLaMA 2 13B    ,48.8%,75.2%,Llama-2-13b,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recRd4cheNnjH84Mj,LLaMA 1 33B    ,54.4%,79.6%,LLaMA-33B,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recZnTdIuD44Xt6sD,LLaMA 2 70B    ,56.5%,79.9%,Llama-2-70b-hf ,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recc1svpFIcg7vAL9,Mistral 7B     ,54.9%,80.5%,Mistral-7B-v0.1,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recwv4JdA8LfWCnVJ,Mixtral 8x7B   ,59.7%,83.1%,Mixtral-8x7B-v0.1,0-shot,Mixtral of Experts,http://arxiv.org/abs/2401.04088,
recFlvyWCd6NoUbI5,Phi-3-mini 3.8b        ,84.9%,94.6%,Phi-3-mini-4k-instruct,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recxwZXkfAY9VYS4M,Phi-3-small 7b         ,90.7%,97.0%,Phi-3-small-8k-instruct,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recnLrwmDVsPnimhW,Phi-3-medium 14b       ,91.6%,97.7%,Phi-3-medium-128k-instruct,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
rec9o6whbdGoRj4EL,Phi-2 2.7b             ,75.9%,88.5%,phi-2,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recm8JgtAr9cYvI3c,Mistral 7b             ,78.6%,90.6%,Mistral-7B-v0.1,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
reccsBnBbU3vLIlXL,Gemma 7b               ,78.3%,91.4%,gemma-7b,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recyK5toDoO0k8HO4,Llama-3-In 8b          ,82.8%,93.4%,Meta-Llama-3-8B-Instruct,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recMzqmrpgMj3B6cS,Mixtral 8x7b           ,87.3%,95.6%,Mixtral-8x7B-v0.1,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recfRXMnx6rHuGIBt,GPT-3.5 version 1106   ,87.4%,96.3%,gpt-3.5-turbo-1106,10-shot,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recYond491moEZsn0,LLaMA-2 7B   ,45.9%,75.2%,Llama-2-7b,,Gemma: Open Models Based on Gemini Research and Technology,http://arxiv.org/abs/2403.08295,
recZUkL7VensCpe7G,LLaMA-2 13B  ,49.4%,77.3%,Llama-2-13b,,Gemma: Open Models Based on Gemini Research and Technology,http://arxiv.org/abs/2403.08295,
recyVBqHxwXmkfQPN,Mistral 7B   ,54.9%,80.5%,Mistral-7B-v0.1,,Gemma: Open Models Based on Gemini Research and Technology,http://arxiv.org/abs/2403.08295,
recQD5p42nBSC7DhU,Gemma 2B     ,42.1%,73.2%,gemma-2b,,Gemma: Open Models Based on Gemini Research and Technology,http://arxiv.org/abs/2403.08295,
rec9mwOSlc5EhlJyP,Gemma 7B     ,53.2%,81.5%,gemma-7b,,Gemma: Open Models Based on Gemini Research and Technology,http://arxiv.org/abs/2403.08295,
recj6fIwM4g5QhZPo,Qwen2.5-Coder-0.5B,34.4%,,Qwen2.5-Coder-0.5B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recHGOaX4WRoiifCr,DS-Coder-1.3B-Base,25.4%,,deepseek-coder-1.3b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
rec7OCOx9wHGEaQoJ,Qwen2.5-Coder-1.5B,45.2%,,Qwen2.5-Coder-1.5B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recxa9NmUOx3zyxMY,StarCoder2-3B,34.2%,,starcoder2-3b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
rec50W2CfGuH4w5Uy,Qwen2.5-Coder-3B,52.9%,,Qwen2.5-Coder-3B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recmivd1RvFYMTrow,StarCoder2-7B,38.7%,,starcoder2-7b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
rec5apbI4aqTcGOt2,DS-Coder-6.7B-Base,36.4%,,deepseek-coder-6.7b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
reck06B6EFq2sdA9w,DS-Coder-V2-Lite-Base,57.3%,,DeepSeek-Coder-V2-Lite-Base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recpJSkO0X2NX3uo4,CodeQwen1.5-7B,35.7%,,CodeQwen1.5-7B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recXIKMqsRclf2Qql,Qwen2.5-Coder-7B,60.9%,,Qwen2.5-Coder-7B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recZRpnfj4C3Md7l1,StarCoder2-15B,47.2%,,starcoder2-15b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recoOOluDbZTCxEFb,Qwen2.5-Coder-14B,66.0%,,Qwen2.5-Coder-14B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recpeuK5Fs5GpJMEj,DS-Coder-33B-Base,42.2%,,deepseek-coder-33b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recZW2JY1PtSj2NeX,DS-Coder-V2-Base,64.3%,,DeepSeek-Coder-V2-Base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
rec3ZJZr9FPPsNCST,Qwen2.5-Coder-32B,70.5%,,Qwen2.5-Coder-32B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recoGOGv6pY2Z77AB,Vicuna-13B (v1.1),43.2%,75.4%,vicuna-13b-v1.1,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recSNV2YipA1bob60,Llama2-7B,43.4%,76.3%,Llama-2-7b,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recH3a6zzXMsqvy9U,Llama-7B,38.5%,68.2%,LLaMA-7B,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
rec81EbC7EomkLKBX,MPT-7B,40.5%,74.9%,mpt-7b,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recDO0Z46FYYeRAj8,Falcon-7B,36.3%,71.9%,falcon-7b,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
rec328KDuE0wcry3j,Falcon-rw-1.3B,28.2%,63.3%,,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recY7BYwRaSw0WvJH,OPT-1.3B,23.2%,57.0%,opt-1.3b,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recl5dU2L0etusoaO,GPT-Neo-2.7B,27.4%,61.1%,,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recKlotp4q8bnKtwd,GPT2-XL-1.5B,25.0%,58.3%,gpt2-xl,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recgOdAV6Fy1Oqq2M,phi-1.5-web-only (1.3B),32.9%,66.6%,,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
reck8zqnBzwmuHWKc,phi-1.5-web (1.3B),44.9%,76.1%,,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recoj6GK2WTBxH06V,phi-1.5 (1.3B),44.4%,75.6%,phi-1_5,,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recnbaPIOtKCOtJ0V,GPT-4,96.3%,,,25-shot,GPT-4 Technical Report,http://arxiv.org/abs/2303.08774,
recGUeMteustGGfMg,GPT-3.5,85.2%,,text-davinci-002,25-shot,GPT-4 Technical Report,http://arxiv.org/abs/2303.08774,
rechw4k0fmZIGuIGv,8-shot PaLM,85.2%,,PaLM 540B,8-shot,GPT-4 Technical Report,http://arxiv.org/abs/2303.08774,
recsaQHxqvzRAnRqF,GPT-3 (175B) (Zero-shot),51.4%,68.8%,text-davinci-001,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
recBGxKI2qp2Vzmtz,GLaM (64B/64E) (Zero-shot),48.0%,71.6%,,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
reco3SamtEdKFjE4P,GPT-3 (175B) (One-shot),53.2%,71.2%,text-davinci-001,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
recJ9BDPpOIL845dB,GLaM (64B/64E) (One-shot),50.3%,76.6%,,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
recH2Cy2QrGCCajNe,GPT-3 (175B) (50-shot),51.5%,70.1%,text-davinci-001,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
recI25UXKgeWd2uxU,GLaM (64B/64E) (3-shot),52.0%,,,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
rec6qlE7YYs8hIOWQ,GLaM (64B/64E) (16-shot),,78.9%,,,GLaM: Efficient Scaling of Language Models with Mixture-of-Experts,http://arxiv.org/abs/2112.06905,
recNlveRZDstMlvIa,Claude Instant 1.1,85.7%,,claude-instant-1.1,,Releasing Claude Instant 1.2,https://www.anthropic.com/news/releasing-claude-instant-1-2,
recCzRTq1cFC8vOhO,Claude Instant 1.2,86.3%,,claude-instant-1.2,,Releasing Claude Instant 1.2,https://www.anthropic.com/news/releasing-claude-instant-1-2,
recmPMvGdviW8gLMV,Switch-Base,,,,,,,
rec3bc6kbIygGnaBo,T5-Base,,,,,,,
recDdVbzbODl8KRDE,XGen-7B,41.2%,,xgen-7b-8k-base,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec96oGAR33iueEEJ,LLaMA-7B,44.8%,,LLaMA-7B,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recIJQRtQygxkLIBx,Falcon-7B,43.4%,,falcon-7b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recbWNpk3h1b9y7PR,MPT-7B,41.7%,,mpt-7b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recdgUh5eB5jQ4oyE,OpenLLaMA-7B,38.7%,,open_llama_7b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec8cEStkqtkCyGmJ,Redpajama-7B,39.1%,,RedPajama-INCITE-7B-Base,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recSYskjlkTSJPrPU,GPT-neox-20B,41.1%,,gpt-neox-20b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recsLxqhuH0roOIAF,OPT-13B,35.8%,,opt-13b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recPDicLmVESGltVO,GPT-J-6B,36.3%,,gpt-j-6b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recpM34slUJwZbjqj,Dolly-v2-12B,39.6%,,dolly-v2-12b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recuKcLt2nDob6ZLa,Cerebras-GPT-13B,32.4%,,Cerebras-GPT-13B,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recHdiAAANd9V5aXp,StableLM-alpha-7B,27.0%,,stablelm-tuned-alpha-7b,,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,