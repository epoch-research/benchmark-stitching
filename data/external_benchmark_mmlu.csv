id,Name,EM,Model version,Shots,Source,Source link,Notes
reccNX56mRCIhx9ok,Amazon Nova Lite,77.0%,amazon.nova-lite-v1:0,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recMu6jniW4Q1aHhj,Amazon Nova Micro,70.8%,amazon.nova-micro-v1:0,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recIRlQ5EAWn5dxqD,Amazon Nova Pro,82.0%,amazon.nova-pro-v1:0,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recyryG18K2x30duJ,AquilaChat2 34B,65.2%,,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
rechbRaRakeh7m35k,AquilaChat2 34B,66.7%,,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
receF4qeBwFbaGr6r,Arctic Instruct,67.7%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rechuNXbQCiXvI5bb,Baichuan 1-7B,42.3%,Baichuan-7B,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recCxbVxrA9fWanQp,Baichuan 1-13B-Base,51.6%,Baichuan-13B-Base,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recL0KmTLb9YnVqAX,Baichuan 2-7B-Base,54.2%,Baichuan-2-7B-Base,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
rec2lAAR2TzfQNZIn,Baichuan 2-13B-Base,59.2%,Baichuan-2-13B-Base,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recg7CzyJtjHNlw9z,Baichuan-2 13B,59.2%,Baichuan-2-13B-Base,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recic0LQTjjN2UHF2,Baichuan2-Chat 13B,55.1%,Baichuan2-13B-Chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recLNxS9WuckNhW0w,Baichuan2-Chat 13B,50.1%,Baichuan2-13B-Chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recjibIVUpfsNYJiW,Cerebras-GPT-13B,26.2%,Cerebras-GPT-13B,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recxEX8BTSBULeO3F,Cerebras-GPT-13B,24.6%,Cerebras-GPT-13B,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec5vUXZIJlzUijla,ChatGLM 2-6B (base)*,47.9%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recJMYoLpkfhVACXE,ChatGLM2 6B,47.9%,chatglm2-6b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recblkzYf2HuW8IIY,Chinchilla 70B,67.5%,Chinchilla (70B),5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recwJ71gOFSsbxqzt,Chinese-Alpaca-Plus-13B,43.9%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recMiCaKbG8RgAL4z,Claude 1.3,77.0%,claude-1.3,5,Model Card and Evaluations for Claude Models,https://www-cdn.anthropic.com/5c49cc247484cecf107c699baf29250302e5da70/claude-2-model-card.pdf,5-shot CoT
recrV38I6BcgNumAG,Claude 2,78.5%,claude-2.0,5,Model Card and Evaluations for Claude Models,https://www-cdn.anthropic.com/5c49cc247484cecf107c699baf29250302e5da70/claude-2-model-card.pdf,5-shot CoT
rec3x29hlWlm49CQP,Claude 2.1,73.5%,claude-2.1,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recFv7M6aEx8RaC1z,Claude 3 Haiku (20240307),73.8%,claude-3-haiku-20240307,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
receM7r5loSsHAQw3,Claude 3 Opus (20240229),84.6%,claude-3-opus-20240229,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recE3DF6ClfScS431,Claude 3 Sonnet (20240229),75.9%,claude-3-sonnet-20240229,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recYAn1b7tiMc4vIW,Claude 3.5 Haiku (20241022),74.3%,claude-3-5-haiku-20241022,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rectxjtMFzEfdNd3Q,Claude 3.5 Sonnet (20240620),86.5%,claude-3-5-sonnet-20240620,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recoTsRA8ILsdFhsM,Claude 3.5 Sonnet (20241022),87.3%,claude-3-5-sonnet-20241022,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recvrlr1UHnsu2xMG,Claude instant,73.4%,claude-instant-1.1,5,Model Card and Evaluations for Claude Models,https://www-cdn.anthropic.com/5c49cc247484cecf107c699baf29250302e5da70/claude-2-model-card.pdf,5-shot CoT
rec8sbiLCZ655gCFv,Claude Instant 1.1,73.4%,claude-instant-1.1,5,Releasing Claude Instant 1.2,https://www.anthropic.com/news/releasing-claude-instant-1-2,
rec5zO5kkq0fxUAov,Claude Instant 1.2,68.8%,claude-instant-1.2,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rece9mgHXM0QhmiDh,Claude Instant 1.2,73.2%,claude-instant-1.2,5,Releasing Claude Instant 1.2,https://www.anthropic.com/news/releasing-claude-instant-1-2,
recBAF9M2T4QfIHAR,CodeQwen1.5-7B,40.5%,CodeQwen1.5-7B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recalVfY5uZ17cXy1,Command R,65.2%,c4ai-command-r-08-2024,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rectFxVzTinEXE5UP,Command R Plus,69.4%,c4ai-command-r-plus-08-2024,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recNBl9C5PMTK1z60,DBRX Instruct,74.1%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recSzBzlqINbmZstc,DeepSeek LLM Chat (67B),72.5%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recZAYS2AtKUwDAot,DeepSeek v3,87.2%,DeepSeek-V3,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recUe3PPejBJft24I,DeepSeek-V2 Base,78.4%,DeepSeek-V2,5,DeepSeek-V3 Technical Report,https://arxiv.org/pdf/2412.19437,
reciHYY3MaHRp7o7O,DeepSeek-V3 Base,87.1%,DeepSeek-V3,5,DeepSeek-V3 Technical Report,https://arxiv.org/pdf/2412.19437,
rec97rlUByGZ2zt8v,Dolly-v2-12B,26.2%,dolly-v2-12b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recWcPAtUKdfuuDcu,Dolly-v2-12B,25.4%,dolly-v2-12b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
reca7wIho24nf1lbz,DS-Coder-1.3B-Base,25.8%,deepseek-coder-1.3b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
rec9GGQ2SbDsozdsi,DS-Coder-6.7B-Base,36.4%,deepseek-coder-6.7b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recWXbEo1J1SGz2Pc,DS-Coder-33B-Base,39.4%,deepseek-coder-33b-base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recvb9WHxy2ct1iLh,DS-Coder-V2-Lite-Base,60.5%,DeepSeek-Coder-V2-Lite-Base,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recZxu6DjE1qtZ1S3,Falcon 7B,35.0%,falcon-7b,5,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recWf7mxbT8We02eo,Falcon 7B,26.2%,falcon-7b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recCqMLHKTiaKiBA0,Falcon 7B,26.2%,falcon-7b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recz02AVGuolhygEY,Falcon 40B,56.9%,falcon-40b,5,Falcon2-11B Technical ReportFalcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recRH4MTY2hMvXK0H,Falcon 40B,55.4%,falcon-40b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recsdVJaTPLaSRk6Q,Falcon 40B,55.4%,falcon-40b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
reci0A7hEp1NCjbaL,Falcon-7B,26.0%,falcon-7b,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recqBkEih0PUjiHHs,Falcon-7B,26.9%,falcon-7b,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recT6jUES7TrDPOPE,Falcon-7B,26.9%,falcon-7b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recoziexUycUxDIif,Falcon-7B,23.9%,falcon-7b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec47dDuJMqw0UtNo,Falcon-180B,70.6%,falcon-180B,5,The Falcon Series of Open Language Models,http://arxiv.org/abs/2311.16867,
recbWgy7ZGi6kS6J4,Falcon-rw-1.3B,25.9%,,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
reca5QOZscaMohhwc,Falcon2-11B,58.4%,falcon-11b,5,Falcon2-11B Technical Report,http://arxiv.org/abs/2407.14885,
recp3h3zrPXM6K5E6,Gemini 1.0 Pro (001),70.0%,gemini-1.0-pro-001,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recya8zx93N6YFh4J,Gemini 1.5 Flash (001),77.9%,gemini-1.5-flash-001,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recIlo0YrdpQ2gmEe,Gemini 1.5 Flash (002),73.9%,gemini-1.5-flash-002,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recvHsglkezP7vlhw,Gemini 1.5 Flash (0514 preview),77.8%,gemini-1.5-flash-0514,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recWbQsttPCe4RW4T,Gemini 1.5 Pro (001),82.7%,gemini-1.5-pro-001,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recosbed3WAJ7x0aX,Gemini 1.5 Pro (002),86.9%,gemini-1.5-pro-002,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recIoOlvBkY3ltQHG,Gemini 1.5 Pro (0409 preview),81.0%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recGFT80UG5ZvEXom,Gemini 2.0 Flash (Experimental),79.7%,gemini-2.0-flash-exp,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec9XaJ2TmQNbln0Q,Gemma (7B),66.1%,gemma-7b,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
receSMvaZsWAJGCwz,Gemma 2 Instruct (9B),72.1%,gemma-2-9b-it,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recvSF9bkUFYJFbvW,Gemma 2 Instruct (27B),75.7%,gemma-2-27b-it,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recFxjYqOdtTFaKbb,Gemma 2B,42.3%,gemma-2b,5,Gemma: Open Models Based on Gemini Research and Technology,https://arxiv.org/pdf/2403.08295,"5-shot top-1
"
recVGRLvxWiFAKPkj,Gemma 7B,64.3%,gemma-7b,5,Gemma: Open Models Based on Gemini Research and Technology,https://arxiv.org/pdf/2403.08295,"5-shot top-1
"
recZ4bWHun8k676qr,Gemma 7B,64.3%,gemma-7b,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recw9AShxMdslSHLM,Gemma 7b               ,63.6%,gemma-7b,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recNkiYry1lAvuSwK,Gopher,60.0%,Gopher (280B),5,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",http://arxiv.org/abs/2112.11446,
rec5n8Sdwq7WFYI2x,Gopher 280B,60.0%,Gopher (280B),5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rec9BQTN7H8M50fyc,GPT 4o-mini,81.8%,gpt-4o-mini-2024-07-18,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
recuAsFQiyYxqtm21,GPT-3,43.9%,text-davinci-001,5,"Scaling Language Models: Methods, Analysis & Insights from Training Gopher",http://arxiv.org/abs/2112.11446,
recvqThL1Bym2eWPd,GPT-3 175B,43.9%,text-davinci-001,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recuAOzevJhAkVd3J,GPT-3.5,70.0%,text-davinci-002,5,GPT-4 Technical Report,https://arxiv.org/pdf/2303.08774,
reciwAV6BQ14hlLxX,GPT-3.5 Turbo,68.5%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recUxR8bLyjemBFQ2,GPT-3.5 Turbo (0125),67.3%,gpt-3.5-turbo-0125,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
receZjlh6qpQqkcqQ,GPT-3.5 Turbo (0613),68.9%,gpt-3.5-turbo-0613,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recGJbQCjDKrqzKXr,GPT-3.5 version 1106   ,71.4%,gpt-3.5-turbo-1106,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recFBhqAXAnkehHJj,GPT-4,83.9%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
reccKxm0VqsklwpFa,GPT-4 (0613),82.4%,gpt-4-0613,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recP6zUYu6rVqvynx,GPT-4 (initial release),86.4%,gpt-4-0314,5,GPT-4 Technical Report,https://arxiv.org/pdf/2303.08774,
rec6xx0AwDEsiaUS8,GPT-4 Turbo (1106 preview),79.6%,gpt-4-turbo,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recTZoT00f1052qmh,GPT-4 Turbo (2024-04-09),81.3%,gpt-4-turbo-2024-04-09,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recTErMEF70Oq8pZU,GPT-4o,88.1%,gpt-4o-2024-11-20,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
rec7uXJcDwu5vAB0v,GPT-4o (2024-05-13),84.2%,gpt-4o-2024-05-13,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recngZX6kgPdpEuvJ,GPT-4o (2024-08-06),84.3%,gpt-4o-2024-08-06,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec66ukiUXgRuE5uX,GPT-4o mini (2024-07-18),76.7%,gpt-4o-mini-2024-07-18,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recSU7vpnDawA53bF,GPT-J-6B,25.1%,gpt-j-6b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recnPxCnkNQT6Bl8j,GPT-J-6B,25.7%,gpt-j-6b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recSr00Py8AW3SFO3,GPT-NeoX 20B,33.6%,,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rechQVncuCixOKIxc,Inflection 1,72.7%,Inflection-1,5,Inflection-1 ,https://inflection.ai/blog/inflection-1,
recwT2hhSXlrSRq1X,InternLM (104B),67.2%,,5,InternLM: A Multilingual Language Model with Progressively Enhanced Capabilities,https://static.aminer.cn/upload/pdf/127/1564/656/6481884993eaf7045294a0c4_0.pdf,
recCRfqyDW6e5Cxj0,InternLM 7B,51.0%,internlm-7b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recdCL1os0x7URkOn,InternLM-Chat 20B,55.6%,internlm-chat-20b,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recQkCpGZV2zmuda4,InternLM-Chat 20B,57.4%,internlm-chat-20b,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
rec1aPizKw4Q63HiH,Jamba 1.5 Large,78.2%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recTOe7AnWWDiRdsD,Jamba 1.5 Mini,69.9%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recg1lDZgeQXcOhJk,Jamba Instruct,65.9%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
reciRq6HujhO9z9nl,LLAMA 1 7B,35.1%,LLaMA-7B,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recN0xjCpJlAJpL3g,LLAMA 1 13B,46.9%,LLaMA-13B,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
rec3LN7X83bnNLYmy,LLAMA 1 33B,57.8%,LLaMA-33B,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
rec8UiAKlK7vPondE,LLaMA 1 33B    ,56.8%,LLaMA-33B,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
rec1vmtLgykjCiHqG,LLAMA 1 65B,63.4%,LLaMA-65B,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recDRfiRYG3HCQq5K,Llama 2 (7B),45.8%,Llama-2-7b,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recHeILlp9WyfKuQk,Llama 2 (13B),55.4%,Llama-2-13b,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recOpGv66pVIzJc2y,Llama 2 (70B),69.5%,Llama-2-70b-hf ,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec8cJlYZZHD6DliH,LLAMA 2 7B,45.3%,Llama-2-7b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recQtVvlLn7Mwe42i,LLaMA 2 7B     ,44.4%,Llama-2-7b,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
recAtLiMOQMukjkr4,LLAMA 2 13B,54.8%,Llama-2-13b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recQabHfvgaByHw50,LLaMA 2 13B    ,55.6%,Llama-2-13b,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
recXGb1eMBkdHVVPt,LLAMA 2 34B,62.6%,Llama-2-34b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
rec4EA8N1sXX54njV,LLaMA 2 34B,62.6%,Llama-2-34b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recCIOv8PV47XWiXE,LLAMA 2 70B,68.9%,Llama-2-70b-hf ,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recEQPQjoxax64ZSN,LLaMA 2 70B,69.8%,Llama-2-70b-hf ,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recvvZSkhoBXMrVwo,LLaMA 2 70B    ,69.9%,Llama-2-70b-hf ,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
rech0sV4TGdAsCGBx,LLaMA 2-7B,45.7%,Llama-2-7b,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
rec4FrJ61uDhzqdol,LLaMA 2-13B,55.1%,Llama-2-13b,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recShUHfQj3yvMmET,Llama 3 (8B),68.8%,Meta-Llama-3-8B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recWvSXL72D2hpbVl,Llama 3 (70B),79.3%,Meta-Llama-3-70B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recaaHZaz730PgETl,Llama 3.1 Instruct Turbo (8B),56.1%,Llama-3.1-8B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
recBq5JDLuhxief9r,Llama 3.1 Instruct Turbo (70B),80.1%,Llama-3.1-70B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
recqvxNx4ASzVf1pr,Llama 3.1 Instruct Turbo (405B),84.5%,Llama-3.1-405B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
rec91E3tiY2SItmiw,Llama 3.2 Vision Instruct Turbo (11B),56.5%,Llama-3.2-11B-Vision-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
recib3s0R87GkOIJ6,Llama 3.2 Vision Instruct Turbo (90B),80.3%,Llama-3.2-90B-Vision-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
recYtSuvfsDMgxpQC,Llama 3.3 Instruct Turbo (70B),79.1%,Llama-3.3-70B-Instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,Seems like the Turbo versions are quantized: https://huggingface.co/spaces/AtlaAI/judge-arena/discussions/4 (that's a different 
rec43wZbfZGjTvUxq,LLaMA 7B,35.6%,LLaMA-7B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recpktJbxIumcFneG,LLaMA 7B,35.1%,LLaMA-7B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recvzXv36THWKaBgb,LLaMA 13B,47.7%,LLaMA-13B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recIiOs7bTAVwyNpa,LLaMA 13B,46.9%,LLaMA-13B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
receAb9h5D57B0gYh,LLaMA 33B,58.7%,LLaMA-33B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recvQI3hl09uCHYs8,LLaMA 33B,57.8%,LLaMA-33B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rec9IhkT5TRasgNag,LLaMA 65B,63.4%,LLaMA-65B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
receYgtoMItZ5byvT,LLaMA-2 7B,45.3%,Llama-2-7b,5,Gemma: Open Models Based on Gemini Research and Technology,https://arxiv.org/pdf/2403.08295,"5-shot top-1
"
recm3ckG9rQdlSf3G,LLaMA-2 13B,54.8%,Llama-2-13b,5,Gemma: Open Models Based on Gemini Research and Technology,https://arxiv.org/pdf/2403.08295,"5-shot top-1
"
recQpivyiHncdya7p,LLaMA-2 13B,54.8%,Llama-2-13b,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
reccZ0kQv849Nx6S0,LLaMA-2 34B,62.6%,Llama-2-34b,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recKeTJ0WxkfqaXc6,Llama-3-In 8b          ,66.5%,Meta-Llama-3-8B-Instruct,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
rec7Kb0dlps0bAwVq,LLaMA-3.1 405B Base,84.4%,Llama-3.1-405B,5,DeepSeek-V3 Technical Report,https://arxiv.org/pdf/2412.19437,
recOK4kloLRVBYWyC,LLaMA-7B,35.1%,LLaMA-7B,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recyV0OffUnewduYa,LLaMA-7B,35.1%,LLaMA-7B,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
reck2fsCW8rwEIBV3,LLaMA-7B,32.0%,LLaMA-7B,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recXt1b7mmd7pBCEN,Llama-7B,35.2%,LLaMA-7B,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recC5kLFkYdywVLTE,LLaMA-13B,46.3%,LLaMA-13B,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
rechfMlLcdL4d6JYV,Llama2-7B,45.3%,Llama-2-7b,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
reccr6kNapl4XhHMh,LLaMA2-Chat 13B,50.9%,Llama-2-13b-chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recP7LM6vdowGXldC,LLaMA2-Chat 13B,47.3%,Llama-2-13b-chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
rechEaZxx7y6EW89C,LLaMA2-Chat 70B,59.4%,Llama-2-70b-chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recq7vZurZvyzSaF8,LLaMA2-Chat 70B,59.9%,Llama-2-70b-chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recFwE99pUPS1RrqR,Llama3.3 70b instruct,86.3%,Llama-3.3-70B-Instruct,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
rec5aVLAAe2uwnAJ3,Mistral 7B,62.5%,Mistral-7B-Instruct-v0.2,5,Gemma: Open Models Based on Gemini Research and Technology,https://arxiv.org/pdf/2403.08295,"5-shot top-1
"
reclqttZHU3FrMenP,Mistral 7B,62.5%,Mistral-7B-v0.1,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
recobovxkli2yXD7Q,Mistral 7B,60.1%,Mistral-7B-v0.1,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recrKIaLtBWuoRKy0,Mistral 7b             ,61.7%,Mistral-7B-v0.1,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recxGM6lCcs0CnKWO,Mistral Instruct v0.3 (7B),59.9%,Mistral-7B-Instruct-v0.3,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recMfHwyb3g0GU3WP,Mistral Large (2402),68.8%,mistral-large-2402,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recKDxkbfoASopZz7,Mistral Large 2 (2407),80.0%,mistral-large-2407,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
reccvR6S88KxSkuED,Mistral NeMo (2402),65.3%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recKStU0sPWNiLWCM,Mistral Small (2402),68.7%,mistral-small-2402,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recdbbEpQDnuQx1SM,Mistral v0.1 (7B),56.6%,Mistral-7B-v0.1,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recHxyrzN6ysHgwup,Mixtral (8x7B 32K seqlen),71.7%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
reczWpbUvk8LZHdwj,Mixtral (8x22B),77.8%,Mixtral-8x22B-v0.1,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec2QbPaiM3fs3ojk,Mixtral 8x7B,70.6%,Mixtral-8x7B-v0.1,5,Mixtral of Experts,https://arxiv.org/pdf/2401.04088,
recVbhuiQ3mCmSZWs,Mixtral 8x7b           ,70.5%,Mixtral-8x7B-v0.1,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recXxnvP42eSSUf1r,MPT 7B,30.8%,mpt-7b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
rec6fhu1fu0tDpFCM,MPT 7B,26.8%,mpt-7b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recsvME0N7N3lHCNM,MPT 30B,47.9%,mpt-30b,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recORhwxKRN3CKT5H,MPT 30B,46.9%,mpt-30b,5,Llama 2: Open Foundation and Fine-Tuned Chat Models,http://arxiv.org/abs/2307.09288,
recciuLJt00P8UdBH,MPT-7B,27.9%,mpt-7b,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recThSGOCYopyGBAn,MPT-7B,26.8%,mpt-7b,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,
recnP0IxuIUI5wyAV,MPT-7B,26.7%,mpt-7b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recjktWCt7fCSUqIu,MPT-7B,27.4%,mpt-7b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recFoOkw8h4blebt7,Nemotron-4 15B,58.7%,Nemotron-4 15B,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
recSXeZwsr3iejrsy,OLMo (7B),29.5%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recfz827JQEYK0ML2,OLMo 1.7 (7B),53.8%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recS3RPFpiAohJDyr,OpenLLaMA-7B,29.9%,open_llama_7b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recKitarPK5ZkGKHY,OpenLLaMA-7B,28.6%,open_llama_7b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recnCITHR0D69TaSW,OPT-13B,25.1%,opt-13b,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recptjItsyCc9FRVH,OPT-13B,24.4%,opt-13b,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec86hiwuXU11mYYm,PaLM 8B,25.4%,,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
rec9nwU5JvWa3KMNP,PaLM 62B,53.7%,PaLM 62B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
recq6tXUJ4hdJZHiK,PaLM 540B,69.3%,PaLM 540B,5,LLaMA: Open and Efficient Foundation Language Models,http://arxiv.org/abs/2302.13971,
receRMAyrZg4S22XH,PaLM-2 (Bison),69.2%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recrhlTc9IULolRYJ,PaLM-2 (Unicorn),78.6%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recgWVSaehLn2uc2n,Palmyra X V2 (33B),62.1%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recraXT1q5kVa9Df9,Palmyra X V3 (72B),78.6%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recxRfXGUWwfxzfMT,Palmyra-X-004,73.9%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recIRX5Xrwuj0aVsw,phi-1.5,37.6%,phi-1_5,2,Textbooks Are All You Need II: phi-1.5 technical report,http://arxiv.org/abs/2309.05463,"We use the harness-eval zero-shot accuracy on PIQA, Hellaswag, OpenbookQA, 2-shot performance on MMLU,"
recOjVJ9mVKxRJb67,Phi-2,58.4%,phi-2,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recZMvyAbMp0eIx88,Phi-2,56.3%,phi-2,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recjSB9vhRshMrbfW,Phi-3 (7B),75.7%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recIC2lbeIoOMCnU9,Phi-3 (14B),77.5%,Phi-3-medium-128k-instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recokPFC1wM7clrm7,Phi-3 14b,77.9%,Phi-3-medium-128k-instruct,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
recCmqAcPDN7z3eOd,Phi-3-medium,78.0%,Phi-3-medium-128k-instruct,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recBm3x8Mkas41pg2,Phi-3-mini,68.8%,Phi-3-mini-4k-instruct,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
reclGoqueJP6ji9WZ,Phi-3-small,75.7%,Phi-3-small-8k-instruct,5,Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,http://arxiv.org/abs/2404.14219,
recPr3djloYa7CtTW,Phi-4 14b,84.8%,phi-4,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"""Specifically, we used log-likelihood evaluations for MMLU (5-shot)"""
recJEnP48cP1MNsrP,Qwen 1.8B,28.2%,Qwen-1_8B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recZMyuEA1HyQDC9A,Qwen 7B,45.0%,Qwen-7B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
recbr9lo3CeOOBkvY,QWEN 14B,66.3%,Qwen-14B,5,Nemotron-4 15B Technical Report,http://arxiv.org/abs/2402.16819,
reci4VBEctqPF5t2B,Qwen 14B,53.4%,Qwen-14B,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
rechXjvOrdKm234Fr,Qwen-Chat 14B,64.0%,Qwen-14B-Chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recfT37OwcoOgwoYl,Qwen-Chat 14B,65.0%,Qwen-14B-Chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recFmlmIXPZeKd0uT,Qwen1.5 (7B),62.6%,Qwen1.5-7B,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recgNYd9sZSHzqlh3,Qwen1.5 (14B),68.6%,qwen1.5-14B,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recpbIA4MZ2d0bMHo,Qwen1.5 (32B),74.4%,qwen1.5-32B,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recN7w14y80rqwibJ,Qwen1.5 (72B),77.4%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec4IdPlkVEWoAke2,Qwen1.5 Chat (110B),76.8%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
rec4k5yqvGWnSlnLK,Qwen2 Instruct (72B),82.4%,qwen2-72b-instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recaLqeKOZiJFuyWC,Qwen2.5 14b instruct,79.9%,qwen2.5-14b-instruct,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
rec1e9rTGH12ziqp2,Qwen2.5 72B Base,85.0%,Qwen2.5-72B,5,DeepSeek-V3 Technical Report,https://arxiv.org/pdf/2412.19437,
recbl49vkZltt7Qu7,Qwen2.5 72b instruct,85.3%,qwen2.5-72b-instruct,5,Phi-4 Technical Report,http://arxiv.org/abs/2412.08905,"Specifically, we used log-likelihood evaluations for MMLU (5-shot)"
rec4M7QClQ8t5k7Fi,Qwen2.5 Instruct Turbo (7B),72.9%,qwen2.5-7b-instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recUfCycerC91cgsO,Qwen2.5 Instruct Turbo (72B),83.4%,qwen2.5-72b-instruct,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recA0z9ynBjuFVr0i,Qwen2.5-Coder-0.5B,42.0%,Qwen2.5-Coder-0.5B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recsb2ABruR7vDJyc,Qwen2.5-Coder-1.5B,53.6%,Qwen2.5-Coder-1.5B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recFedHhPHlgqWxpq,Qwen2.5-Coder-3B,61.2%,Qwen2.5-Coder-32B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recot1Px8adoUoPs3,Qwen2.5-Coder-7B,68.0%,Qwen2.5-Coder-7B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recXLZnQpE0oht07R,Qwen2.5-Coder-14B,75.2%,Qwen2.5-Coder-14B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recgIGiZ5lVnVM7rT,Qwen2.5-Coder-32B,79.1%,Qwen2.5-Coder-32B,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
reclqOVSaOoy7NX2U,Redpajama-7B,26.3%,RedPajama-INCITE-7B-Base,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recQGR1shnVCw79MB,Redpajama-7B,25.8%,RedPajama-INCITE-7B-Base,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recvPdPH4F3YB9X2m,Solar Pro,77.6%,,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
reca4GRikJuwzhgQj,StableBeluga2 70B,68.6%,StableBeluga2,5,Qwen Technical Report,https://arxiv.org/pdf/2309.16609,
rec7SmDXXVMzS12UD,StarCoder2-3B,36.6%,starcoder2-3b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recbF6EudRQDiZM0w,StarCoder2-7B,38.8%,starcoder2-7b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recslUwoLlToAjB27,StarCoder2-15B,64.1%,starcoder2-15b,,Qwen2.5-Coder Technical Report,http://arxiv.org/abs/2409.12186,
recjDwTuCMcGYnymQ,Vicuna-13B,52.0%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recmtaX4LELTcHv2G,XGen-7B,36.3%,xgen-7b-8k-base,5,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
recNXliE4Qvt56aRx,XGen-7B,32.1%,xgen-7b-8k-base,0,XGen-7B Technical Report,http://arxiv.org/abs/2309.03450,
rec3RbWkc7eNqnBO3,XVERSE-13B,55.2%,,5,Baichuan 2: Open Large-scale Language Models,http://arxiv.org/abs/2309.10305,
recQDuDGOq1wY5Ouj,Yi (6B),64.0%,Yi-6B,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recjx70KTlRekGQ02,Yi (34B),76.2%,Yi-34B,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recGm5EDNDIETSYi6,Yi 6B,63.2%,Yi-6B,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,"We report the overall results for MMLU[27](5-shot), CMMLU[42] (5-shot), Gaokao-Bench[90] (5-shot), and BigBench[72] Hard (BBH[74]) (3-shot)."
recwCEStuvtsY9T89,Yi 34B,76.3%,Yi-34B,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,"We report the overall results for MMLU[27](5-shot), CMMLU[42] (5-shot), Gaokao-Bench[90] (5-shot), and BigBench[72] Hard (BBH[74]) (3-shot)."
recbChoe3AEIXUMHg,Yi Large (Preview),79.3%,Yi-large,5,Stanford CRFM Leaderboard,https://crfm.stanford.edu/helm/lite/latest/#/leaderboard/mmlu,
recrn20mUuMopGxXJ,Yi-9B,68.4%,Yi-9B,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recS1feH5g4KJrpW8,Yi-Chat 6B,58.2%,Yi-6B-Chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
receVD87dnzgVzRts,Yi-Chat 6B,61.0%,Yi-6B-Chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
recswVGACIIFbdPtu,Yi-Chat 34B,67.6%,Yi-34B-Chat,0,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,
reckSm2dCL3rMGbBd,Yi-Chat 34B,73.5%,Yi-34B-Chat,5,Yi: Open Foundation Models by 01.AI,http://arxiv.org/abs/2403.04652,