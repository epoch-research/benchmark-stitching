{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ea3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null performances after coercion: 295\n",
      "after saturation filter 1911\n",
      "after filter num benchmarks 1473\n",
      "after merge with model versions 1468\n",
      "after merge with benchmark dates 1468\n",
      "Original number of rows: 1468\n",
      "Number of rows after aggregation: 1244\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 38, initial cost 4.3493e+01, final cost 2.6360e+00, first-order optimality 1.17e-03.\n",
      "GPT-3 (001): 0.954\n",
      "GPT-3 (002): 1.49\n",
      "GPT-4: 1.52\n",
      "GPT-5: 2.65\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_loader import scores_df\n",
    "from fit import fit_statistical_model\n",
    "\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 0\n",
    "anchor_slope = 1\n",
    "df1, df_cm1, df_db1 = fit_statistical_model(\n",
    "    scores_df, \n",
    "    anchor_mode=\"benchmark\", \n",
    "    anchor_benchmark=anchor_benchmark, \n",
    "    anchor_difficulty=anchor_difficulty, \n",
    "    anchor_slope=anchor_slope)\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df_cm1['date_obj'] = pd.to_datetime(df_cm1['date'])\n",
    "\n",
    "gpt_3_001_score = df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['estimated_capability'].values[0]\n",
    "gpt_3_002_score = df_cm1[df_cm1['model'].str.contains('text-davinci-002')]['estimated_capability'].values[0]\n",
    "gpt_4_score = df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['estimated_capability'].values[0]\n",
    "gpt_5_score = df_cm1[df_cm1['model'].str.contains('gpt-5-2025-08-07_medium')]['estimated_capability'].values[0]\n",
    "print(f\"GPT-3 (001): {gpt_3_001_score:.3}\")\n",
    "print(f\"GPT-3 (002): {gpt_3_002_score:.3}\")\n",
    "print(f\"GPT-4: {gpt_4_score:.3}\")\n",
    "print(f\"GPT-5: {gpt_5_score:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9b679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>performance</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>benchmark_release_date</th>\n",
       "      <th>optimized</th>\n",
       "      <th>is_math</th>\n",
       "      <th>is_coding</th>\n",
       "      <th>model</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>m15</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.748</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>m17</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.735</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>m22</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.818</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>m297</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.864</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>m301</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.699</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>m6</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.738</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>m64</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.881</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4o-2024-11-20</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>Phi-4 Technical Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>m74</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.711</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gpt-4-turbo-2024-04-09</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>Stanford CRFM Leaderboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_id benchmark_id  performance benchmark benchmark_release_date  \\\n",
       "252       m15          b21        0.748      MMLU             2020-09-07   \n",
       "326       m17          b21        0.735      MMLU             2020-09-07   \n",
       "550       m22          b21        0.818      MMLU             2020-09-07   \n",
       "728      m297          b21        0.864      MMLU             2020-09-07   \n",
       "747      m301          b21        0.699      MMLU             2020-09-07   \n",
       "946        m6          b21        0.738      MMLU             2020-09-07   \n",
       "979       m64          b21        0.881      MMLU             2020-09-07   \n",
       "1060      m74          b21        0.711      MMLU             2020-09-07   \n",
       "\n",
       "      optimized  is_math  is_coding                   model        date  \\\n",
       "252        True    False      False       gpt-4o-2024-05-13  2024-05-13   \n",
       "326        True    False      False              gpt-4-0613  2023-06-13   \n",
       "550        True    False      False  gpt-4o-mini-2024-07-18  2024-07-18   \n",
       "728        True    False      False              gpt-4-0314  2023-03-14   \n",
       "747        True    False      False             gpt-4-turbo  2023-11-06   \n",
       "946        True    False      False       gpt-4o-2024-08-06  2024-08-06   \n",
       "979        True    False      False       gpt-4o-2024-11-20  2024-11-20   \n",
       "1060       True    False      False  gpt-4-turbo-2024-04-09  2024-04-09   \n",
       "\n",
       "                         source  \n",
       "252   Stanford CRFM Leaderboard  \n",
       "326   Stanford CRFM Leaderboard  \n",
       "550   Stanford CRFM Leaderboard  \n",
       "728      GPT-4 Technical Report  \n",
       "747   Stanford CRFM Leaderboard  \n",
       "946   Stanford CRFM Leaderboard  \n",
       "979      Phi-4 Technical Report  \n",
       "1060  Stanford CRFM Leaderboard  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df[scores_df['model'].str.contains('gpt-4') & (scores_df['benchmark'] == \"MMLU\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a1cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm1[['model', 'Model', 'date', 'estimated_capability']].to_csv('output/eci_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a73731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c20315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
