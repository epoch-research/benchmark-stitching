{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ea3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.5665e+01, final cost 3.4294e+00, first-order optimality 7.44e-04.\n",
      "GPT-3 (001): 0.999\n",
      "GPT-3 (002): 1.48\n",
      "GPT-4: 1.63\n",
      "o3: 2.64\n",
      "GPT-5: 2.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_loader_rescale import scores_df\n",
    "from fit import fit_statistical_model\n",
    "\n",
    "anchor_mode = \"benchmark\"\n",
    "\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 1\n",
    "anchor_slope = 1\n",
    "\n",
    "anchor_model1 = 'text-davinci-001', \n",
    "anchor_model1_capability = 1, \n",
    "anchor_model2 = 'gpt-4-0613',\n",
    "anchor_model2_capability = 1.2\n",
    "\n",
    "if anchor_mode == \"model\":\n",
    "    df1, df_cm1, df_db1 = fit_statistical_model(\n",
    "        scores_df, \n",
    "        anchor_mode=anchor_mode, \n",
    "        anchor_model1=anchor_model1,\n",
    "        anchor_model1_capability=anchor_model1_capability, \n",
    "        anchor_model2=anchor_model2,\n",
    "        anchor_model2_capability=anchor_model2_capability\n",
    "    )\n",
    "else:\n",
    "    df1, df_cm1, df_db1 = fit_statistical_model(\n",
    "        scores_df, \n",
    "        anchor_mode=anchor_mode, \n",
    "        anchor_benchmark=anchor_benchmark,\n",
    "        anchor_difficulty=anchor_difficulty,\n",
    "        anchor_slope=anchor_slope\n",
    "    )\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df_cm1['date_obj'] = pd.to_datetime(df_cm1['date'])\n",
    "\n",
    "gpt_3_001_score = df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['estimated_capability'].values[0]\n",
    "gpt_3_002_score = df_cm1[df_cm1['model'].str.contains('text-davinci-002')]['estimated_capability'].values[0]\n",
    "gpt_4_score = df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['estimated_capability'].values[0]\n",
    "gpt_5_score = df_cm1[df_cm1['model'].str.contains('gpt-5-2025-08-07_medium')]['estimated_capability'].values[0]\n",
    "o3_score = df_cm1[df_cm1['model'].str.contains('o3-2025-04-16_high')]['estimated_capability'].values[0]\n",
    "print(f\"GPT-3 (001): {gpt_3_001_score:.3}\")\n",
    "print(f\"GPT-3 (002): {gpt_3_002_score:.3}\")\n",
    "print(f\"GPT-4: {gpt_4_score:.3}\")\n",
    "print(f\"o3: {o3_score:.3}\")\n",
    "print(f\"GPT-5: {gpt_5_score:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6189e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model  estimated_capability\n",
      "32                      Qwen-1_8B              0.341581\n",
      "25             Baichuan-2-7B-Base              0.369050\n",
      "42                        phi-1_5              0.392430\n",
      "41                       gemma-2b              0.437605\n",
      "20                         mpt-7b              0.501528\n",
      "..                            ...                   ...\n",
      "106            o3-2025-04-16_high              2.636470\n",
      "0                     grok-4-0709              2.674136\n",
      "122  gemini-2.5-pro-preview-06-05              2.689337\n",
      "130         gpt-5-2025-08-07_high              2.817619\n",
      "128       gpt-5-2025-08-07_medium              2.858115\n",
      "\n",
      "[143 rows x 2 columns]\n",
      "Minimum capability: 0.342\n",
      "Maximum capability: 2.86\n",
      "\n",
      "GPT-4 jump: 0.635\n",
      "GPT-5 jump: 1.22\n"
     ]
    }
   ],
   "source": [
    "print(df_cm1[['model', 'estimated_capability']].sort_values('estimated_capability', ascending=True))\n",
    "\n",
    "print(f\"Minimum capability: {df_cm1['estimated_capability'].min():.3}\")\n",
    "print(f\"Maximum capability: {df_cm1['estimated_capability'].max():.3}\\n\")\n",
    "\n",
    "print(f\"GPT-4 jump: {gpt_4_score - gpt_3_001_score:.3}\")\n",
    "print(f\"GPT-5 jump: {gpt_5_score - gpt_4_score:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ad6ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ECI score scaling values\n",
    "gpt_3_fix_at = 100\n",
    "gpt_4_fix_at = 120\n",
    "gpt_3_4_ratio = gpt_3_001_score / gpt_4_score\n",
    "\n",
    "a = (gpt_4_fix_at * gpt_3_4_ratio - gpt_3_fix_at) / (gpt_3_4_ratio - 1)\n",
    "b = (gpt_3_fix_at - a) / gpt_3_001_score\n",
    "\n",
    "df_cm1['eci'] = a + b * df_cm1['estimated_capability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d9c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top-3 models ever: 33\n",
      "Number of unique ECIs among top-3 models: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "has_tie\n",
       "False    28\n",
       "True      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we check whether our scaling is going to produce a bunch of ties, especially for the top few models.\n",
    "def get_rank(\n",
    "    df: pd.DataFrame,\n",
    "    n: int | None = None,\n",
    "    sort_col: str = \"Publication date\",\n",
    "    val_col: str = \"Training compute (FLOP)\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cumulative rank of *val_col* up to each row, ordered by *sort_col*,\n",
    "    robust to missing values.\n",
    "\n",
    "    • If *val_col* is NaN for a row → rank is NaN.  \n",
    "    • Rows whose *val_col* is NaN do **not** affect later ranks.  \n",
    "    • Rows whose *sort_col* is NaN are treated as having unknown release time\n",
    "      → their own rank is NaN and they do not affect others.  \n",
    "    • If *n* is given, ranks > n are set to NaN (frontier filter).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series aligned with *df.index* (dtype float, so NaNs are allowed).\n",
    "    \"\"\"\n",
    "    # Sort chronologically; keep a stable sort to preserve original order ties\n",
    "    ordered = df.sort_values(\n",
    "        sort_col, kind=\"mergesort\", na_position=\"last\"\n",
    "    ).reset_index()\n",
    "\n",
    "    vals  = ordered[val_col]\n",
    "    ranks = pd.Series(np.nan, index=ordered.index, dtype=float)\n",
    "\n",
    "    # Working array of non-NaN values we have seen so far\n",
    "    seen = []\n",
    "\n",
    "    for idx, v in enumerate(vals):\n",
    "        if pd.isna(v):           # current value is NaN → leave rank as NaN\n",
    "            continue\n",
    "        # Count how many previous non-NaN values are strictly larger\n",
    "        rank = 1 + sum(prev > v for prev in seen)\n",
    "        ranks.iloc[idx] = rank\n",
    "        seen.append(v)           # add current value for future rows\n",
    "\n",
    "    if n is not None:\n",
    "        ranks = ranks.where(ranks <= n)\n",
    "\n",
    "    # Re-align to the original DataFrame’s index order\n",
    "    ranks.index = ordered[\"index\"]\n",
    "    return ranks.reindex(df.index)\n",
    "\n",
    "# Check the top 5 at each date, and count the number of time we get ties\n",
    "# We'll look at ECI rounded to the nearest integer\n",
    "df_cm1['eci_rounded'] = df_cm1['eci'].astype(int)\n",
    "df_cm1['rank'] = get_rank(df_cm1, sort_col='date', val_col='eci')\n",
    "\n",
    "N = 3\n",
    "topn_df = df_cm1[df_cm1['rank'] <= N].copy()\n",
    "print(f\"Number of top-{N} models ever: {len(topn_df)}\")\n",
    "print(f\"Number of unique ECIs among top-{N} models: {len(topn_df['eci_rounded'].unique())}\")\n",
    "\n",
    "# Create has_tie column - True if this row's eci_rounded value appears in other rows\n",
    "topn_df['has_tie'] = topn_df['eci_rounded'].duplicated(keep=False)\n",
    "topn_df['has_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1521bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top-3 models ever: 33\n",
      "Number of unique ECIs among top-3 models: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "has_tie\n",
       "False    28\n",
       "True      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we check whether our scaling is going to produce a bunch of ties, especially for the top few models.\n",
    "def get_rank(\n",
    "    df: pd.DataFrame,\n",
    "    n: int | None = None,\n",
    "    sort_col: str = \"Publication date\",\n",
    "    val_col: str = \"Training compute (FLOP)\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cumulative rank of *val_col* up to each row, ordered by *sort_col*,\n",
    "    robust to missing values.\n",
    "\n",
    "    • If *val_col* is NaN for a row → rank is NaN.  \n",
    "    • Rows whose *val_col* is NaN do **not** affect later ranks.  \n",
    "    • Rows whose *sort_col* is NaN are treated as having unknown release time\n",
    "      → their own rank is NaN and they do not affect others.  \n",
    "    • If *n* is given, ranks > n are set to NaN (frontier filter).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series aligned with *df.index* (dtype float, so NaNs are allowed).\n",
    "    \"\"\"\n",
    "    # Sort chronologically; keep a stable sort to preserve original order ties\n",
    "    ordered = df.sort_values(\n",
    "        sort_col, kind=\"mergesort\", na_position=\"last\"\n",
    "    ).reset_index()\n",
    "\n",
    "    vals  = ordered[val_col]\n",
    "    ranks = pd.Series(np.nan, index=ordered.index, dtype=float)\n",
    "\n",
    "    # Working array of non-NaN values we have seen so far\n",
    "    seen = []\n",
    "\n",
    "    for idx, v in enumerate(vals):\n",
    "        if pd.isna(v):           # current value is NaN → leave rank as NaN\n",
    "            continue\n",
    "        # Count how many previous non-NaN values are strictly larger\n",
    "        rank = 1 + sum(prev > v for prev in seen)\n",
    "        ranks.iloc[idx] = rank\n",
    "        seen.append(v)           # add current value for future rows\n",
    "\n",
    "    if n is not None:\n",
    "        ranks = ranks.where(ranks <= n)\n",
    "\n",
    "    # Re-align to the original DataFrame’s index order\n",
    "    ranks.index = ordered[\"index\"]\n",
    "    return ranks.reindex(df.index)\n",
    "\n",
    "# Check the top 5 at each date, and count the number of time we get ties\n",
    "# We'll look at ECI rounded to the nearest integer\n",
    "df_cm1['eci_rounded'] = df_cm1['eci'].astype(int)\n",
    "df_cm1['rank'] = get_rank(df_cm1, sort_col='date', val_col='eci')\n",
    "\n",
    "N = 3\n",
    "topn_df = df_cm1[df_cm1['rank'] <= N].copy()\n",
    "print(f\"Number of top-{N} models ever: {len(topn_df)}\")\n",
    "print(f\"Number of unique ECIs among top-{N} models: {len(topn_df['eci_rounded'].unique())}\")\n",
    "\n",
    "# Create has_tie column - True if this row's eci_rounded value appears in other rows\n",
    "topn_df['has_tie'] = topn_df['eci_rounded'].duplicated(keep=False)\n",
    "topn_df['has_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f98cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting, we'll join some metadata\n",
    "models_df = pd.read_csv('data/ai_models/all_ai_models.csv')\n",
    "versions_df = pd.read_csv('data/model_versions.csv')\n",
    "merged_df = df_cm1.merge(models_df, left_on='Model', right_on='Model')\n",
    "merged_df = merged_df.merge(versions_df[['id', 'Display name']], left_on='model', right_on='id')\n",
    "\n",
    "# Features\n",
    "accessibility_conditions = [\n",
    "    merged_df['Model accessibility'].isin([\n",
    "        'API access',\n",
    "        'Hosted access (no API)',\n",
    "        'Unreleased'\n",
    "    ]),\n",
    "    merged_df['Model accessibility'].isin([\n",
    "        'Open weights (unrestricted)',\n",
    "        'Open weights (restricted use)',\n",
    "        'Open weights (non-commercial)'\n",
    "    ])\n",
    "]\n",
    "accessibilities = ['Closed weights', 'Open weigh†s']\n",
    "merged_df['Accessibility group'] = np.select(accessibility_conditions, accessibilities, default='Other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de41d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "gpt-5-2025-08-07_medium"
          ],
          [
           "gpt-5-2025-08-07_high"
          ],
          [
           "gemini-2.5-pro-preview-06-05"
          ],
          [
           "grok-4-0709"
          ],
          [
           "o3-2025-04-16_high"
          ],
          [
           "gemini-2.5-pro-exp-03-25"
          ],
          [
           "o3-2025-04-16_medium"
          ],
          [
           "gemini-2.5-pro-preview-03-25"
          ],
          [
           "o1-2024-12-17_high"
          ],
          [
           "o3-mini-2025-01-31_high"
          ],
          [
           "o1-2024-12-17_medium"
          ],
          [
           "DeepSeek-R1"
          ],
          [
           "o1-mini-2024-09-12_high"
          ],
          [
           "o1-mini-2024-09-12_medium"
          ],
          [
           "o1-preview-2024-09-12"
          ],
          [
           "Llama-3.1-405B"
          ],
          [
           "claude-3-5-sonnet-20240620"
          ],
          [
           "gpt-4o-2024-08-06"
          ],
          [
           "gpt-4o-2024-05-13"
          ],
          [
           "gpt-4-turbo-2024-04-09"
          ],
          [
           "claude-3-opus-20240229"
          ],
          [
           "DeepSeek-V2"
          ],
          [
           "PaLM 540B"
          ],
          [
           "StableBeluga2"
          ],
          [
           "Inflection-1"
          ],
          [
           "claude-2.0"
          ],
          [
           "text-davinci-002"
          ],
          [
           "gpt-4-0613"
          ],
          [
           "PaLM 2-L"
          ],
          [
           "GLaM (MoE)"
          ],
          [
           "text-davinci-001"
          ],
          [
           "Megatron-Turing NLG 530B"
          ],
          [
           "Gopher (280B)"
          ]
         ],
         "hovertemplate": "date=%{x}<br>estimated_capability=%{y}<br>model=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2025-08-07",
          "2025-08-07",
          "2025-06-05",
          "2025-07-09",
          "2025-04-16",
          "2025-03-25",
          "2025-04-16",
          "2025-04-09",
          "2024-12-17",
          "2025-01-31",
          "2024-12-17",
          "2025-01-20",
          "2024-09-12",
          "2024-09-12",
          "2024-09-12",
          "2024-07-23",
          "2024-06-20",
          "2024-08-06",
          "2024-05-13",
          "2024-04-09",
          "2024-02-29",
          "2024-05-07",
          "2022-04-04",
          "2023-07-20",
          "2023-06-22",
          "2023-07-11",
          "2022-03-15",
          "2023-06-13",
          "2023-05-17",
          "2021-12-13",
          "2022-01-27",
          "2022-01-28",
          "2021-12-08"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "zkTOL3a9AkBs5siEiXICQJkzGjKgmgFAPsC/3TJ5AUDJzmpe0j0BQIW98yX4IwFA/lBOy7wWAUAsNVMtMT4AQLkKjcLAJgBAvet+7HgaAEBwYTyiKBcAQBaWxBFtmP4/7G6A4Dv8/T87ducqhhX9P+ddWFdGrfw/6U8ibFdU+j/c9t8nVNn5P0e9ghqtSPk/U2Gs/6vM+D9fgJCv42r4P15k85pT9fc/5MsaM2jf9z8Lycf6ZNf1P8EZzEIAuvQ/2HePELJh9D8ksB5Mswr0P2toH0HKyvM/MzMzMzMz8z8JoBRtf2zyP1yVcUgd8PE/AAAAAAAA8D8eAkOEVaDvPxyOa3TXA+o/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "estimated_capability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "px.scatter(\n",
    "    topn_df, \n",
    "    x='date', \n",
    "    y='estimated_capability', \n",
    "    # color='has_tie',\n",
    "    hover_data=['model', 'estimated_capability']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c20315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "export_df = merged_df[['model', 'Model', 'Display name', 'eci', 'date', 'Organization', 'Country (of organization)', 'Model accessibility']]\n",
    "export_df = export_df.rename(columns={\n",
    "    'model': 'model version'\n",
    "})\n",
    "\n",
    "export_df.to_csv('outputs/eci_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculates the sigmoid of the input x.\n",
    "    x can be a scalar or a NumPy array.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def implied_eci(ab, db, score):\n",
    "    return (db + (np.log(np.clip(score, 1e-12, 1-1e-12)) - np.log1p(-np.clip(score, 1e-12, 1-1e-12))) / ab)\n",
    "\n",
    "def implied_score(ab, cb, db):\n",
    "    return sigmoid(ab * (cb - db))\n",
    "\n",
    "palm_scores = scores_df[scores_df['model'] == 'PaLM 540B'][['benchmark', 'performance', 'model']]\n",
    "gpt4_scores = scores_df[scores_df['model'] == 'gpt-4-0613'][['benchmark', 'performance', 'model']]\n",
    "\n",
    "check_scores = pd.concat([palm_scores, gpt4_scores])\n",
    "\n",
    "compare_df = df_db1[df_db1['benchmark_name'].isin(check_scores['benchmark'].unique())]\n",
    "compare_df = compare_df.rename(columns={'benchmark_name': 'benchmark'})\n",
    "\n",
    "# Join score data to difficulty data\n",
    "compare_df = compare_df.merge(check_scores, on='benchmark')\n",
    "\n",
    "# Join eci data to difficulty data\n",
    "compare_df = compare_df.merge(df_cm1[['model', 'estimated_capability']], on='model')\n",
    "\n",
    "# Estimate implied ECI based on individual benchmarks\n",
    "compare_df['implied_eci'] = implied_eci(\n",
    "    ab = compare_df['estimated_slope'],\n",
    "    db = compare_df['estimated_difficulty'],\n",
    "    score = compare_df['performance']\n",
    ")\n",
    "compare_df['implied_performance'] = implied_score(\n",
    "  ab = compare_df['estimated_slope'],\n",
    "  cb = compare_df['estimated_capability'],\n",
    "  db = compare_df['estimated_difficulty']\n",
    ")\n",
    "\n",
    "compare_df[['model', 'implied_eci']].groupby('model').agg(geometric_mean=('implied_eci', gmean), arithmetic_mean=('implied_eci', 'mean'))\n",
    "\n",
    "imputations = {}\n",
    "\n",
    "for b in compare_df['benchmark'].unique():\n",
    "    imputations[b] = {}\n",
    "    for m in compare_df['model'].unique():\n",
    "        mask = (compare_df[\"model\"] == m) & (compare_df[\"benchmark\"] == b)\n",
    "        ab = compare_df.loc[compare_df['benchmark'] == b, 'estimated_slope'].iat[0]\n",
    "        db = compare_df.loc[compare_df['benchmark'] == b, 'estimated_difficulty'].iat[0]\n",
    "        if not mask.any():\n",
    "            cb = compare_df.loc[compare_df['model'] == m, 'estimated_capability'].iat[0]\n",
    "            imputed_score = implied_score(ab=ab, cb=cb, db=db)\n",
    "            imputations[b][m] = {\n",
    "              'score': f\"{imputed_score:.3}*\",\n",
    "              'eci': f\"{cb:.3}\"\n",
    "            }\n",
    "        else:\n",
    "            score = compare_df.loc[\n",
    "                (compare_df['model'] == m) & (compare_df['benchmark'] == b),\n",
    "                'performance'\n",
    "            ].iat[0]\n",
    "            imputed_eci = implied_eci(ab=ab, db=db, score=score)\n",
    "            imputations[b][m] = {\n",
    "              'score': f\"{score:.3}\",\n",
    "              'eci': f\"{imputed_eci:.3}*\"\n",
    "            }\n",
    "\n",
    "# Flatten the nested dict into a dataframe\n",
    "imputations_df = (\n",
    "    pd.concat(\n",
    "        {\n",
    "            b: pd.DataFrame.from_dict(m_dict, orient=\"index\")\n",
    "            for b, m_dict in imputations.items()\n",
    "        },\n",
    "        names=[\"benchmark\", \"model\"]\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "imputations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pair_tables(\n",
    "    df: pd.DataFrame,\n",
    "    model_a: str = \"GPT-4\",\n",
    "    model_b: str = \"PaLM 540B\",\n",
    "    score_col: str = \"performance\",\n",
    "    eci_col: str = \"estimated_capability\",\n",
    "    slope_col: str = \"estimated_slope\",\n",
    "    diff_col: str = \"estimated_difficulty\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Build two tidy tables for a model pair:\n",
    "      1) scores_tbl: compare actual score of one model vs imputed score of the other\n",
    "      2) eci_tbl:    compare implied ECI (from score) of one model vs baseline ECI of the other\n",
    "\n",
    "    Imputation rules:\n",
    "      - Imputed SCORE for a missing (model, benchmark) = implied_score(ab, cb, db)\n",
    "          where ab,db are benchmark params, cb is the model's baseline ECI.\n",
    "      - Implied ECI for a present (model, benchmark) = implied_eci(ab, db, score).\n",
    "    \"\"\"\n",
    "    # --- Canonical inputs ---\n",
    "    models = [model_a, model_b]\n",
    "\n",
    "    # One row per benchmark for params\n",
    "    bench_params = (\n",
    "        df[[\"benchmark\", slope_col, diff_col]]\n",
    "        .drop_duplicates(subset=[\"benchmark\"])\n",
    "    )\n",
    "\n",
    "    # One ECI per model (assumed global; take first if duplicated)\n",
    "    model_eci = (\n",
    "        df[[\"model\", eci_col]]\n",
    "        .dropna(subset=[eci_col])\n",
    "        .drop_duplicates(subset=[\"model\"])\n",
    "        .set_index(\"model\")[eci_col]\n",
    "    )\n",
    "\n",
    "    # All (benchmark × models-of-interest) pairs\n",
    "    grid = (\n",
    "        df[[\"benchmark\"]].drop_duplicates()\n",
    "        .assign(_k=1)\n",
    "        .merge(pd.DataFrame({\"model\": models, \"_k\": 1}), on=\"_k\")\n",
    "        .drop(columns=\"_k\")\n",
    "    )\n",
    "\n",
    "    # Attach actual scores (take first if duplicated)\n",
    "    actual_scores = (\n",
    "        df[[\"benchmark\", \"model\", score_col]]\n",
    "        .drop_duplicates(subset=[\"benchmark\", \"model\"])\n",
    "    )\n",
    "\n",
    "    out = (grid\n",
    "           .merge(actual_scores, how=\"left\", on=[\"benchmark\", \"model\"])\n",
    "           .merge(bench_params, how=\"left\", on=\"benchmark\"))\n",
    "\n",
    "    # Attach baseline ECI per model\n",
    "    out[eci_col] = out[\"model\"].map(model_eci)\n",
    "\n",
    "    # Compute imputed score (only when score is missing)\n",
    "    out[\"imputed_score\"] = out.apply(\n",
    "        lambda r: implied_score(ab=r[slope_col], cb=r[eci_col], db=r[diff_col])\n",
    "        if pd.isna(r[score_col]) and pd.notna(r[eci_col]) and pd.notna(r[slope_col]) and pd.notna(r[diff_col])\n",
    "        else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Compute implied ECI from score (only when score is present)\n",
    "    out[\"implied_eci\"] = out.apply(\n",
    "        lambda r: implied_eci(ab=r[slope_col], db=r[diff_col], score=r[score_col])\n",
    "        if pd.notna(r[score_col]) and pd.notna(r[slope_col]) and pd.notna(r[diff_col])\n",
    "        else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Wide for easy pair picking\n",
    "    wide = out.pivot(index=\"benchmark\", columns=\"model\")\n",
    "\n",
    "    # Helper selectors\n",
    "    sA = wide[(score_col, model_a)]\n",
    "    sB = wide[(score_col, model_b)]\n",
    "    impA = wide[(\"imputed_score\", model_a)]\n",
    "    impB = wide[(\"imputed_score\", model_b)]\n",
    "    eciA = wide[(eci_col, model_a)]\n",
    "    eciB = wide[(eci_col, model_b)]\n",
    "    impECIA = wide[(\"implied_eci\", model_a)]\n",
    "    impECIB = wide[(\"implied_eci\", model_b)]\n",
    "\n",
    "    # ---- SCORES table ----\n",
    "    # Cases: A has actual & B missing → compare A_actual vs B_imputed\n",
    "    scores_A_vs_B = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_a}_actual\": sA,\n",
    "            f\"{model_b}_imputed\": impB,\n",
    "        })\n",
    "        .loc[sA.notna() & sB.isna()]\n",
    "        .assign(direction=f\"{model_a} actual vs {model_b} imputed\")\n",
    "    )\n",
    "\n",
    "    # Cases: B has actual & A missing → compare B_actual vs A_imputed\n",
    "    scores_B_vs_A = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_b}_actual\": sB,\n",
    "            f\"{model_a}_imputed\": impA,\n",
    "        })\n",
    "        .loc[sB.notna() & sA.isna()]\n",
    "        .assign(direction=f\"{model_b} actual vs {model_a} imputed\")\n",
    "    )\n",
    "\n",
    "    # Combine to one tidy scores table; add delta for convenience\n",
    "    scores_tbl = pd.concat([scores_A_vs_B, scores_B_vs_A], ignore_index=True)\n",
    "    if f\"{model_a}_actual\" in scores_tbl and f\"{model_b}_imputed\" in scores_tbl:\n",
    "        scores_tbl[\"delta\"] = scores_tbl.get(f\"{model_a}_actual\") - scores_tbl.get(f\"{model_b}_imputed\")\n",
    "    if f\"{model_b}_actual\" in scores_tbl and f\"{model_a}_imputed\" in scores_tbl:\n",
    "        scores_tbl[\"delta\"] = scores_tbl.get(f\"{model_b}_actual\").fillna(scores_tbl.get(f\"{model_a}_actual\")) - \\\n",
    "                              scores_tbl.get(f\"{model_a}_imputed\").fillna(scores_tbl.get(f\"{model_b}_imputed\"))\n",
    "\n",
    "    # ---- ECI table ----\n",
    "    # Cases: A has score (so we have A implied_eci) & B missing score (so use B baseline ECI)\n",
    "    eci_A_vs_B = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_a}_eci_from_score\": impECIA,\n",
    "            f\"{model_b}_baseline_eci\": eciB,\n",
    "        })\n",
    "        .loc[sA.notna() & sB.isna()]\n",
    "        .assign(direction=f\"{model_a} implied ECI vs {model_b} baseline ECI\")\n",
    "    )\n",
    "\n",
    "    # Cases: B has score & A missing score\n",
    "    eci_B_vs_A = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_b}_eci_from_score\": impECIB,\n",
    "            f\"{model_a}_baseline_eci\": eciA,\n",
    "        })\n",
    "        .loc[sB.notna() & sA.isna()]\n",
    "        .assign(direction=f\"{model_b} implied ECI vs {model_a} baseline ECI\")\n",
    "    )\n",
    "\n",
    "    eci_tbl = pd.concat([eci_A_vs_B, eci_B_vs_A], ignore_index=True)\n",
    "\n",
    "    # Optional: standardize column order a bit\n",
    "    def order_cols(df):\n",
    "        first = [\"benchmark\", \"direction\"]\n",
    "        rest = [c for c in df.columns if c not in first]\n",
    "        return df[first + rest]\n",
    "\n",
    "    return order_cols(scores_tbl), order_cols(eci_tbl)\n",
    "\n",
    "scores_tbl, eci_tbl = pair_tables(compare_df, model_a=\"gpt-4-0613\", model_b=\"PaLM 540B\")\n",
    "eci_tbl.drop(columns='direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data: decimal year from benchmark_release_date\n",
    "_df = df_db1.copy()\n",
    "_df['benchmark_release_date'] = pd.to_datetime(_df['benchmark_release_date'], errors='coerce')\n",
    "\n",
    "# Compute decimal year: year + (day_of_year - 1) / days_in_year\n",
    "_days_in_year = np.where(_df['benchmark_release_date'].dt.is_leap_year, 366, 365)\n",
    "_df['decimal_year'] = (\n",
    "    _df['benchmark_release_date'].dt.year +\n",
    "    (_df['benchmark_release_date'].dt.dayofyear - 1) / _days_in_year\n",
    ")\n",
    "\n",
    "# Drop rows with missing values needed for regression\n",
    "_reg = _df.dropna(subset=['decimal_year', 'estimated_slope'])\n",
    "\n",
    "x = _reg['decimal_year'].to_numpy()\n",
    "y = _reg['estimated_slope'].to_numpy()\n",
    "\n",
    "# Simple linear regression (y = a*x + b)\n",
    "coef, intercept = np.polyfit(x, y, 1)\n",
    "print(f\"Coefficient (estimated_slope ~ decimal_year): {coef:.6f}\")\n",
    "print(f\"Intercept: {intercept:.6f}\")\n",
    "\n",
    "# Optional: show a quick sanity summary\n",
    "print(f\"N used: {len(_reg)} | date range: {pd.to_datetime(_reg['benchmark_release_date']).min().date()} → {pd.to_datetime(_reg['benchmark_release_date']).max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv('outputs/input_scores.csv')\n",
    "df_cm1.to_csv('outputs/model_capabilities.csv')\n",
    "df_db1.to_csv('outputs/benchmark_difficulties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e843b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import benchmarks, df_fiction, df_factorio\n",
    "pd.concat(benchmarks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab262fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[scores_df['performance'] <0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39aa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
