{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ea3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null performances after coercion: 295\n",
      "after saturation filter 1905\n",
      "after filter num benchmarks 1090\n",
      "after merge with model versions 1086\n",
      "after merge with benchmark dates 1086\n",
      "Original number of rows: 1086\n",
      "Number of rows after aggregation: 878\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 37, initial cost 3.3276e+01, final cost 2.4235e+00, first-order optimality 2.98e-04.\n",
      "GPT-3 (001): 0.944\n",
      "GPT-3 (002): 1.49\n",
      "GPT-4: 1.64\n",
      "o3: 2.72\n",
      "GPT-5: 3.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_loader import scores_df\n",
    "from fit import fit_statistical_model\n",
    "\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 0\n",
    "anchor_slope = 1\n",
    "\n",
    "# # TEMP TESTING\n",
    "# # Drop all PaLM scores except the OpenBookQA one\n",
    "# scores_df = scores_df.loc[\n",
    "#     ~(scores_df['model'].eq('PaLM 540B') & scores_df['benchmark'].eq('OpenBookQA'))\n",
    "# ].reset_index(drop=True)\n",
    "# # END TEMP\n",
    "\n",
    "\n",
    "df1, df_cm1, df_db1 = fit_statistical_model(\n",
    "    scores_df, \n",
    "    anchor_mode=\"benchmark\", \n",
    "    anchor_benchmark=anchor_benchmark, \n",
    "    anchor_difficulty=anchor_difficulty, \n",
    "    anchor_slope=anchor_slope)\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df_cm1['date_obj'] = pd.to_datetime(df_cm1['date'])\n",
    "\n",
    "gpt_3_001_score = df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['estimated_capability'].values[0]\n",
    "gpt_3_002_score = df_cm1[df_cm1['model'].str.contains('text-davinci-002')]['estimated_capability'].values[0]\n",
    "gpt_4_score = df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['estimated_capability'].values[0]\n",
    "gpt_5_score = df_cm1[df_cm1['model'].str.contains('gpt-5-2025-08-07_medium')]['estimated_capability'].values[0]\n",
    "o3_score = df_cm1[df_cm1['model'].str.contains('o3-2025-04-16_high')]['estimated_capability'].values[0]\n",
    "print(f\"GPT-3 (001): {gpt_3_001_score:.3}\")\n",
    "print(f\"GPT-3 (002): {gpt_3_002_score:.3}\")\n",
    "print(f\"GPT-4: {gpt_4_score:.3}\")\n",
    "print(f\"o3: {o3_score:.3}\")\n",
    "print(f\"GPT-5: {gpt_5_score:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb5cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3: 100.0\n",
      "GPT-4: 120.0\n"
     ]
    }
   ],
   "source": [
    "gpt_3_to_4_gap = 20\n",
    "gpt_3_fixed_score = 100\n",
    "\n",
    "b = gpt_3_to_4_gap / (gpt_4_score - gpt_3_001_score)\n",
    "a = 100 - gpt_3_001_score * b\n",
    "\n",
    "df_cm1['eci'] = a + b * df_cm1['estimated_capability']\n",
    "\n",
    "print(f\"GPT-3: {df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['eci'].values[0]}\")\n",
    "print(f\"GPT-4: {df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['eci'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b78a5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top-3 models ever: 33\n",
      "Number of unique ECIs among top-3 models: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "has_tie\n",
       "False    18\n",
       "True     15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we check whether our scaling is going to produce a bunch of ties, especially for the top few models.\n",
    "def get_rank(\n",
    "    df: pd.DataFrame,\n",
    "    n: int | None = None,\n",
    "    sort_col: str = \"Publication date\",\n",
    "    val_col: str = \"Training compute (FLOP)\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cumulative rank of *val_col* up to each row, ordered by *sort_col*,\n",
    "    robust to missing values.\n",
    "\n",
    "    • If *val_col* is NaN for a row → rank is NaN.  \n",
    "    • Rows whose *val_col* is NaN do **not** affect later ranks.  \n",
    "    • Rows whose *sort_col* is NaN are treated as having unknown release time\n",
    "      → their own rank is NaN and they do not affect others.  \n",
    "    • If *n* is given, ranks > n are set to NaN (frontier filter).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series aligned with *df.index* (dtype float, so NaNs are allowed).\n",
    "    \"\"\"\n",
    "    # Sort chronologically; keep a stable sort to preserve original order ties\n",
    "    ordered = df.sort_values(\n",
    "        sort_col, kind=\"mergesort\", na_position=\"last\"\n",
    "    ).reset_index()\n",
    "\n",
    "    vals  = ordered[val_col]\n",
    "    ranks = pd.Series(np.nan, index=ordered.index, dtype=float)\n",
    "\n",
    "    # Working array of non-NaN values we have seen so far\n",
    "    seen = []\n",
    "\n",
    "    for idx, v in enumerate(vals):\n",
    "        if pd.isna(v):           # current value is NaN → leave rank as NaN\n",
    "            continue\n",
    "        # Count how many previous non-NaN values are strictly larger\n",
    "        rank = 1 + sum(prev > v for prev in seen)\n",
    "        ranks.iloc[idx] = rank\n",
    "        seen.append(v)           # add current value for future rows\n",
    "\n",
    "    if n is not None:\n",
    "        ranks = ranks.where(ranks <= n)\n",
    "\n",
    "    # Re-align to the original DataFrame’s index order\n",
    "    ranks.index = ordered[\"index\"]\n",
    "    return ranks.reindex(df.index)\n",
    "\n",
    "# Check the top 5 at each date, and count the number of time we get ties\n",
    "# We'll look at ECI rounded to the nearest integer\n",
    "df_cm1['eci_rounded'] = df_cm1['eci'].astype(int)\n",
    "df_cm1['rank'] = get_rank(df_cm1, sort_col='date', val_col='eci')\n",
    "\n",
    "N = 3\n",
    "topn_df = df_cm1[df_cm1['rank'] <= N].copy()\n",
    "print(f\"Number of top-{N} models ever: {len(topn_df)}\")\n",
    "print(f\"Number of unique ECIs among top-{N} models: {len(topn_df['eci_rounded'].unique())}\")\n",
    "\n",
    "# Create has_tie column - True if this row's eci_rounded value appears in other rows\n",
    "topn_df['has_tie'] = topn_df['eci_rounded'].duplicated(keep=False)\n",
    "topn_df['has_tie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f98cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting, we'll join some metadata\n",
    "models_df = pd.read_csv('data/ai_models/all_ai_models.csv')\n",
    "versions_df = pd.read_csv('data/model_versions.csv')\n",
    "merged_df = df_cm1.merge(models_df, left_on='Model', right_on='Model')\n",
    "merged_df = merged_df.merge(versions_df[['id', 'Display name']], left_on='model', right_on='id')\n",
    "\n",
    "# Features\n",
    "accessibility_conditions = [\n",
    "    merged_df['Model accessibility'].isin([\n",
    "        'API access',\n",
    "        'Hosted access (no API)',\n",
    "        'Unreleased'\n",
    "    ]),\n",
    "    merged_df['Model accessibility'].isin([\n",
    "        'Open weights (unrestricted)',\n",
    "        'Open weights (restricted use)',\n",
    "        'Open weights (non-commercial)'\n",
    "    ])\n",
    "]\n",
    "accessibilities = ['Closed weights', 'Open weigh†s']\n",
    "merged_df['Accessibility group'] = np.select(accessibility_conditions, accessibilities, default='Other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de41d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "gpt-5-2025-08-07_medium"
          ],
          [
           "gpt-5-2025-08-07_high"
          ],
          [
           "gemini-2.5-pro-preview-06-05"
          ],
          [
           "grok-4-0709"
          ],
          [
           "o3-2025-04-16_high"
          ],
          [
           "gemini-2.5-pro-exp-03-25"
          ],
          [
           "o3-2025-04-16_medium"
          ],
          [
           "gemini-2.5-pro-preview-03-25"
          ],
          [
           "o1-2024-12-17_high"
          ],
          [
           "o3-mini-2025-01-31_high"
          ],
          [
           "o1-2024-12-17_medium"
          ],
          [
           "DeepSeek-R1"
          ],
          [
           "o1-mini-2024-09-12_high"
          ],
          [
           "o1-mini-2024-09-12_medium"
          ],
          [
           "o1-preview-2024-09-12"
          ],
          [
           "claude-3-5-sonnet-20240620"
          ],
          [
           "Llama-3.1-405B"
          ],
          [
           "gpt-4o-2024-08-06"
          ],
          [
           "gpt-4o-2024-05-13"
          ],
          [
           "gpt-4-turbo-2024-04-09"
          ],
          [
           "gemini-1.5-pro-001"
          ],
          [
           "claude-3-opus-20240229"
          ],
          [
           "DeepSeek-V2"
          ],
          [
           "Meta-Llama-3-70B-Instruct"
          ],
          [
           "PaLM 540B"
          ],
          [
           "gpt-4-0613"
          ],
          [
           "StableBeluga2"
          ],
          [
           "claude-2.0"
          ],
          [
           "text-davinci-002"
          ],
          [
           "PaLM 2-L"
          ],
          [
           "GLaM (MoE)"
          ],
          [
           "Gopher (280B)"
          ],
          [
           "text-davinci-001"
          ]
         ],
         "hovertemplate": "date=%{x}<br>estimated_capability=%{y}<br>model=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2025-08-07",
          "2025-08-07",
          "2025-06-05",
          "2025-07-09",
          "2025-04-16",
          "2025-03-25",
          "2025-04-16",
          "2025-04-09",
          "2024-12-17",
          "2025-01-31",
          "2024-12-17",
          "2025-01-20",
          "2024-09-12",
          "2024-09-12",
          "2024-09-12",
          "2024-06-20",
          "2024-07-23",
          "2024-08-06",
          "2024-05-13",
          "2024-04-09",
          "2024-05-24",
          "2024-02-29",
          "2024-05-07",
          "2024-04-18",
          "2022-04-04",
          "2023-06-13",
          "2023-07-20",
          "2023-07-11",
          "2022-03-15",
          "2023-05-17",
          "2021-12-13",
          "2021-12-08",
          "2022-01-27"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "OPokHd8QCEBE25RxVqIHQONvBYLyXAZA6XBUx7wYBkAeA21TkMsFQHvqawDCnQVAJ9RRUweRBUCIAY3ygXMEQPHQ4xbQWgRAQelL0uVPBEB3OQRWE0gEQPL2U+CZMgNAefJGkR7pAkD3l4x/w2wCQHJPa3BGIgJAZ7SeEN0JAECBPmArVPX/P/OJpRDoS/8/z0W6iAb9/j/hFZ25U3f+Pyev/lJUZ/0/DpMBJQRQ/T+ncrq3rf78P0iveMIHdPo/Ux6kojpm+j9kmix29U76P17r/K14PPk/5VMqGssI+T/a89Evsd73Py5WuHkG2fU/v1hL7U7F9T9yao+wxefwP2NZc8tiMu4/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "estimated_capability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "px.scatter(\n",
    "    topn_df, \n",
    "    x='date', \n",
    "    y='estimated_capability', \n",
    "    # color='has_tie',\n",
    "    hover_data=['model', 'estimated_capability']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c20315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "export_df = merged_df[['model', 'Model', 'Display name', 'eci', 'date', 'Organization', 'Country (of organization)', 'Model accessibility']]\n",
    "export_df = export_df.rename(columns={\n",
    "    'model': 'model version'\n",
    "})\n",
    "\n",
    "export_df.to_csv('output/eci_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeda9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculates the sigmoid of the input x.\n",
    "    x can be a scalar or a NumPy array.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def implied_eci(ab, db, score):\n",
    "    return (db + (np.log(np.clip(score, 1e-12, 1-1e-12)) - np.log1p(-np.clip(score, 1e-12, 1-1e-12))) / ab)\n",
    "\n",
    "def implied_score(ab, cb, db):\n",
    "    return sigmoid(ab * (cb - db))\n",
    "\n",
    "palm_scores = scores_df[scores_df['model'] == 'PaLM 540B'][['benchmark', 'performance', 'model']]\n",
    "gpt4_scores = scores_df[scores_df['model'] == 'gpt-4-0613'][['benchmark', 'performance', 'model']]\n",
    "\n",
    "check_scores = pd.concat([palm_scores, gpt4_scores])\n",
    "\n",
    "compare_df = df_db1[df_db1['benchmark_name'].isin(check_scores['benchmark'].unique())]\n",
    "compare_df = compare_df.rename(columns={'benchmark_name': 'benchmark'})\n",
    "\n",
    "# Join score data to difficulty data\n",
    "compare_df = compare_df.merge(check_scores, on='benchmark')\n",
    "\n",
    "# Join eci data to difficulty data\n",
    "compare_df = compare_df.merge(df_cm1[['model', 'estimated_capability']], on='model')\n",
    "\n",
    "# Estimate implied ECI based on individual benchmarks\n",
    "compare_df['implied_eci'] = implied_eci(\n",
    "    ab = compare_df['estimated_slope'],\n",
    "    db = compare_df['estimated_difficulty'],\n",
    "    score = compare_df['performance']\n",
    ")\n",
    "compare_df['implied_performance'] = implied_score(\n",
    "  ab = compare_df['estimated_slope'],\n",
    "  cb = compare_df['estimated_capability'],\n",
    "  db = compare_df['estimated_difficulty']\n",
    ")\n",
    "\n",
    "compare_df[['model', 'implied_eci']].groupby('model').agg(geometric_mean=('implied_eci', gmean), arithmetic_mean=('implied_eci', 'mean'))\n",
    "\n",
    "imputations = {}\n",
    "\n",
    "for b in compare_df['benchmark'].unique():\n",
    "    imputations[b] = {}\n",
    "    for m in compare_df['model'].unique():\n",
    "        mask = (compare_df[\"model\"] == m) & (compare_df[\"benchmark\"] == b)\n",
    "        ab = compare_df.loc[compare_df['benchmark'] == b, 'estimated_slope'].iat[0]\n",
    "        db = compare_df.loc[compare_df['benchmark'] == b, 'estimated_difficulty'].iat[0]\n",
    "        if not mask.any():\n",
    "            cb = compare_df.loc[compare_df['model'] == m, 'estimated_capability'].iat[0]\n",
    "            imputed_score = implied_score(ab=ab, cb=cb, db=db)\n",
    "            imputations[b][m] = {\n",
    "              'score': f\"{imputed_score:.3}*\",\n",
    "              'eci': f\"{cb:.3}\"\n",
    "            }\n",
    "        else:\n",
    "            score = compare_df.loc[\n",
    "                (compare_df['model'] == m) & (compare_df['benchmark'] == b),\n",
    "                'performance'\n",
    "            ].iat[0]\n",
    "            imputed_eci = implied_eci(ab=ab, db=db, score=score)\n",
    "            imputations[b][m] = {\n",
    "              'score': f\"{score:.3}\",\n",
    "              'eci': f\"{imputed_eci:.3}*\"\n",
    "            }\n",
    "\n",
    "# Flatten the nested dict into a dataframe\n",
    "imputations_df = (\n",
    "    pd.concat(\n",
    "        {\n",
    "            b: pd.DataFrame.from_dict(m_dict, orient=\"index\")\n",
    "            for b, m_dict in imputations.items()\n",
    "        },\n",
    "        names=[\"benchmark\", \"model\"]\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff63db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>eci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1.49*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.857*</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.851</td>\n",
       "      <td>1.74*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.838*</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.814</td>\n",
       "      <td>2.01*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.848</td>\n",
       "      <td>2.33*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BoolQ</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1.52*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BoolQ</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.904*</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OpenBookQA</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.36*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OpenBookQA</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.622*</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARC AI2</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.852</td>\n",
       "      <td>1.55*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ARC AI2</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.881*</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MMLU</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.76*</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MMLU</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.824</td>\n",
       "      <td>1.89*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MATH level 5</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.25*</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MATH level 5</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.62*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GPQA diamond</td>\n",
       "      <td>PaLM 540B</td>\n",
       "      <td>0.353*</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GPQA diamond</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.54*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       benchmark       model   score    eci\n",
       "0      HellaSwag   PaLM 540B   0.838  1.49*\n",
       "1      HellaSwag  gpt-4-0613  0.857*   1.64\n",
       "2     Winogrande   PaLM 540B   0.851  1.74*\n",
       "3     Winogrande  gpt-4-0613  0.838*   1.64\n",
       "4       TriviaQA   PaLM 540B   0.814  2.01*\n",
       "5       TriviaQA  gpt-4-0613   0.848  2.33*\n",
       "6          BoolQ   PaLM 540B   0.887  1.52*\n",
       "7          BoolQ  gpt-4-0613  0.904*   1.64\n",
       "8     OpenBookQA   PaLM 540B    0.68  2.36*\n",
       "9     OpenBookQA  gpt-4-0613  0.622*   1.64\n",
       "10       ARC AI2   PaLM 540B   0.852  1.55*\n",
       "11       ARC AI2  gpt-4-0613  0.881*   1.64\n",
       "12          MMLU   PaLM 540B   0.76*   1.65\n",
       "13          MMLU  gpt-4-0613   0.824  1.89*\n",
       "14  MATH level 5   PaLM 540B   0.25*   1.65\n",
       "15  MATH level 5  gpt-4-0613    0.23  1.62*\n",
       "16  GPQA diamond   PaLM 540B  0.353*   1.65\n",
       "17  GPQA diamond  gpt-4-0613   0.307  1.54*"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c6d9186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pair_tables(\n",
    "    df: pd.DataFrame,\n",
    "    model_a: str = \"GPT-4\",\n",
    "    model_b: str = \"PaLM 540B\",\n",
    "    score_col: str = \"performance\",\n",
    "    eci_col: str = \"estimated_capability\",\n",
    "    slope_col: str = \"estimated_slope\",\n",
    "    diff_col: str = \"estimated_difficulty\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Build two tidy tables for a model pair:\n",
    "      1) scores_tbl: compare actual score of one model vs imputed score of the other\n",
    "      2) eci_tbl:    compare implied ECI (from score) of one model vs baseline ECI of the other\n",
    "\n",
    "    Imputation rules:\n",
    "      - Imputed SCORE for a missing (model, benchmark) = implied_score(ab, cb, db)\n",
    "          where ab,db are benchmark params, cb is the model's baseline ECI.\n",
    "      - Implied ECI for a present (model, benchmark) = implied_eci(ab, db, score).\n",
    "    \"\"\"\n",
    "    # --- Canonical inputs ---\n",
    "    models = [model_a, model_b]\n",
    "\n",
    "    # One row per benchmark for params\n",
    "    bench_params = (\n",
    "        df[[\"benchmark\", slope_col, diff_col]]\n",
    "        .drop_duplicates(subset=[\"benchmark\"])\n",
    "    )\n",
    "\n",
    "    # One ECI per model (assumed global; take first if duplicated)\n",
    "    model_eci = (\n",
    "        df[[\"model\", eci_col]]\n",
    "        .dropna(subset=[eci_col])\n",
    "        .drop_duplicates(subset=[\"model\"])\n",
    "        .set_index(\"model\")[eci_col]\n",
    "    )\n",
    "\n",
    "    # All (benchmark × models-of-interest) pairs\n",
    "    grid = (\n",
    "        df[[\"benchmark\"]].drop_duplicates()\n",
    "        .assign(_k=1)\n",
    "        .merge(pd.DataFrame({\"model\": models, \"_k\": 1}), on=\"_k\")\n",
    "        .drop(columns=\"_k\")\n",
    "    )\n",
    "\n",
    "    # Attach actual scores (take first if duplicated)\n",
    "    actual_scores = (\n",
    "        df[[\"benchmark\", \"model\", score_col]]\n",
    "        .drop_duplicates(subset=[\"benchmark\", \"model\"])\n",
    "    )\n",
    "\n",
    "    out = (grid\n",
    "           .merge(actual_scores, how=\"left\", on=[\"benchmark\", \"model\"])\n",
    "           .merge(bench_params, how=\"left\", on=\"benchmark\"))\n",
    "\n",
    "    # Attach baseline ECI per model\n",
    "    out[eci_col] = out[\"model\"].map(model_eci)\n",
    "\n",
    "    # Compute imputed score (only when score is missing)\n",
    "    out[\"imputed_score\"] = out.apply(\n",
    "        lambda r: implied_score(ab=r[slope_col], cb=r[eci_col], db=r[diff_col])\n",
    "        if pd.isna(r[score_col]) and pd.notna(r[eci_col]) and pd.notna(r[slope_col]) and pd.notna(r[diff_col])\n",
    "        else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Compute implied ECI from score (only when score is present)\n",
    "    out[\"implied_eci\"] = out.apply(\n",
    "        lambda r: implied_eci(ab=r[slope_col], db=r[diff_col], score=r[score_col])\n",
    "        if pd.notna(r[score_col]) and pd.notna(r[slope_col]) and pd.notna(r[diff_col])\n",
    "        else np.nan,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Wide for easy pair picking\n",
    "    wide = out.pivot(index=\"benchmark\", columns=\"model\")\n",
    "\n",
    "    # Helper selectors\n",
    "    sA = wide[(score_col, model_a)]\n",
    "    sB = wide[(score_col, model_b)]\n",
    "    impA = wide[(\"imputed_score\", model_a)]\n",
    "    impB = wide[(\"imputed_score\", model_b)]\n",
    "    eciA = wide[(eci_col, model_a)]\n",
    "    eciB = wide[(eci_col, model_b)]\n",
    "    impECIA = wide[(\"implied_eci\", model_a)]\n",
    "    impECIB = wide[(\"implied_eci\", model_b)]\n",
    "\n",
    "    # ---- SCORES table ----\n",
    "    # Cases: A has actual & B missing → compare A_actual vs B_imputed\n",
    "    scores_A_vs_B = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_a}_actual\": sA,\n",
    "            f\"{model_b}_imputed\": impB,\n",
    "        })\n",
    "        .loc[sA.notna() & sB.isna()]\n",
    "        .assign(direction=f\"{model_a} actual vs {model_b} imputed\")\n",
    "    )\n",
    "\n",
    "    # Cases: B has actual & A missing → compare B_actual vs A_imputed\n",
    "    scores_B_vs_A = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_b}_actual\": sB,\n",
    "            f\"{model_a}_imputed\": impA,\n",
    "        })\n",
    "        .loc[sB.notna() & sA.isna()]\n",
    "        .assign(direction=f\"{model_b} actual vs {model_a} imputed\")\n",
    "    )\n",
    "\n",
    "    # Combine to one tidy scores table; add delta for convenience\n",
    "    scores_tbl = pd.concat([scores_A_vs_B, scores_B_vs_A], ignore_index=True)\n",
    "    if f\"{model_a}_actual\" in scores_tbl and f\"{model_b}_imputed\" in scores_tbl:\n",
    "        scores_tbl[\"delta\"] = scores_tbl.get(f\"{model_a}_actual\") - scores_tbl.get(f\"{model_b}_imputed\")\n",
    "    if f\"{model_b}_actual\" in scores_tbl and f\"{model_a}_imputed\" in scores_tbl:\n",
    "        scores_tbl[\"delta\"] = scores_tbl.get(f\"{model_b}_actual\").fillna(scores_tbl.get(f\"{model_a}_actual\")) - \\\n",
    "                              scores_tbl.get(f\"{model_a}_imputed\").fillna(scores_tbl.get(f\"{model_b}_imputed\"))\n",
    "\n",
    "    # ---- ECI table ----\n",
    "    # Cases: A has score (so we have A implied_eci) & B missing score (so use B baseline ECI)\n",
    "    eci_A_vs_B = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_a}_eci_from_score\": impECIA,\n",
    "            f\"{model_b}_baseline_eci\": eciB,\n",
    "        })\n",
    "        .loc[sA.notna() & sB.isna()]\n",
    "        .assign(direction=f\"{model_a} implied ECI vs {model_b} baseline ECI\")\n",
    "    )\n",
    "\n",
    "    # Cases: B has score & A missing score\n",
    "    eci_B_vs_A = (\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": wide.index,\n",
    "            f\"{model_b}_eci_from_score\": impECIB,\n",
    "            f\"{model_a}_baseline_eci\": eciA,\n",
    "        })\n",
    "        .loc[sB.notna() & sA.isna()]\n",
    "        .assign(direction=f\"{model_b} implied ECI vs {model_a} baseline ECI\")\n",
    "    )\n",
    "\n",
    "    eci_tbl = pd.concat([eci_A_vs_B, eci_B_vs_A], ignore_index=True)\n",
    "\n",
    "    # Optional: standardize column order a bit\n",
    "    def order_cols(df):\n",
    "        first = [\"benchmark\", \"direction\"]\n",
    "        rest = [c for c in df.columns if c not in first]\n",
    "        return df[first + rest]\n",
    "\n",
    "    return order_cols(scores_tbl), order_cols(eci_tbl)\n",
    "\n",
    "# Example:\n",
    "scores_tbl, eci_tbl = pair_tables(compare_df, model_a=\"gpt-4-0613\", model_b=\"PaLM 540B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8f303b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>gpt-4-0613_eci_from_score</th>\n",
       "      <th>PaLM 540B_baseline_eci</th>\n",
       "      <th>PaLM 540B_eci_from_score</th>\n",
       "      <th>gpt-4-0613_baseline_eci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPQA diamond</td>\n",
       "      <td>1.539834</td>\n",
       "      <td>1.649958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATH level 5</td>\n",
       "      <td>1.622123</td>\n",
       "      <td>1.649958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMLU</td>\n",
       "      <td>1.886542</td>\n",
       "      <td>1.649958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARC AI2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.547709</td>\n",
       "      <td>1.644277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BoolQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.516433</td>\n",
       "      <td>1.644277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.487632</td>\n",
       "      <td>1.644277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OpenBookQA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.356508</td>\n",
       "      <td>1.644277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.742466</td>\n",
       "      <td>1.644277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      benchmark  gpt-4-0613_eci_from_score  PaLM 540B_baseline_eci  \\\n",
       "0  GPQA diamond                   1.539834                1.649958   \n",
       "1  MATH level 5                   1.622123                1.649958   \n",
       "2          MMLU                   1.886542                1.649958   \n",
       "3       ARC AI2                        NaN                     NaN   \n",
       "4         BoolQ                        NaN                     NaN   \n",
       "5     HellaSwag                        NaN                     NaN   \n",
       "6    OpenBookQA                        NaN                     NaN   \n",
       "7    Winogrande                        NaN                     NaN   \n",
       "\n",
       "   PaLM 540B_eci_from_score  gpt-4-0613_baseline_eci  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                  1.547709                 1.644277  \n",
       "4                  1.516433                 1.644277  \n",
       "5                  1.487632                 1.644277  \n",
       "6                  2.356508                 1.644277  \n",
       "7                  1.742466                 1.644277  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eci_tbl.drop(columns='direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "736a6363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(25.379401231731087)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_db1.sort_values('benchmark_release_date')['estimated_slope'].max() / df_db1.sort_values('benchmark_release_date')['estimated_slope'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bffe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient (estimated_slope ~ decimal_year): -0.000253\n",
      "Intercept: 2.296564\n",
      "N used: 31 | date range: 2017-05-09 → 2025-06-13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare data: decimal year from benchmark_release_date\n",
    "_df = df_db1.copy()\n",
    "_df['benchmark_release_date'] = pd.to_datetime(_df['benchmark_release_date'], errors='coerce')\n",
    "\n",
    "# Compute decimal year: year + (day_of_year - 1) / days_in_year\n",
    "_days_in_year = np.where(_df['benchmark_release_date'].dt.is_leap_year, 366, 365)\n",
    "_df['decimal_year'] = (\n",
    "    _df['benchmark_release_date'].dt.year +\n",
    "    (_df['benchmark_release_date'].dt.dayofyear - 1) / _days_in_year\n",
    ")\n",
    "\n",
    "# Drop rows with missing values needed for regression\n",
    "_reg = _df.dropna(subset=['decimal_year', 'estimated_slope'])\n",
    "\n",
    "x = _reg['decimal_year'].to_numpy()\n",
    "y = _reg['estimated_slope'].to_numpy()\n",
    "\n",
    "# Simple linear regression (y = a*x + b)\n",
    "coef, intercept = np.polyfit(x, y, 1)\n",
    "print(f\"Coefficient (estimated_slope ~ decimal_year): {coef:.6f}\")\n",
    "print(f\"Intercept: {intercept:.6f}\")\n",
    "\n",
    "# Optional: show a quick sanity summary\n",
    "print(f\"N used: {len(_reg)} | date range: {pd.to_datetime(_reg['benchmark_release_date']).min().date()} → {pd.to_datetime(_reg['benchmark_release_date']).max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv('outputs/input_scores.csv')\n",
    "df_cm1.to_csv('outputs/model_capabilities.csv')\n",
    "df_db1.to_csv('outputs/benchmark_difficulties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e843b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.601503759398496)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.groupby('model').agg('count')['model_id'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32d9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
