{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ea3069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null performances after coercion: 295\n",
      "after saturation filter 1911\n",
      "after filter num benchmarks 1093\n",
      "after merge with model versions 1089\n",
      "after merge with benchmark dates 1089\n",
      "Original number of rows: 1089\n",
      "Number of rows after aggregation: 878\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 38, initial cost 3.2776e+01, final cost 2.4365e+00, first-order optimality 1.55e-04.\n",
      "GPT-3 (001): 0.949\n",
      "GPT-3 (002): 1.53\n",
      "GPT-4: 1.55\n",
      "o3: 2.66\n",
      "GPT-5: 2.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_loader import scores_df\n",
    "from fit import fit_statistical_model\n",
    "\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 0\n",
    "anchor_slope = 1\n",
    "df1, df_cm1, df_db1 = fit_statistical_model(\n",
    "    scores_df, \n",
    "    anchor_mode=\"benchmark\", \n",
    "    anchor_benchmark=anchor_benchmark, \n",
    "    anchor_difficulty=anchor_difficulty, \n",
    "    anchor_slope=anchor_slope)\n",
    "\n",
    "# Convert date strings to datetime objects\n",
    "df_cm1['date_obj'] = pd.to_datetime(df_cm1['date'])\n",
    "\n",
    "gpt_3_001_score = df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['estimated_capability'].values[0]\n",
    "gpt_3_002_score = df_cm1[df_cm1['model'].str.contains('text-davinci-002')]['estimated_capability'].values[0]\n",
    "gpt_4_score = df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['estimated_capability'].values[0]\n",
    "gpt_5_score = df_cm1[df_cm1['model'].str.contains('gpt-5-2025-08-07_medium')]['estimated_capability'].values[0]\n",
    "o3_score = df_cm1[df_cm1['model'].str.contains('o3-2025-04-16_high')]['estimated_capability'].values[0]\n",
    "print(f\"GPT-3 (001): {gpt_3_001_score:.3}\")\n",
    "print(f\"GPT-3 (002): {gpt_3_002_score:.3}\")\n",
    "print(f\"GPT-4: {gpt_4_score:.3}\")\n",
    "print(f\"o3: {o3_score:.3}\")\n",
    "print(f\"GPT-5: {gpt_5_score:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3: 100.0\n",
      "GPT-4: 120.0\n",
      "68.47197846330454\n"
     ]
    }
   ],
   "source": [
    "gpt_3_to_4_gap = 20\n",
    "gpt_3_fixed_score = 100\n",
    "\n",
    "b = gpt_3_to_4_gap / (gpt_4_score - gpt_3_001_score)\n",
    "a = 100 - gpt_3_001_score * b\n",
    "\n",
    "df_cm1['eci'] = a + b * df_cm1['estimated_capability']\n",
    "\n",
    "print(f\"GPT-3: {df_cm1[df_cm1['model'].str.contains('text-davinci-001')]['eci'].values[0]}\")\n",
    "print(f\"GPT-4: {df_cm1[df_cm1['model'].str.contains('gpt-4-0613')]['eci'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e78543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>estimated_capability</th>\n",
       "      <th>model</th>\n",
       "      <th>is_anchor</th>\n",
       "      <th>Model</th>\n",
       "      <th>date</th>\n",
       "      <th>date_obj</th>\n",
       "      <th>eci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>m82</td>\n",
       "      <td>2.949242</td>\n",
       "      <td>gpt-5-2025-08-07_medium</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>166.427851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>m84</td>\n",
       "      <td>2.894642</td>\n",
       "      <td>gpt-5-2025-08-07_high</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>164.614364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>m83</td>\n",
       "      <td>2.594062</td>\n",
       "      <td>gpt-5-mini-2025-08-07_medium</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5 mini</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>154.630942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>m79</td>\n",
       "      <td>2.565518</td>\n",
       "      <td>gpt-5-mini-2025-08-07_high</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5 mini</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>153.682876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>m81</td>\n",
       "      <td>2.488548</td>\n",
       "      <td>gpt-5-nano-2025-08-07_medium</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5 nano</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>151.126394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>m80</td>\n",
       "      <td>2.479642</td>\n",
       "      <td>gpt-5-nano-2025-08-07_high</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-5 nano</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>150.830609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>m49</td>\n",
       "      <td>2.247117</td>\n",
       "      <td>gpt-4.5-preview-2025-02-27</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4.5</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>143.107546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>m59</td>\n",
       "      <td>2.239488</td>\n",
       "      <td>gpt-4.1-2025-04-14</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4.1</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>142.854143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>m61</td>\n",
       "      <td>2.176937</td>\n",
       "      <td>gpt-4.1-mini-2025-04-14</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4.1 mini</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>140.776585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>m60</td>\n",
       "      <td>1.969094</td>\n",
       "      <td>gpt-4.1-nano-2025-04-14</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4.1 nano</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>133.873284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>m38</td>\n",
       "      <td>1.883259</td>\n",
       "      <td>gpt-4o-2024-11-20</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>131.022381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>m6</td>\n",
       "      <td>1.870487</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>130.598175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>m13</td>\n",
       "      <td>1.851691</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>129.973886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>m48</td>\n",
       "      <td>1.816526</td>\n",
       "      <td>gpt-4-turbo-2024-04-09</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4 Turbo</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>128.805916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>m19</td>\n",
       "      <td>1.767738</td>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4o mini</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>127.185480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>m15</td>\n",
       "      <td>1.551399</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>m17</td>\n",
       "      <td>1.474832</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>False</td>\n",
       "      <td>GPT-3.5 Turbo</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>117.456933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_id  estimated_capability                         model  is_anchor  \\\n",
       "114      m82              2.949242       gpt-5-2025-08-07_medium      False   \n",
       "116      m84              2.894642         gpt-5-2025-08-07_high      False   \n",
       "115      m83              2.594062  gpt-5-mini-2025-08-07_medium      False   \n",
       "110      m79              2.565518    gpt-5-mini-2025-08-07_high      False   \n",
       "113      m81              2.488548  gpt-5-nano-2025-08-07_medium      False   \n",
       "112      m80              2.479642    gpt-5-nano-2025-08-07_high      False   \n",
       "77       m49              2.247117    gpt-4.5-preview-2025-02-27      False   \n",
       "88       m59              2.239488            gpt-4.1-2025-04-14      False   \n",
       "91       m61              2.176937       gpt-4.1-mini-2025-04-14      False   \n",
       "90       m60              1.969094       gpt-4.1-nano-2025-04-14      False   \n",
       "65       m38              1.883259             gpt-4o-2024-11-20      False   \n",
       "89        m6              1.870487             gpt-4o-2024-08-06      False   \n",
       "34       m13              1.851691             gpt-4o-2024-05-13      False   \n",
       "76       m48              1.816526        gpt-4-turbo-2024-04-09      False   \n",
       "45       m19              1.767738        gpt-4o-mini-2024-07-18      False   \n",
       "41       m15              1.551399                    gpt-4-0613      False   \n",
       "43       m17              1.474832            gpt-3.5-turbo-1106      False   \n",
       "\n",
       "             Model        date   date_obj         eci  \n",
       "114          GPT-5  2025-08-07 2025-08-07  166.427851  \n",
       "116          GPT-5  2025-08-07 2025-08-07  164.614364  \n",
       "115     GPT-5 mini  2025-08-07 2025-08-07  154.630942  \n",
       "110     GPT-5 mini  2025-08-07 2025-08-07  153.682876  \n",
       "113     GPT-5 nano  2025-08-07 2025-08-07  151.126394  \n",
       "112     GPT-5 nano  2025-08-07 2025-08-07  150.830609  \n",
       "77         GPT-4.5  2025-02-27 2025-02-27  143.107546  \n",
       "88         GPT-4.1  2025-04-14 2025-04-14  142.854143  \n",
       "91    GPT-4.1 mini  2025-04-14 2025-04-14  140.776585  \n",
       "90    GPT-4.1 nano  2025-04-14 2025-04-14  133.873284  \n",
       "65          GPT-4o  2024-11-20 2024-11-20  131.022381  \n",
       "89          GPT-4o  2024-08-06 2024-08-06  130.598175  \n",
       "34          GPT-4o  2024-05-13 2024-05-13  129.973886  \n",
       "76     GPT-4 Turbo  2024-04-09 2024-04-09  128.805916  \n",
       "45     GPT-4o mini  2024-07-18 2024-07-18  127.185480  \n",
       "41           GPT-4  2023-06-13 2023-06-13  120.000000  \n",
       "43   GPT-3.5 Turbo  2023-11-06 2023-11-06  117.456933  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm1[df_cm1['model'].str.contains('gpt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ff1ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>performance</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>benchmark_release_date</th>\n",
       "      <th>optimized</th>\n",
       "      <th>is_math</th>\n",
       "      <th>is_coding</th>\n",
       "      <th>model</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>m116</td>\n",
       "      <td>b12</td>\n",
       "      <td>0.775</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>GLaM: Efficient Scaling of Language Models wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>m116</td>\n",
       "      <td>b14</td>\n",
       "      <td>0.529</td>\n",
       "      <td>CSQA2</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>CommonsenseQA 2.0: Exposing the Limits of AI t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>m116</td>\n",
       "      <td>b20</td>\n",
       "      <td>0.793</td>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>GLaM: Efficient Scaling of Language Models wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>m116</td>\n",
       "      <td>b21</td>\n",
       "      <td>0.439</td>\n",
       "      <td>MMLU</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>Scaling Language Models: Methods, Analysis &amp; I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>m116</td>\n",
       "      <td>b22</td>\n",
       "      <td>0.654</td>\n",
       "      <td>OpenBookQA</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>GLaM: Efficient Scaling of Language Models wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>m116</td>\n",
       "      <td>b27</td>\n",
       "      <td>0.712</td>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>m116</td>\n",
       "      <td>b31</td>\n",
       "      <td>0.777</td>\n",
       "      <td>Winogrande</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>m116</td>\n",
       "      <td>b7</td>\n",
       "      <td>0.354</td>\n",
       "      <td>ANLI</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>Using DeepSpeed and Megatron to Train Megatron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>m116</td>\n",
       "      <td>b9</td>\n",
       "      <td>0.532</td>\n",
       "      <td>ARC AI2</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>The Falcon Series of Open Language Models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_id benchmark_id  performance   benchmark benchmark_release_date  \\\n",
       "114     m116          b12        0.775       BoolQ             2019-05-24   \n",
       "115     m116          b14        0.529       CSQA2             2022-01-14   \n",
       "116     m116          b20        0.793   HellaSwag             2019-05-19   \n",
       "117     m116          b21        0.439        MMLU             2020-09-07   \n",
       "118     m116          b22        0.654  OpenBookQA             2018-09-08   \n",
       "119     m116          b27        0.712    TriviaQA             2017-05-09   \n",
       "120     m116          b31        0.777  Winogrande             2019-07-24   \n",
       "121     m116           b7        0.354        ANLI             2019-10-31   \n",
       "122     m116           b9        0.532     ARC AI2             2018-03-14   \n",
       "\n",
       "     optimized  is_math  is_coding             model        date  \\\n",
       "114       True    False      False  text-davinci-001  2022-01-27   \n",
       "115      False    False      False  text-davinci-001  2022-01-27   \n",
       "116       True    False      False  text-davinci-001  2022-01-27   \n",
       "117       True    False      False  text-davinci-001  2022-01-27   \n",
       "118       True    False      False  text-davinci-001  2022-01-27   \n",
       "119       True    False      False  text-davinci-001  2022-01-27   \n",
       "120       True    False      False  text-davinci-001  2022-01-27   \n",
       "121       True    False      False  text-davinci-001  2022-01-27   \n",
       "122       True    False      False  text-davinci-001  2022-01-27   \n",
       "\n",
       "                                                source  \n",
       "114  GLaM: Efficient Scaling of Language Models wit...  \n",
       "115  CommonsenseQA 2.0: Exposing the Limits of AI t...  \n",
       "116  GLaM: Efficient Scaling of Language Models wit...  \n",
       "117  Scaling Language Models: Methods, Analysis & I...  \n",
       "118  GLaM: Efficient Scaling of Language Models wit...  \n",
       "119              Language Models are Few-Shot Learners  \n",
       "120              Language Models are Few-Shot Learners  \n",
       "121  Using DeepSpeed and Megatron to Train Megatron...  \n",
       "122          The Falcon Series of Open Language Models  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df[scores_df['model'].str.contains('text-davinci-001')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c20315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm1.to_csv('output/eci_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
