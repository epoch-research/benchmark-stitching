{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a733e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parent)\n",
    "# print(\"cwd is now:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59f7aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null performances after coercion: 281\n",
      "after saturation filter 2201\n",
      "after filter num benchmarks 1401\n",
      "after merge with model versions 1397\n",
      "after merge with benchmark dates 1397\n",
      "Original number of rows: 1397\n",
      "Number of rows after aggregation: 967\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from data_loader import scores_df\n",
    "from fit import fit_statistical_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fbd2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 38, initial cost 3.4246e+01, final cost 2.4828e+00, first-order optimality 1.78e-04.\n"
     ]
    }
   ],
   "source": [
    "anchor_mode = \"model\" # \"model\", \"benchmark\"\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 0\n",
    "anchor_slope = 1\n",
    "anchor_model1 = \"claude-2.0\"\n",
    "anchor_model1_capability = 1.177630\n",
    "anchor_model2 = \"claude-3-opus-20240229\"\n",
    "anchor_model2_capability = 1.311554\n",
    "\n",
    "df_anchor, df_cm_anchor, df_db_anchor = fit_statistical_model(\n",
    "    scores_df,\n",
    "    anchor_mode=anchor_mode,\n",
    "    anchor_benchmark=anchor_benchmark,\n",
    "    anchor_difficulty=anchor_difficulty,\n",
    "    anchor_slope=anchor_slope,\n",
    "    anchor_model1=anchor_model1,\n",
    "    anchor_model1_capability=anchor_model1_capability,\n",
    "    anchor_model2=anchor_model2,\n",
    "    anchor_model2_capability=anchor_model2_capability\n",
    ")\n",
    "\n",
    "df_cm_anchor['date_obj'] = pd.to_datetime(df_cm_anchor['date'])\n",
    "\n",
    "# anchor_benchmark = \"Winogrande\"\n",
    "# anchor_difficulty = 0\n",
    "# anchor_slope = 1\n",
    "# df_anchor, df_cm_anchor, df_db_anchor = fit_statistical_model(scores_df, anchor_benchmark, anchor_difficulty, anchor_slope)\n",
    "\n",
    "# # Convert date strings to datetime objects\n",
    "# df_cm_anchor['date_obj'] = pd.to_datetime(df_cm_anchor['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193f1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 3.3915e+01, final cost 2.4254e+00, first-order optimality 1.12e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.3946e+01, final cost 2.4270e+00, first-order optimality 5.09e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 3.3996e+01, final cost 2.4268e+00, first-order optimality 4.95e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3945e+01, final cost 2.4270e+00, first-order optimality 7.92e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4094e+01, final cost 2.4247e+00, first-order optimality 3.41e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.4081e+01, final cost 2.4246e+00, first-order optimality 2.21e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4146e+01, final cost 2.4273e+00, first-order optimality 1.31e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 3.4086e+01, final cost 2.4274e+00, first-order optimality 4.55e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4087e+01, final cost 2.4277e+00, first-order optimality 5.11e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.4091e+01, final cost 2.4270e+00, first-order optimality 1.63e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4104e+01, final cost 2.4246e+00, first-order optimality 3.31e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 3.4081e+01, final cost 2.4251e+00, first-order optimality 2.92e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.5168e+01, final cost 2.4197e+00, first-order optimality 1.19e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 44, initial cost 3.4208e+01, final cost 2.4238e+00, first-order optimality 8.19e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 3.4148e+01, final cost 2.4217e+00, first-order optimality 5.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3704e+01, final cost 2.4159e+00, first-order optimality 5.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4128e+01, final cost 2.4232e+00, first-order optimality 2.88e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 50, initial cost 3.4365e+01, final cost 2.4205e+00, first-order optimality 1.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4260e+01, final cost 2.4185e+00, first-order optimality 9.58e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.4084e+01, final cost 2.4237e+00, first-order optimality 9.44e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4051e+01, final cost 2.4242e+00, first-order optimality 6.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.4099e+01, final cost 2.4245e+00, first-order optimality 1.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 3.4088e+01, final cost 2.4245e+00, first-order optimality 4.07e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4083e+01, final cost 2.4244e+00, first-order optimality 3.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.4083e+01, final cost 2.4239e+00, first-order optimality 2.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.3987e+01, final cost 2.4222e+00, first-order optimality 3.39e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.4089e+01, final cost 2.4247e+00, first-order optimality 1.29e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 43, initial cost 3.4086e+01, final cost 2.4245e+00, first-order optimality 1.55e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.4082e+01, final cost 2.4246e+00, first-order optimality 5.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 44, initial cost 3.4004e+01, final cost 2.4236e+00, first-order optimality 1.83e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 42, initial cost 3.4084e+01, final cost 2.4246e+00, first-order optimality 6.58e-04.\n"
     ]
    }
   ],
   "source": [
    "all_runs = {}           # will map benchmark_name -> dict of outputs\n",
    "failed    = []          # keep track of anything that errors out\n",
    "\n",
    "# --- loop --------------------------------------------------------------------\n",
    "for _, row in df_db_anchor.iterrows():\n",
    "    anchor_benchmark  = row['benchmark_name']       # e.g. \"HellaSwag\"\n",
    "    anchor_difficulty = float(row['estimated_difficulty'])\n",
    "    anchor_slope      = float(row['estimated_slope'])\n",
    "    \n",
    "    try:\n",
    "        df, df_cm, df_db = fit_statistical_model(\n",
    "            scores_df,\n",
    "            anchor_mode=\"benchmark\",\n",
    "            anchor_benchmark  = anchor_benchmark,\n",
    "            anchor_difficulty = anchor_difficulty,\n",
    "            anchor_slope      = anchor_slope\n",
    "        )\n",
    "        all_runs[anchor_benchmark] = {\n",
    "            \"df1\" : df,\n",
    "            \"df_cm1\" : df_cm,\n",
    "            \"df_db\" : df_db,\n",
    "            # cache the anchor values for reference\n",
    "            \"anchor_difficulty\" : anchor_difficulty,\n",
    "            \"anchor_slope\"      : anchor_slope,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        failed.append((anchor_benchmark, str(e)))\n",
    "\n",
    "# --- post-processing (optional) ----------------------------------------------\n",
    "# 1) quick glance at what failed\n",
    "if failed:\n",
    "    print(\"Benchmarks that raised errors:\", failed)\n",
    "\n",
    "# 2) pull out the difficulty/slope re-estimates across all runs\n",
    "summary = (\n",
    "    pd.concat(\n",
    "        {k: v[\"df_db\"][[\"benchmark_name\", \"estimated_difficulty\", \"estimated_slope\"]]\n",
    "         for k, v in all_runs.items()},\n",
    "        names=[\"anchor_benchmark\"]\n",
    "    )\n",
    "    .reset_index(level=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31753a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== variation in benchmark difficulties ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.879505</td>\n",
       "      <td>0.067812</td>\n",
       "      <td>0.630540</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>0.075807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.074245</td>\n",
       "      <td>0.115938</td>\n",
       "      <td>-0.146989</td>\n",
       "      <td>0.198066</td>\n",
       "      <td>1.535318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>2.068905</td>\n",
       "      <td>0.053815</td>\n",
       "      <td>1.814401</td>\n",
       "      <td>2.147912</td>\n",
       "      <td>0.025574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>1.770756</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>1.515033</td>\n",
       "      <td>1.834522</td>\n",
       "      <td>0.029848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.468574</td>\n",
       "      <td>0.090208</td>\n",
       "      <td>0.233932</td>\n",
       "      <td>0.567482</td>\n",
       "      <td>0.189280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>2.450525</td>\n",
       "      <td>0.056428</td>\n",
       "      <td>2.198041</td>\n",
       "      <td>2.552235</td>\n",
       "      <td>0.022640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>-1.123609</td>\n",
       "      <td>0.208504</td>\n",
       "      <td>-1.537819</td>\n",
       "      <td>-0.922035</td>\n",
       "      <td>-0.182447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.085801</td>\n",
       "      <td>0.092002</td>\n",
       "      <td>-0.081500</td>\n",
       "      <td>0.192395</td>\n",
       "      <td>1.054255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>1.807249</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>1.551749</td>\n",
       "      <td>1.872774</td>\n",
       "      <td>0.029199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>2.704045</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>2.452568</td>\n",
       "      <td>2.807132</td>\n",
       "      <td>0.020544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>2.138523</td>\n",
       "      <td>0.053962</td>\n",
       "      <td>1.884264</td>\n",
       "      <td>2.220344</td>\n",
       "      <td>0.024809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>3.291521</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>3.044971</td>\n",
       "      <td>3.409100</td>\n",
       "      <td>0.018039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>2.767474</td>\n",
       "      <td>0.057877</td>\n",
       "      <td>2.516382</td>\n",
       "      <td>2.875475</td>\n",
       "      <td>0.020562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.398261</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>1.142144</td>\n",
       "      <td>1.440413</td>\n",
       "      <td>0.039222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>3.562423</td>\n",
       "      <td>0.053321</td>\n",
       "      <td>3.311074</td>\n",
       "      <td>3.640527</td>\n",
       "      <td>0.014716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.679617</td>\n",
       "      <td>0.067150</td>\n",
       "      <td>0.418787</td>\n",
       "      <td>0.759745</td>\n",
       "      <td>0.097145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>-0.839563</td>\n",
       "      <td>0.184822</td>\n",
       "      <td>-1.200790</td>\n",
       "      <td>-0.656476</td>\n",
       "      <td>-0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>1.360245</td>\n",
       "      <td>0.056086</td>\n",
       "      <td>1.103951</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>0.040540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.258968</td>\n",
       "      <td>0.103663</td>\n",
       "      <td>0.031469</td>\n",
       "      <td>0.371317</td>\n",
       "      <td>0.393567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>4.378514</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>4.133827</td>\n",
       "      <td>4.481546</td>\n",
       "      <td>0.012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>1.939359</td>\n",
       "      <td>0.053568</td>\n",
       "      <td>1.683743</td>\n",
       "      <td>2.007598</td>\n",
       "      <td>0.027157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>1.782325</td>\n",
       "      <td>0.053741</td>\n",
       "      <td>1.526578</td>\n",
       "      <td>1.846923</td>\n",
       "      <td>0.029645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.081038</td>\n",
       "      <td>0.115716</td>\n",
       "      <td>-0.140299</td>\n",
       "      <td>0.204567</td>\n",
       "      <td>1.403921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>3.152396</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>2.905969</td>\n",
       "      <td>3.228782</td>\n",
       "      <td>0.016619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>2.141933</td>\n",
       "      <td>0.054138</td>\n",
       "      <td>1.887880</td>\n",
       "      <td>2.225785</td>\n",
       "      <td>0.024850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>3.407955</td>\n",
       "      <td>0.060782</td>\n",
       "      <td>3.161834</td>\n",
       "      <td>3.525614</td>\n",
       "      <td>0.017535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>-1.607660</td>\n",
       "      <td>0.230357</td>\n",
       "      <td>-2.042884</td>\n",
       "      <td>-1.381893</td>\n",
       "      <td>-0.140879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>2.394031</td>\n",
       "      <td>0.056103</td>\n",
       "      <td>2.140698</td>\n",
       "      <td>2.492943</td>\n",
       "      <td>0.023041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>-0.421325</td>\n",
       "      <td>0.071693</td>\n",
       "      <td>-0.675146</td>\n",
       "      <td>-0.325216</td>\n",
       "      <td>-0.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>2.187983</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>1.936006</td>\n",
       "      <td>2.270665</td>\n",
       "      <td>0.024162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>-1.318872</td>\n",
       "      <td>0.223705</td>\n",
       "      <td>-1.761074</td>\n",
       "      <td>-1.104866</td>\n",
       "      <td>-0.166767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean       std       min       max  \\\n",
       "benchmark_name                                                            \n",
       "ANLI                             0.879505  0.067812  0.630540  0.952880   \n",
       "ARC AI2                          0.074245  0.115938 -0.146989  0.198066   \n",
       "ARC-AGI                          2.068905  0.053815  1.814401  2.147912   \n",
       "Aider polyglot                   1.770756  0.053756  1.515033  1.834522   \n",
       "BBH                              0.468574  0.090208  0.233932  0.567482   \n",
       "Balrog                           2.450525  0.056428  2.198041  2.552235   \n",
       "BoolQ                           -1.123609  0.208504 -1.537819 -0.922035   \n",
       "CSQA2                            0.085801  0.092002 -0.081500  0.192395   \n",
       "CadEval                          1.807249  0.053672  1.551749  1.872774   \n",
       "Cybench                          2.704045  0.056502  2.452568  2.807132   \n",
       "DeepResearch Bench               2.138523  0.053962  1.884264  2.220344   \n",
       "Factorio learning environment    3.291521  0.060390  3.044971  3.409100   \n",
       "FrontierMath-2025-02-28-Private  2.767474  0.057877  2.516382  2.875475   \n",
       "GPQA diamond                     1.398261  0.055781  1.142144  1.440413   \n",
       "GSO-Bench                        3.562423  0.053321  3.311074  3.640527   \n",
       "GeoBench                         0.679617  0.067150  0.418787  0.759745   \n",
       "HellaSwag                       -0.839563  0.184822 -1.200790 -0.656476   \n",
       "MATH level 5                     1.360245  0.056086  1.103951  1.402592   \n",
       "MMLU                             0.258968  0.103663  0.031469  0.371317   \n",
       "OSUniverse                       4.378514  0.057261  4.133827  4.481546   \n",
       "OSWorld                          1.939359  0.053568  1.683743  2.007598   \n",
       "OTIS Mock AIME 2024-2025         1.782325  0.053741  1.526578  1.846923   \n",
       "OpenBookQA                       0.081038  0.115716 -0.140299  0.204567   \n",
       "SWE-Bench verified               3.152396  0.053285  2.905969  3.228782   \n",
       "SimpleBench                      2.141933  0.054138  1.887880  2.225785   \n",
       "Terminal Bench                   3.407955  0.060782  3.161834  3.525614   \n",
       "TriviaQA                        -1.607660  0.230357 -2.042884 -1.381893   \n",
       "VPCT                             2.394031  0.056103  2.140698  2.492943   \n",
       "VideoMME                        -0.421325  0.071693 -0.675146 -0.325216   \n",
       "WeirdML                          2.187983  0.053771  1.936006  2.270665   \n",
       "Winogrande                      -1.318872  0.223705 -1.761074 -1.104866   \n",
       "\n",
       "                                       cv  \n",
       "benchmark_name                             \n",
       "ANLI                             0.075807  \n",
       "ARC AI2                          1.535318  \n",
       "ARC-AGI                          0.025574  \n",
       "Aider polyglot                   0.029848  \n",
       "BBH                              0.189280  \n",
       "Balrog                           0.022640  \n",
       "BoolQ                           -0.182447  \n",
       "CSQA2                            1.054255  \n",
       "CadEval                          0.029199  \n",
       "Cybench                          0.020544  \n",
       "DeepResearch Bench               0.024809  \n",
       "Factorio learning environment    0.018039  \n",
       "FrontierMath-2025-02-28-Private  0.020562  \n",
       "GPQA diamond                     0.039222  \n",
       "GSO-Bench                        0.014716  \n",
       "GeoBench                         0.097145  \n",
       "HellaSwag                       -0.216440  \n",
       "MATH level 5                     0.040540  \n",
       "MMLU                             0.393567  \n",
       "OSUniverse                       0.012858  \n",
       "OSWorld                          0.027157  \n",
       "OTIS Mock AIME 2024-2025         0.029645  \n",
       "OpenBookQA                       1.403921  \n",
       "SWE-Bench verified               0.016619  \n",
       "SimpleBench                      0.024850  \n",
       "Terminal Bench                   0.017535  \n",
       "TriviaQA                        -0.140879  \n",
       "VPCT                             0.023041  \n",
       "VideoMME                        -0.167300  \n",
       "WeirdML                          0.024162  \n",
       "Winogrande                      -0.166767  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== variation in model capabilities ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.136867</td>\n",
       "      <td>0.113286</td>\n",
       "      <td>-0.081509</td>\n",
       "      <td>0.261958</td>\n",
       "      <td>0.814249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>-0.054945</td>\n",
       "      <td>0.127712</td>\n",
       "      <td>-0.265558</td>\n",
       "      <td>0.083539</td>\n",
       "      <td>-2.286591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.506247</td>\n",
       "      <td>0.164431</td>\n",
       "      <td>-0.798413</td>\n",
       "      <td>-0.335947</td>\n",
       "      <td>-0.319523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)</th>\n",
       "      <td>0.713319</td>\n",
       "      <td>0.075675</td>\n",
       "      <td>0.472465</td>\n",
       "      <td>0.798634</td>\n",
       "      <td>0.104364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1</th>\n",
       "      <td>1.800190</td>\n",
       "      <td>0.052852</td>\n",
       "      <td>1.544126</td>\n",
       "      <td>1.865246</td>\n",
       "      <td>0.028882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablelm-tuned-alpha-7b</th>\n",
       "      <td>-0.825597</td>\n",
       "      <td>0.191350</td>\n",
       "      <td>-1.176695</td>\n",
       "      <td>-0.632813</td>\n",
       "      <td>-0.228003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-001</th>\n",
       "      <td>0.289187</td>\n",
       "      <td>0.102725</td>\n",
       "      <td>0.065418</td>\n",
       "      <td>0.403878</td>\n",
       "      <td>0.349443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>1.059209</td>\n",
       "      <td>0.059915</td>\n",
       "      <td>0.804349</td>\n",
       "      <td>1.120091</td>\n",
       "      <td>0.055646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.081865</td>\n",
       "      <td>0.130633</td>\n",
       "      <td>-0.298455</td>\n",
       "      <td>0.058758</td>\n",
       "      <td>-1.569773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.141378</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>-0.367546</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>-0.942141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean       std       min       max        cv\n",
       "model                                                                    \n",
       "Baichuan-2-13B-Base      0.136867  0.113286 -0.081509  0.261958  0.814249\n",
       "Baichuan-2-7B-Base      -0.054945  0.127712 -0.265558  0.083539 -2.286591\n",
       "Cerebras-GPT-13B        -0.506247  0.164431 -0.798413 -0.335947 -0.319523\n",
       "Chinchilla (70B)         0.713319  0.075675  0.472465  0.798634  0.104364\n",
       "DeepSeek-R1              1.800190  0.052852  1.544126  1.865246  0.028882\n",
       "...                           ...       ...       ...       ...       ...\n",
       "stablelm-tuned-alpha-7b -0.825597  0.191350 -1.176695 -0.632813 -0.228003\n",
       "text-davinci-001         0.289187  0.102725  0.065418  0.403878  0.349443\n",
       "text-davinci-002         1.059209  0.059915  0.804349  1.120091  0.055646\n",
       "vicuna-13b-v1.1         -0.081865  0.130633 -0.298455  0.058758 -1.569773\n",
       "xgen-7b-8k-base         -0.141378  0.135400 -0.367546  0.003393 -0.942141\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1)  DIFFICULTY  ––  variation of each benchmark’s difficulty estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "difficulty_rows = []\n",
    "\n",
    "for anchor, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]                                  # difficulty table from that fit\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_difficulty\"]].copy()\n",
    "    out[\"anchor_benchmark\"] = anchor                      # remember which fit this came from\n",
    "    difficulty_rows.append(out)\n",
    "\n",
    "difficulty_long = pd.concat(difficulty_rows, ignore_index=True)\n",
    "\n",
    "# drop the trivial row where the benchmark was forced to be the anchor (always fixed):\n",
    "difficulty_long = difficulty_long[\n",
    "    difficulty_long[\"benchmark_name\"] != difficulty_long[\"anchor_benchmark\"]\n",
    "]\n",
    "\n",
    "difficulty_stats = (\n",
    "    difficulty_long\n",
    "      .groupby(\"benchmark_name\")[\"estimated_difficulty\"]\n",
    "      .agg(mean   = \"mean\",\n",
    "           std    = \"std\",\n",
    "           min    = \"min\",\n",
    "           max    = \"max\",\n",
    "           cv     = lambda s: s.std(ddof=0) / s.mean()      # coefficient of variation\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2)  CAPABILITY  ––  variation of each model’s capability estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "capability_rows = []\n",
    "\n",
    "for anchor, run in all_runs.items():\n",
    "    df_cm = run[\"df_cm1\"]                                  # capability table from that fit\n",
    "    out = df_cm[[\"model\", \"estimated_capability\"]].copy()\n",
    "    out[\"anchor_benchmark\"] = anchor\n",
    "    capability_rows.append(out)\n",
    "\n",
    "capability_long = pd.concat(capability_rows, ignore_index=True)\n",
    "\n",
    "capability_stats = (\n",
    "    capability_long\n",
    "      .groupby(\"model\")[\"estimated_capability\"]\n",
    "      .agg(mean = \"mean\",\n",
    "           std  = \"std\",\n",
    "           min  = \"min\",\n",
    "           max  = \"max\",\n",
    "           cv   = lambda s: s.std(ddof=0) / s.mean()\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3)  quick look\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"=== variation in benchmark difficulties ===\")\n",
    "display(difficulty_stats)\n",
    "\n",
    "print(\"\\n=== variation in model capabilities ===\")\n",
    "display(capability_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85924acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spearman rank correlation across fits (benchmark difficulties) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th>ANLI</th>\n",
       "      <th>ARC AI2</th>\n",
       "      <th>ARC-AGI</th>\n",
       "      <th>Aider polyglot</th>\n",
       "      <th>BBH</th>\n",
       "      <th>Balrog</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>CSQA2</th>\n",
       "      <th>CadEval</th>\n",
       "      <th>Cybench</th>\n",
       "      <th>...</th>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <th>SimpleBench</th>\n",
       "      <th>Terminal Bench</th>\n",
       "      <th>TriviaQA</th>\n",
       "      <th>VPCT</th>\n",
       "      <th>VideoMME</th>\n",
       "      <th>WeirdML</th>\n",
       "      <th>Winogrande</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999291</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.998364</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.998548</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998198</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>0.998381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998520</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.999451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.998198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.998562</td>\n",
       "      <td>0.998719</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.998830</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.998442</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.998322</td>\n",
       "      <td>0.999234</td>\n",
       "      <td>0.998417</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.999121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>0.998255</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.998472</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.998606</td>\n",
       "      <td>0.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.998510</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.999106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998360</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.999192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998207</td>\n",
       "      <td>0.998442</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>0.999480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.999587</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.998876</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.999129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.998503</td>\n",
       "      <td>0.998381</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.998285</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999106</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998520</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.999444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.998817</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>0.998589</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.998784</td>\n",
       "      <td>0.999418</td>\n",
       "      <td>0.998662</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.998666</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>0.999372</td>\n",
       "      <td>0.998877</td>\n",
       "      <td>0.998638</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.999640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>0.998280</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999125</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>0.998442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>0.999604</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.999451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.999401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.998198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.998262</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>0.998292</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.999105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.999106</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.999125</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998360</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.998849</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.999789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998391</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998201</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>0.998165</td>\n",
       "      <td>0.998671</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.998412</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.998528</td>\n",
       "      <td>0.999474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>0.998638</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.998848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.999398</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.998471</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.999789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998786</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.998889</td>\n",
       "      <td>0.997686</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.998173</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.997666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.997748</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>0.997739</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.998614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999593</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998292</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998357</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999604</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998509</td>\n",
       "      <td>0.998098</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.998472</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>0.998963</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>0.998528</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999144</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998201</td>\n",
       "      <td>0.998391</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.999274</td>\n",
       "      <td>0.998671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.998360</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.997928</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.998465</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.998661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.998357</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>0.999444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.998520</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.998322</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997928</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.999480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.998364</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999234</td>\n",
       "      <td>0.998255</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.999587</td>\n",
       "      <td>0.998836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998671</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.998562</td>\n",
       "      <td>0.998417</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998873</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.999540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.998719</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.998873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.999640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.998548</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.998472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.998419</td>\n",
       "      <td>0.998664</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.998357</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999365</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998509</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998830</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998876</td>\n",
       "      <td>0.998520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998465</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.998763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>0.999540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.998606</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.998443</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor_benchmark                     ANLI   ARC AI2   ARC-AGI  Aider polyglot  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                             1.000000  0.999291  0.998633        0.999141   \n",
       "ARC AI2                          0.999291  1.000000  0.998198        0.998479   \n",
       "ARC-AGI                          0.998633  0.998198  1.000000        0.999586   \n",
       "Aider polyglot                   0.999141  0.998479  0.999586        1.000000   \n",
       "BBH                              1.000000  0.999436  0.998497        0.998960   \n",
       "Balrog                           0.998510  0.998363  0.998683        0.998329   \n",
       "BoolQ                            0.999316  0.999437  0.998788        0.998836   \n",
       "CSQA2                            0.999192  1.000000  0.998207        0.998442   \n",
       "CadEval                          0.998788  0.998285  1.000000        0.999785   \n",
       "Cybench                          0.998503  0.998381  0.998588        0.998285   \n",
       "DeepResearch Bench               0.998938  0.998573  0.999554        0.998956   \n",
       "Factorio learning environment    0.998934  0.998848  0.998666        0.998576   \n",
       "FrontierMath-2025-02-28-Private  0.998535  0.998431  0.998532        0.998280   \n",
       "GPQA diamond                     0.999338  0.998588  0.999401        1.000000   \n",
       "GSO-Bench                        0.999200  0.999106  0.998843        0.998809   \n",
       "GeoBench                         0.999785  0.999600  0.998382        0.998800   \n",
       "HellaSwag                        0.999189  0.999495  0.998542        0.998638   \n",
       "MATH level 5                     0.999105  0.998253  0.998786        0.999339   \n",
       "MMLU                             0.999593  0.999786  0.998292        0.998664   \n",
       "OSUniverse                       0.999553  0.999444  0.999105        0.999129   \n",
       "OSWorld                          0.998614  0.998399  0.998963        0.998510   \n",
       "OTIS Mock AIME 2024-2025         0.998511  0.997926  0.999340        0.999555   \n",
       "OpenBookQA                       0.999426  1.000000  0.998229        0.998555   \n",
       "SWE-Bench verified               0.998611  0.998520  0.998521        0.998322   \n",
       "SimpleBench                      0.998364  0.998049  0.999785        0.999234   \n",
       "Terminal Bench                   0.998741  0.998656  0.998562        0.998417   \n",
       "TriviaQA                         0.999132  0.999615  0.998719        0.998908   \n",
       "VPCT                             0.998548  0.998371  0.998809        0.998405   \n",
       "VideoMME                         0.999136  0.999786  0.998830        0.998972   \n",
       "WeirdML                          0.998703  0.998444  0.999141        0.998639   \n",
       "Winogrande                       0.999527  0.999451  0.999121        0.999121   \n",
       "\n",
       "anchor_benchmark                      BBH    Balrog     BoolQ     CSQA2  \\\n",
       "anchor_benchmark                                                          \n",
       "ANLI                             1.000000  0.998510  0.999316  0.999192   \n",
       "ARC AI2                          0.999436  0.998363  0.999437  1.000000   \n",
       "ARC-AGI                          0.998497  0.998683  0.998788  0.998207   \n",
       "Aider polyglot                   0.998960  0.998329  0.998836  0.998442   \n",
       "BBH                              1.000000  0.998443  0.999321  0.999312   \n",
       "Balrog                           0.998443  1.000000  0.999107  0.998413   \n",
       "BoolQ                            0.999321  0.999107  1.000000  0.999516   \n",
       "CSQA2                            0.999312  0.998413  0.999516  1.000000   \n",
       "CadEval                          0.998639  0.998555  0.998809  0.998280   \n",
       "Cybench                          0.998444  1.000000  0.999106  0.998431   \n",
       "DeepResearch Bench               0.998817  0.999273  0.999228  0.998595   \n",
       "Factorio learning environment    0.998901  0.999398  0.999372  0.998877   \n",
       "FrontierMath-2025-02-28-Private  0.998483  0.999786  0.999125  0.998479   \n",
       "GPQA diamond                     0.999141  0.998229  0.998843  0.998532   \n",
       "GSO-Bench                        0.999171  0.999384  0.999548  0.999125   \n",
       "GeoBench                         1.000000  0.998391  0.999331  0.999448   \n",
       "HellaSwag                        0.999224  0.998841  1.000000  0.999622   \n",
       "MATH level 5                     0.998889  0.997686  0.998380  0.998173   \n",
       "MMLU                             0.999786  0.998357  0.999350  0.999604   \n",
       "OSUniverse                       0.999527  0.999444  0.999789  0.999451   \n",
       "OSWorld                          0.998528  0.999786  0.999144  0.998444   \n",
       "OTIS Mock AIME 2024-2025         0.998346  0.997987  0.998360  0.997904   \n",
       "OpenBookQA                       0.999596  0.998346  0.999384  0.999786   \n",
       "SWE-Bench verified               0.998567  0.999609  0.999171  0.998564   \n",
       "SimpleBench                      0.998255  0.998974  0.998734  0.998079   \n",
       "Terminal Bench                   0.998703  0.999477  0.999250  0.998693   \n",
       "TriviaQA                         0.999197  0.998643  0.999788  0.999787   \n",
       "VPCT                             0.998472  1.000000  0.999121  0.998419   \n",
       "VideoMME                         0.999230  0.998504  0.999630  1.000000   \n",
       "WeirdML                          0.998606  0.999596  0.999171  0.998483   \n",
       "Winogrande                       0.999500  0.999454  1.000000  0.999480   \n",
       "\n",
       "anchor_benchmark                  CadEval   Cybench  ...  \\\n",
       "anchor_benchmark                                     ...   \n",
       "ANLI                             0.998788  0.998503  ...   \n",
       "ARC AI2                          0.998285  0.998381  ...   \n",
       "ARC-AGI                          1.000000  0.998588  ...   \n",
       "Aider polyglot                   0.999785  0.998285  ...   \n",
       "BBH                              0.998639  0.998444  ...   \n",
       "Balrog                           0.998555  1.000000  ...   \n",
       "BoolQ                            0.998809  0.999106  ...   \n",
       "CSQA2                            0.998280  0.998431  ...   \n",
       "CadEval                          1.000000  0.998479  ...   \n",
       "Cybench                          0.998479  1.000000  ...   \n",
       "DeepResearch Bench               0.999339  0.999160  ...   \n",
       "Factorio learning environment    0.998638  0.999495  ...   \n",
       "FrontierMath-2025-02-28-Private  0.998442  1.000000  ...   \n",
       "GPQA diamond                     0.999586  0.998198  ...   \n",
       "GSO-Bench                        0.998836  0.999437  ...   \n",
       "GeoBench                         0.998510  0.998399  ...   \n",
       "HellaSwag                        0.998576  0.998848  ...   \n",
       "MATH level 5                     0.998956  0.997666  ...   \n",
       "MMLU                             0.998405  0.998371  ...   \n",
       "OSUniverse                       0.999121  0.999451  ...   \n",
       "OSWorld                          0.998800  0.999600  ...   \n",
       "OTIS Mock AIME 2024-2025         0.999555  0.997926  ...   \n",
       "OpenBookQA                       0.998329  0.998363  ...   \n",
       "SWE-Bench verified               0.998451  0.999786  ...   \n",
       "SimpleBench                      0.999587  0.998836  ...   \n",
       "Terminal Bench                   0.998513  0.999615  ...   \n",
       "TriviaQA                         0.998778  0.998656  ...   \n",
       "VPCT                             0.998664  0.999786  ...   \n",
       "VideoMME                         0.998876  0.998520  ...   \n",
       "WeirdML                          0.998960  0.999436  ...   \n",
       "Winogrande                       0.999129  0.999444  ...   \n",
       "\n",
       "anchor_benchmark                 OTIS Mock AIME 2024-2025  OpenBookQA  \\\n",
       "anchor_benchmark                                                        \n",
       "ANLI                                             0.998511    0.999426   \n",
       "ARC AI2                                          0.997926    1.000000   \n",
       "ARC-AGI                                          0.999340    0.998229   \n",
       "Aider polyglot                                   0.999555    0.998555   \n",
       "BBH                                              0.998346    0.999596   \n",
       "Balrog                                           0.997987    0.998346   \n",
       "BoolQ                                            0.998360    0.999384   \n",
       "CSQA2                                            0.997904    0.999786   \n",
       "CadEval                                          0.999555    0.998329   \n",
       "Cybench                                          0.997926    0.998363   \n",
       "DeepResearch Bench                               0.998958    0.998589   \n",
       "Factorio learning environment                    0.998146    0.998841   \n",
       "FrontierMath-2025-02-28-Private                  0.997904    0.998413   \n",
       "GPQA diamond                                     0.999340    0.998683   \n",
       "GSO-Bench                                        0.998360    0.999107   \n",
       "GeoBench                                         0.998201    0.999786   \n",
       "HellaSwag                                        0.998146    0.999398   \n",
       "MATH level 5                                     0.999586    0.998369   \n",
       "MMLU                                             0.998080    1.000000   \n",
       "OSUniverse                                       0.998661    0.999454   \n",
       "OSWorld                                          0.998201    0.998391   \n",
       "OTIS Mock AIME 2024-2025                         1.000000    0.997987   \n",
       "OpenBookQA                                       0.997987    1.000000   \n",
       "SWE-Bench verified                               0.997928    0.998504   \n",
       "SimpleBench                                      0.999586    0.998058   \n",
       "Terminal Bench                                   0.998005    0.998643   \n",
       "TriviaQA                                         0.998385    0.999477   \n",
       "VPCT                                             0.998080    0.998357   \n",
       "VideoMME                                         0.998465    0.999609   \n",
       "WeirdML                                          0.998346    0.998443   \n",
       "Winogrande                                       0.998661    0.999444   \n",
       "\n",
       "anchor_benchmark                 SWE-Bench verified  SimpleBench  \\\n",
       "anchor_benchmark                                                   \n",
       "ANLI                                       0.998611     0.998364   \n",
       "ARC AI2                                    0.998520     0.998049   \n",
       "ARC-AGI                                    0.998521     0.999785   \n",
       "Aider polyglot                             0.998322     0.999234   \n",
       "BBH                                        0.998567     0.998255   \n",
       "Balrog                                     0.999609     0.998974   \n",
       "BoolQ                                      0.999171     0.998734   \n",
       "CSQA2                                      0.998564     0.998079   \n",
       "CadEval                                    0.998451     0.999587   \n",
       "Cybench                                    0.999786     0.998836   \n",
       "DeepResearch Bench                         0.999053     0.999553   \n",
       "Factorio learning environment              0.999787     0.998725   \n",
       "FrontierMath-2025-02-28-Private            1.000000     0.998735   \n",
       "GPQA diamond                               0.998262     0.999079   \n",
       "GSO-Bench                                  0.999630     0.998849   \n",
       "GeoBench                                   0.998532     0.998165   \n",
       "HellaSwag                                  0.998936     0.998471   \n",
       "MATH level 5                               0.997748     0.999077   \n",
       "MMLU                                       0.998509     0.998098   \n",
       "OSUniverse                                 0.999540     0.999057   \n",
       "OSWorld                                    0.999336     0.999335   \n",
       "OTIS Mock AIME 2024-2025                   0.997928     0.999586   \n",
       "OpenBookQA                                 0.998504     0.998058   \n",
       "SWE-Bench verified                         1.000000     0.998678   \n",
       "SimpleBench                                0.998678     1.000000   \n",
       "Terminal Bench                             1.000000     0.998671   \n",
       "TriviaQA                                   0.998763     0.998611   \n",
       "VPCT                                       0.999461     0.999141   \n",
       "VideoMME                                   0.998642     0.998741   \n",
       "WeirdML                                    0.999230     0.999551   \n",
       "Winogrande                                 0.999480     0.999083   \n",
       "\n",
       "anchor_benchmark                 Terminal Bench  TriviaQA      VPCT  VideoMME  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                                   0.998741  0.999132  0.998548  0.999136   \n",
       "ARC AI2                                0.998656  0.999615  0.998371  0.999786   \n",
       "ARC-AGI                                0.998562  0.998719  0.998809  0.998830   \n",
       "Aider polyglot                         0.998417  0.998908  0.998405  0.998972   \n",
       "BBH                                    0.998703  0.999197  0.998472  0.999230   \n",
       "Balrog                                 0.999477  0.998643  1.000000  0.998504   \n",
       "BoolQ                                  0.999250  0.999788  0.999121  0.999630   \n",
       "CSQA2                                  0.998693  0.999787  0.998419  1.000000   \n",
       "CadEval                                0.998513  0.998778  0.998664  0.998876   \n",
       "Cybench                                0.999615  0.998656  0.999786  0.998520   \n",
       "DeepResearch Bench                     0.999075  0.998784  0.999418  0.998662   \n",
       "Factorio learning environment          1.000000  0.999031  0.999325  0.998936   \n",
       "FrontierMath-2025-02-28-Private        0.999787  0.998693  0.999604  0.998564   \n",
       "GPQA diamond                           0.998370  0.998978  0.998292  0.999022   \n",
       "GSO-Bench                              0.999788  0.999250  0.999350  0.999171   \n",
       "GeoBench                               0.998671  0.999274  0.998412  0.999336   \n",
       "HellaSwag                              0.999031  1.000000  0.998850  0.999787   \n",
       "MATH level 5                           0.997865  0.998595  0.997739  0.998614   \n",
       "MMLU                                   0.998650  0.999365  0.998373  0.999461   \n",
       "OSUniverse                             0.999640  0.999540  0.999454  0.999480   \n",
       "OSWorld                                0.999274  0.998671  1.000000  0.998532   \n",
       "OTIS Mock AIME 2024-2025               0.998005  0.998385  0.998080  0.998465   \n",
       "OpenBookQA                             0.998643  0.999477  0.998357  0.999609   \n",
       "SWE-Bench verified                     1.000000  0.998763  0.999461  0.998642   \n",
       "SimpleBench                            0.998671  0.998611  0.999141  0.998741   \n",
       "Terminal Bench                         1.000000  0.998873  0.999365  0.998763   \n",
       "TriviaQA                               0.998873  1.000000  0.998650  1.000000   \n",
       "VPCT                                   0.999365  0.998650  1.000000  0.998509   \n",
       "VideoMME                               0.998763  1.000000  0.998509  1.000000   \n",
       "WeirdML                                0.999197  0.998703  0.999786  0.998567   \n",
       "Winogrande                             0.999540  0.999640  0.999474  0.999540   \n",
       "\n",
       "anchor_benchmark                  WeirdML  Winogrande  \n",
       "anchor_benchmark                                       \n",
       "ANLI                             0.998703    0.999527  \n",
       "ARC AI2                          0.998444    0.999451  \n",
       "ARC-AGI                          0.999141    0.999121  \n",
       "Aider polyglot                   0.998639    0.999121  \n",
       "BBH                              0.998606    0.999500  \n",
       "Balrog                           0.999596    0.999454  \n",
       "BoolQ                            0.999171    1.000000  \n",
       "CSQA2                            0.998483    0.999480  \n",
       "CadEval                          0.998960    0.999129  \n",
       "Cybench                          0.999436    0.999444  \n",
       "DeepResearch Bench               0.999785    0.999574  \n",
       "Factorio learning environment    0.999224    0.999640  \n",
       "FrontierMath-2025-02-28-Private  0.999312    0.999451  \n",
       "GPQA diamond                     0.998497    0.999105  \n",
       "GSO-Bench                        0.999321    0.999789  \n",
       "GeoBench                         0.998528    0.999474  \n",
       "HellaSwag                        0.998901    0.999789  \n",
       "MATH level 5                     0.997921    0.998614  \n",
       "MMLU                             0.998472    0.999454  \n",
       "OSUniverse                       0.999500    1.000000  \n",
       "OSWorld                          1.000000    0.999500  \n",
       "OTIS Mock AIME 2024-2025         0.998346    0.998661  \n",
       "OpenBookQA                       0.998443    0.999444  \n",
       "SWE-Bench verified               0.999230    0.999480  \n",
       "SimpleBench                      0.999551    0.999083  \n",
       "Terminal Bench                   0.999197    0.999540  \n",
       "TriviaQA                         0.998703    0.999640  \n",
       "VPCT                             0.999786    0.999474  \n",
       "VideoMME                         0.998567    0.999540  \n",
       "WeirdML                          1.000000    0.999527  \n",
       "Winogrande                       0.999527    1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per fit (difficulties):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.999232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.999029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.998995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.998969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.998969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.998941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.998941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.998938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.998919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.998919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.998911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.998911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.998907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.998907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.998856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.998856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.998843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.998843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.998839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.998481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.998444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 mean_rho\n",
       "anchor_benchmark                         \n",
       "OSUniverse                       0.999434\n",
       "Winogrande                       0.999434\n",
       "GSO-Bench                        0.999232\n",
       "BoolQ                            0.999232\n",
       "Factorio learning environment    0.999089\n",
       "HellaSwag                        0.999089\n",
       "TriviaQA                         0.999084\n",
       "DeepResearch Bench               0.999073\n",
       "VideoMME                         0.999063\n",
       "ANLI                             0.999029\n",
       "WeirdML                          0.999000\n",
       "BBH                              0.999000\n",
       "Terminal Bench                   0.998995\n",
       "OSWorld                          0.998969\n",
       "GeoBench                         0.998969\n",
       "VPCT                             0.998941\n",
       "MMLU                             0.998941\n",
       "SWE-Bench verified               0.998938\n",
       "Balrog                           0.998919\n",
       "OpenBookQA                       0.998919\n",
       "FrontierMath-2025-02-28-Private  0.998911\n",
       "CSQA2                            0.998911\n",
       "Cybench                          0.998907\n",
       "ARC AI2                          0.998907\n",
       "Aider polyglot                   0.998856\n",
       "CadEval                          0.998856\n",
       "GPQA diamond                     0.998843\n",
       "ARC-AGI                          0.998843\n",
       "SimpleBench                      0.998839\n",
       "OTIS Mock AIME 2024-2025         0.998481\n",
       "MATH level 5                     0.998444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spearman rank correlation across fits (model capabilities) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th>ANLI</th>\n",
       "      <th>ARC AI2</th>\n",
       "      <th>ARC-AGI</th>\n",
       "      <th>Aider polyglot</th>\n",
       "      <th>BBH</th>\n",
       "      <th>Balrog</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>CSQA2</th>\n",
       "      <th>CadEval</th>\n",
       "      <th>Cybench</th>\n",
       "      <th>...</th>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <th>OpenBookQA</th>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <th>SimpleBench</th>\n",
       "      <th>Terminal Bench</th>\n",
       "      <th>TriviaQA</th>\n",
       "      <th>VPCT</th>\n",
       "      <th>VideoMME</th>\n",
       "      <th>WeirdML</th>\n",
       "      <th>Winogrande</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor_benchmark                     ANLI   ARC AI2   ARC-AGI  Aider polyglot  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                             1.000000  0.999872  0.999940        0.999911   \n",
       "ARC AI2                          0.999872  1.000000  0.999858        0.999840   \n",
       "ARC-AGI                          0.999940  0.999858  1.000000        0.999957   \n",
       "Aider polyglot                   0.999911  0.999840  0.999957        1.000000   \n",
       "BBH                              0.999890  0.999986  0.999872        0.999854   \n",
       "Balrog                           0.999943  0.999847  0.999989        0.999961   \n",
       "BoolQ                            0.999904  0.999975  0.999908        0.999883   \n",
       "CSQA2                            0.999947  0.999844  0.999986        0.999957   \n",
       "CadEval                          0.999936  0.999865  0.999982        0.999979   \n",
       "Cybench                          0.999943  0.999840  0.999982        0.999961   \n",
       "DeepResearch Bench               0.999947  0.999844  0.999986        0.999957   \n",
       "Factorio learning environment    0.999947  0.999844  0.999986        0.999957   \n",
       "FrontierMath-2025-02-28-Private  0.999947  0.999844  0.999986        0.999957   \n",
       "GPQA diamond                     0.999940  0.999868  0.999986        0.999972   \n",
       "GSO-Bench                        0.999947  0.999844  0.999986        0.999957   \n",
       "GeoBench                         0.999947  0.999844  0.999986        0.999957   \n",
       "HellaSwag                        0.999900  0.999982  0.999883        0.999861   \n",
       "MATH level 5                     0.999936  0.999865  0.999982        0.999975   \n",
       "MMLU                             0.999876  0.999947  0.999915        0.999900   \n",
       "OSUniverse                       0.999943  0.999840  0.999982        0.999954   \n",
       "OSWorld                          0.999943  0.999858  0.999982        0.999954   \n",
       "OTIS Mock AIME 2024-2025         0.999929  0.999883  0.999975        0.999961   \n",
       "OpenBookQA                       0.999900  0.999979  0.999868        0.999851   \n",
       "SWE-Bench verified               0.999943  0.999840  0.999982        0.999964   \n",
       "SimpleBench                      0.999932  0.999851  0.999979        0.999975   \n",
       "Terminal Bench                   0.999940  0.999844  0.999986        0.999961   \n",
       "TriviaQA                         0.999950  0.999947  0.999925        0.999904   \n",
       "VPCT                             0.999943  0.999840  0.999982        0.999954   \n",
       "VideoMME                         0.999947  0.999844  0.999986        0.999957   \n",
       "WeirdML                          0.999929  0.999858  0.999975        0.999975   \n",
       "Winogrande                       0.999893  0.999986  0.999893        0.999872   \n",
       "\n",
       "anchor_benchmark                      BBH    Balrog     BoolQ     CSQA2  \\\n",
       "anchor_benchmark                                                          \n",
       "ANLI                             0.999890  0.999943  0.999904  0.999947   \n",
       "ARC AI2                          0.999986  0.999847  0.999975  0.999844   \n",
       "ARC-AGI                          0.999872  0.999989  0.999908  0.999986   \n",
       "Aider polyglot                   0.999854  0.999961  0.999883  0.999957   \n",
       "BBH                              1.000000  0.999861  0.999968  0.999858   \n",
       "Balrog                           0.999861  1.000000  0.999900  0.999996   \n",
       "BoolQ                            0.999968  0.999900  1.000000  0.999897   \n",
       "CSQA2                            0.999858  0.999996  0.999897  1.000000   \n",
       "CadEval                          0.999879  0.999986  0.999911  0.999982   \n",
       "Cybench                          0.999854  0.999993  0.999893  0.999996   \n",
       "DeepResearch Bench               0.999858  0.999996  0.999897  1.000000   \n",
       "Factorio learning environment    0.999858  0.999996  0.999897  1.000000   \n",
       "FrontierMath-2025-02-28-Private  0.999858  0.999996  0.999897  1.000000   \n",
       "GPQA diamond                     0.999883  0.999989  0.999915  0.999986   \n",
       "GSO-Bench                        0.999858  0.999996  0.999897  1.000000   \n",
       "GeoBench                         0.999858  0.999996  0.999897  1.000000   \n",
       "HellaSwag                        0.999979  0.999872  0.999975  0.999868   \n",
       "MATH level 5                     0.999879  0.999986  0.999911  0.999982   \n",
       "MMLU                             0.999961  0.999904  0.999947  0.999897   \n",
       "OSUniverse                       0.999854  0.999993  0.999890  0.999996   \n",
       "OSWorld                          0.999872  0.999993  0.999911  0.999996   \n",
       "OTIS Mock AIME 2024-2025         0.999897  0.999979  0.999929  0.999975   \n",
       "OpenBookQA                       0.999975  0.999858  0.999964  0.999854   \n",
       "SWE-Bench verified               0.999854  0.999993  0.999893  0.999996   \n",
       "SimpleBench                      0.999865  0.999982  0.999900  0.999979   \n",
       "Terminal Bench                   0.999858  0.999989  0.999897  0.999993   \n",
       "TriviaQA                         0.999964  0.999918  0.999961  0.999915   \n",
       "VPCT                             0.999854  0.999993  0.999893  0.999996   \n",
       "VideoMME                         0.999858  0.999996  0.999897  1.000000   \n",
       "WeirdML                          0.999872  0.999979  0.999904  0.999975   \n",
       "Winogrande                       0.999989  0.999883  0.999986  0.999879   \n",
       "\n",
       "anchor_benchmark                  CadEval   Cybench  ...  \\\n",
       "anchor_benchmark                                     ...   \n",
       "ANLI                             0.999936  0.999943  ...   \n",
       "ARC AI2                          0.999865  0.999840  ...   \n",
       "ARC-AGI                          0.999982  0.999982  ...   \n",
       "Aider polyglot                   0.999979  0.999961  ...   \n",
       "BBH                              0.999879  0.999854  ...   \n",
       "Balrog                           0.999986  0.999993  ...   \n",
       "BoolQ                            0.999911  0.999893  ...   \n",
       "CSQA2                            0.999982  0.999996  ...   \n",
       "CadEval                          1.000000  0.999979  ...   \n",
       "Cybench                          0.999979  1.000000  ...   \n",
       "DeepResearch Bench               0.999982  0.999996  ...   \n",
       "Factorio learning environment    0.999982  0.999996  ...   \n",
       "FrontierMath-2025-02-28-Private  0.999982  0.999996  ...   \n",
       "GPQA diamond                     0.999996  0.999982  ...   \n",
       "GSO-Bench                        0.999982  0.999996  ...   \n",
       "GeoBench                         0.999982  0.999996  ...   \n",
       "HellaSwag                        0.999886  0.999865  ...   \n",
       "MATH level 5                     0.999993  0.999979  ...   \n",
       "MMLU                             0.999925  0.999893  ...   \n",
       "OSUniverse                       0.999979  0.999993  ...   \n",
       "OSWorld                          0.999979  0.999993  ...   \n",
       "OTIS Mock AIME 2024-2025         0.999986  0.999972  ...   \n",
       "OpenBookQA                       0.999876  0.999851  ...   \n",
       "SWE-Bench verified               0.999986  0.999993  ...   \n",
       "SimpleBench                      0.999982  0.999982  ...   \n",
       "Terminal Bench                   0.999982  0.999989  ...   \n",
       "TriviaQA                         0.999929  0.999911  ...   \n",
       "VPCT                             0.999979  0.999993  ...   \n",
       "VideoMME                         0.999982  0.999996  ...   \n",
       "WeirdML                          0.999972  0.999972  ...   \n",
       "Winogrande                       0.999900  0.999876  ...   \n",
       "\n",
       "anchor_benchmark                 OTIS Mock AIME 2024-2025  OpenBookQA  \\\n",
       "anchor_benchmark                                                        \n",
       "ANLI                                             0.999929    0.999900   \n",
       "ARC AI2                                          0.999883    0.999979   \n",
       "ARC-AGI                                          0.999975    0.999868   \n",
       "Aider polyglot                                   0.999961    0.999851   \n",
       "BBH                                              0.999897    0.999975   \n",
       "Balrog                                           0.999979    0.999858   \n",
       "BoolQ                                            0.999929    0.999964   \n",
       "CSQA2                                            0.999975    0.999854   \n",
       "CadEval                                          0.999986    0.999876   \n",
       "Cybench                                          0.999972    0.999851   \n",
       "DeepResearch Bench                               0.999975    0.999854   \n",
       "Factorio learning environment                    0.999975    0.999854   \n",
       "FrontierMath-2025-02-28-Private                  0.999975    0.999854   \n",
       "GPQA diamond                                     0.999989    0.999879   \n",
       "GSO-Bench                                        0.999975    0.999854   \n",
       "GeoBench                                         0.999975    0.999854   \n",
       "HellaSwag                                        0.999904    0.999989   \n",
       "MATH level 5                                     0.999986    0.999876   \n",
       "MMLU                                             0.999943    0.999947   \n",
       "OSUniverse                                       0.999968    0.999851   \n",
       "OSWorld                                          0.999979    0.999868   \n",
       "OTIS Mock AIME 2024-2025                         1.000000    0.999893   \n",
       "OpenBookQA                                       0.999893    1.000000   \n",
       "SWE-Bench verified                               0.999972    0.999851   \n",
       "SimpleBench                                      0.999982    0.999861   \n",
       "Terminal Bench                                   0.999968    0.999854   \n",
       "TriviaQA                                         0.999943    0.999957   \n",
       "VPCT                                             0.999972    0.999851   \n",
       "VideoMME                                         0.999975    0.999854   \n",
       "WeirdML                                          0.999972    0.999868   \n",
       "Winogrande                                       0.999918    0.999979   \n",
       "\n",
       "anchor_benchmark                 SWE-Bench verified  SimpleBench  \\\n",
       "anchor_benchmark                                                   \n",
       "ANLI                                       0.999943     0.999932   \n",
       "ARC AI2                                    0.999840     0.999851   \n",
       "ARC-AGI                                    0.999982     0.999979   \n",
       "Aider polyglot                             0.999964     0.999975   \n",
       "BBH                                        0.999854     0.999865   \n",
       "Balrog                                     0.999993     0.999982   \n",
       "BoolQ                                      0.999893     0.999900   \n",
       "CSQA2                                      0.999996     0.999979   \n",
       "CadEval                                    0.999986     0.999982   \n",
       "Cybench                                    0.999993     0.999982   \n",
       "DeepResearch Bench                         0.999996     0.999979   \n",
       "Factorio learning environment              0.999996     0.999979   \n",
       "FrontierMath-2025-02-28-Private            0.999996     0.999979   \n",
       "GPQA diamond                               0.999982     0.999986   \n",
       "GSO-Bench                                  0.999996     0.999979   \n",
       "GeoBench                                   0.999996     0.999979   \n",
       "HellaSwag                                  0.999865     0.999876   \n",
       "MATH level 5                               0.999979     0.999982   \n",
       "MMLU                                       0.999893     0.999908   \n",
       "OSUniverse                                 0.999993     0.999975   \n",
       "OSWorld                                    0.999993     0.999975   \n",
       "OTIS Mock AIME 2024-2025                   0.999972     0.999982   \n",
       "OpenBookQA                                 0.999851     0.999861   \n",
       "SWE-Bench verified                         1.000000     0.999975   \n",
       "SimpleBench                                0.999975     1.000000   \n",
       "Terminal Bench                             0.999996     0.999972   \n",
       "TriviaQA                                   0.999911     0.999918   \n",
       "VPCT                                       0.999993     0.999975   \n",
       "VideoMME                                   0.999996     0.999979   \n",
       "WeirdML                                    0.999972     0.999979   \n",
       "Winogrande                                 0.999876     0.999886   \n",
       "\n",
       "anchor_benchmark                 Terminal Bench  TriviaQA      VPCT  VideoMME  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                                   0.999940  0.999950  0.999943  0.999947   \n",
       "ARC AI2                                0.999844  0.999947  0.999840  0.999844   \n",
       "ARC-AGI                                0.999986  0.999925  0.999982  0.999986   \n",
       "Aider polyglot                         0.999961  0.999904  0.999954  0.999957   \n",
       "BBH                                    0.999858  0.999964  0.999854  0.999858   \n",
       "Balrog                                 0.999989  0.999918  0.999993  0.999996   \n",
       "BoolQ                                  0.999897  0.999961  0.999893  0.999897   \n",
       "CSQA2                                  0.999993  0.999915  0.999996  1.000000   \n",
       "CadEval                                0.999982  0.999929  0.999979  0.999982   \n",
       "Cybench                                0.999989  0.999911  0.999993  0.999996   \n",
       "DeepResearch Bench                     0.999993  0.999915  0.999996  1.000000   \n",
       "Factorio learning environment          0.999993  0.999915  0.999996  1.000000   \n",
       "FrontierMath-2025-02-28-Private        0.999993  0.999915  0.999996  1.000000   \n",
       "GPQA diamond                           0.999979  0.999932  0.999982  0.999986   \n",
       "GSO-Bench                              0.999993  0.999915  0.999996  1.000000   \n",
       "GeoBench                               0.999993  0.999915  0.999996  1.000000   \n",
       "HellaSwag                              0.999868  0.999968  0.999865  0.999868   \n",
       "MATH level 5                           0.999975  0.999929  0.999979  0.999982   \n",
       "MMLU                                   0.999897  0.999954  0.999893  0.999897   \n",
       "OSUniverse                             0.999989  0.999908  0.999993  0.999996   \n",
       "OSWorld                                0.999989  0.999925  0.999993  0.999996   \n",
       "OTIS Mock AIME 2024-2025               0.999968  0.999943  0.999972  0.999975   \n",
       "OpenBookQA                             0.999854  0.999957  0.999851  0.999854   \n",
       "SWE-Bench verified                     0.999996  0.999911  0.999993  0.999996   \n",
       "SimpleBench                            0.999972  0.999918  0.999975  0.999979   \n",
       "Terminal Bench                         1.000000  0.999915  0.999989  0.999993   \n",
       "TriviaQA                               0.999915  1.000000  0.999911  0.999915   \n",
       "VPCT                                   0.999989  0.999911  1.000000  0.999996   \n",
       "VideoMME                               0.999993  0.999915  0.999996  1.000000   \n",
       "WeirdML                                0.999968  0.999922  0.999972  0.999975   \n",
       "Winogrande                             0.999879  0.999964  0.999876  0.999879   \n",
       "\n",
       "anchor_benchmark                  WeirdML  Winogrande  \n",
       "anchor_benchmark                                       \n",
       "ANLI                             0.999929    0.999893  \n",
       "ARC AI2                          0.999858    0.999986  \n",
       "ARC-AGI                          0.999975    0.999893  \n",
       "Aider polyglot                   0.999975    0.999872  \n",
       "BBH                              0.999872    0.999989  \n",
       "Balrog                           0.999979    0.999883  \n",
       "BoolQ                            0.999904    0.999986  \n",
       "CSQA2                            0.999975    0.999879  \n",
       "CadEval                          0.999972    0.999900  \n",
       "Cybench                          0.999972    0.999876  \n",
       "DeepResearch Bench               0.999975    0.999879  \n",
       "Factorio learning environment    0.999975    0.999879  \n",
       "FrontierMath-2025-02-28-Private  0.999975    0.999879  \n",
       "GPQA diamond                     0.999975    0.999904  \n",
       "GSO-Bench                        0.999975    0.999879  \n",
       "GeoBench                         0.999975    0.999879  \n",
       "HellaSwag                        0.999883    0.999982  \n",
       "MATH level 5                     0.999979    0.999900  \n",
       "MMLU                             0.999915    0.999968  \n",
       "OSUniverse                       0.999968    0.999876  \n",
       "OSWorld                          0.999979    0.999893  \n",
       "OTIS Mock AIME 2024-2025         0.999972    0.999918  \n",
       "OpenBookQA                       0.999868    0.999979  \n",
       "SWE-Bench verified               0.999972    0.999876  \n",
       "SimpleBench                      0.999979    0.999886  \n",
       "Terminal Bench                   0.999968    0.999879  \n",
       "TriviaQA                         0.999922    0.999964  \n",
       "VPCT                             0.999972    0.999876  \n",
       "VideoMME                         0.999975    0.999879  \n",
       "WeirdML                          1.000000    0.999890  \n",
       "Winogrande                       0.999890    1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per fit (capabilities):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.999959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.999956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.999955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.999955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.999952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.999929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.999917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 mean_rho\n",
       "anchor_benchmark                         \n",
       "GPQA diamond                     0.999961\n",
       "OSWorld                          0.999960\n",
       "Balrog                           0.999959\n",
       "VideoMME                         0.999958\n",
       "GeoBench                         0.999958\n",
       "DeepResearch Bench               0.999958\n",
       "GSO-Bench                        0.999958\n",
       "FrontierMath-2025-02-28-Private  0.999958\n",
       "Factorio learning environment    0.999958\n",
       "CSQA2                            0.999958\n",
       "CadEval                          0.999958\n",
       "MATH level 5                     0.999958\n",
       "OTIS Mock AIME 2024-2025         0.999957\n",
       "ARC-AGI                          0.999956\n",
       "SWE-Bench verified               0.999956\n",
       "Cybench                          0.999955\n",
       "VPCT                             0.999955\n",
       "Terminal Bench                   0.999954\n",
       "OSUniverse                       0.999954\n",
       "SimpleBench                      0.999952\n",
       "WeirdML                          0.999950\n",
       "Aider polyglot                   0.999936\n",
       "TriviaQA                         0.999929\n",
       "ANLI                             0.999929\n",
       "BoolQ                            0.999917\n",
       "MMLU                             0.999916\n",
       "Winogrande                       0.999907\n",
       "HellaSwag                        0.999899\n",
       "BBH                              0.999891\n",
       "OpenBookQA                       0.999888\n",
       "ARC AI2                          0.999879"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4)  Rank correlation across fits (Spearman) for difficulties and capabilities\n",
    "#     Robust to duplicates and missing values\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def _spearman_corr_from_long(df_long: pd.DataFrame, index_col: str, columns_col: str, values_col: str) -> pd.DataFrame:\n",
    "    # Allow duplicates by aggregating with mean; coerce to numeric in case of stray dtypes\n",
    "    wide = df_long.pivot_table(\n",
    "        index=index_col,\n",
    "        columns=columns_col,\n",
    "        values=values_col,\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    wide = wide.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Drop rows that are entirely NaN\n",
    "    wide = wide.dropna(axis=0, how=\"all\")\n",
    "\n",
    "    # Need at least two fits (columns) to compute a correlation matrix\n",
    "    if wide.shape[1] < 2:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Compute Spearman by ranking then applying Pearson correlation\n",
    "    ranks = wide.rank(axis=0, method=\"average\", na_option=\"keep\")\n",
    "    corr = ranks.corr(method=\"pearson\", min_periods=2)\n",
    "    return corr\n",
    "\n",
    "print(\"=== Spearman rank correlation across fits (benchmark difficulties) ===\")\n",
    "spearman_difficulty = _spearman_corr_from_long(\n",
    "    difficulty_long,\n",
    "    index_col=\"benchmark_name\",\n",
    "    columns_col=\"anchor_benchmark\",\n",
    "    values_col=\"estimated_difficulty\",\n",
    ")\n",
    "if spearman_difficulty.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for difficulties.\")\n",
    "else:\n",
    "    display(spearman_difficulty)\n",
    "    mean_rho_difficulty = spearman_difficulty.apply(\n",
    "        lambda s: s.drop(labels=s.name).mean(), axis=0\n",
    "    ).sort_values(ascending=False).to_frame(\"mean_rho\")\n",
    "    print(\"\\nMean off-diagonal Spearman per fit (difficulties):\")\n",
    "    display(mean_rho_difficulty)\n",
    "\n",
    "print(\"\\n=== Spearman rank correlation across fits (model capabilities) ===\")\n",
    "spearman_capability = _spearman_corr_from_long(\n",
    "    capability_long,\n",
    "    index_col=\"model\",\n",
    "    columns_col=\"anchor_benchmark\",\n",
    "    values_col=\"estimated_capability\",\n",
    ")\n",
    "if spearman_capability.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for capabilities.\")\n",
    "else:\n",
    "    display(spearman_capability)\n",
    "    mean_rho_capability = spearman_capability.apply(\n",
    "        lambda s: s.drop(labels=s.name).mean(), axis=0\n",
    "    ).sort_values(ascending=False).to_frame(\"mean_rho\")\n",
    "    print(\"\\nMean off-diagonal Spearman per fit (capabilities):\")\n",
    "    display(mean_rho_capability)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bf280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3672e+01, final cost 2.5757e+00, first-order optimality 7.42e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3849e+01, final cost 2.5774e+00, first-order optimality 9.07e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3905e+01, final cost 2.5777e+00, first-order optimality 2.53e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3986e+01, final cost 2.5791e+00, first-order optimality 3.92e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.3994e+01, final cost 2.5796e+00, first-order optimality 9.97e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.3557e+01, final cost 2.5788e+00, first-order optimality 6.74e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.3932e+01, final cost 2.5812e+00, first-order optimality 9.82e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 21, initial cost 3.3987e+01, final cost 2.5831e+00, first-order optimality 3.58e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.3758e+01, final cost 2.5854e+00, first-order optimality 1.18e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3885e+01, final cost 2.5860e+00, first-order optimality 1.88e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 22, initial cost 3.3475e+01, final cost 2.5858e+00, first-order optimality 5.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 38, initial cost 3.3480e+01, final cost 2.5857e+00, first-order optimality 1.05e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3668e+01, final cost 2.5863e+00, first-order optimality 3.89e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 22, initial cost 3.3944e+01, final cost 2.5870e+00, first-order optimality 2.83e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.3975e+01, final cost 2.5872e+00, first-order optimality 2.86e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3782e+01, final cost 2.5872e+00, first-order optimality 1.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3664e+01, final cost 2.5873e+00, first-order optimality 1.29e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.4005e+01, final cost 2.5884e+00, first-order optimality 1.19e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4065e+01, final cost 2.5887e+00, first-order optimality 1.46e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3450e+01, final cost 2.5886e+00, first-order optimality 3.13e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.3359e+01, final cost 2.5888e+00, first-order optimality 2.99e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.2685e+01, final cost 2.5890e+00, first-order optimality 5.73e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.3013e+01, final cost 2.5896e+00, first-order optimality 1.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4301e+01, final cost 2.5899e+00, first-order optimality 1.05e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4465e+01, final cost 2.5901e+00, first-order optimality 2.19e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4340e+01, final cost 2.5906e+00, first-order optimality 1.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.4019e+01, final cost 2.5907e+00, first-order optimality 1.84e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3588e+01, final cost 2.5912e+00, first-order optimality 2.12e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 3.3534e+01, final cost 2.5921e+00, first-order optimality 3.07e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.4467e+01, final cost 2.5928e+00, first-order optimality 1.82e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.4416e+01, final cost 2.5934e+00, first-order optimality 2.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4370e+01, final cost 2.5940e+00, first-order optimality 4.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4559e+01, final cost 2.5942e+00, first-order optimality 1.31e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.4133e+01, final cost 2.5941e+00, first-order optimality 1.47e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 3.5408e+01, final cost 2.5942e+00, first-order optimality 5.37e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.5555e+01, final cost 2.5946e+00, first-order optimality 2.67e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.4312e+01, final cost 2.5946e+00, first-order optimality 5.31e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 40, initial cost 3.3392e+01, final cost 2.5938e+00, first-order optimality 2.71e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3647e+01, final cost 2.5948e+00, first-order optimality 3.93e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3958e+01, final cost 2.5953e+00, first-order optimality 2.38e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.4294e+01, final cost 2.5957e+00, first-order optimality 2.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4807e+01, final cost 2.5960e+00, first-order optimality 7.59e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3345e+01, final cost 2.5957e+00, first-order optimality 2.39e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.2074e+01, final cost 2.5825e+00, first-order optimality 6.41e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.2923e+01, final cost 2.5965e+00, first-order optimality 1.00e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.4859e+01, final cost 2.5974e+00, first-order optimality 2.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 40, initial cost 3.5009e+01, final cost 2.5979e+00, first-order optimality 1.45e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3978e+01, final cost 2.5983e+00, first-order optimality 1.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.3840e+01, final cost 2.5973e+00, first-order optimality 2.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.3974e+01, final cost 2.5986e+00, first-order optimality 1.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3875e+01, final cost 2.5998e+00, first-order optimality 4.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.4245e+01, final cost 2.6000e+00, first-order optimality 8.52e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 22, initial cost 3.4290e+01, final cost 2.6003e+00, first-order optimality 3.57e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4084e+01, final cost 2.6003e+00, first-order optimality 2.91e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 39, initial cost 3.3982e+01, final cost 2.6003e+00, first-order optimality 3.71e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3754e+01, final cost 2.6006e+00, first-order optimality 9.84e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 41, initial cost 3.4079e+01, final cost 2.6007e+00, first-order optimality 1.66e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 40, initial cost 3.4804e+01, final cost 2.6010e+00, first-order optimality 5.49e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4971e+01, final cost 2.6017e+00, first-order optimality 4.33e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.5281e+01, final cost 2.6019e+00, first-order optimality 5.33e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.4875e+01, final cost 2.6018e+00, first-order optimality 1.55e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3947e+01, final cost 2.6019e+00, first-order optimality 1.79e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 37, initial cost 3.3783e+01, final cost 2.6022e+00, first-order optimality 1.46e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3237e+01, final cost 2.6013e+00, first-order optimality 6.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3168e+01, final cost 2.6015e+00, first-order optimality 6.28e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3940e+01, final cost 2.6026e+00, first-order optimality 3.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 3.4161e+01, final cost 2.6014e+00, first-order optimality 4.18e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 51, initial cost 3.4579e+01, final cost 2.6016e+00, first-order optimality 9.46e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.4660e+01, final cost 2.6028e+00, first-order optimality 3.27e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.4033e+01, final cost 2.6029e+00, first-order optimality 3.89e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4487e+01, final cost 2.6032e+00, first-order optimality 1.19e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.4750e+01, final cost 2.6027e+00, first-order optimality 2.33e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.4098e+01, final cost 2.6025e+00, first-order optimality 6.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 40, initial cost 3.3695e+01, final cost 2.6033e+00, first-order optimality 1.85e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.2874e+01, final cost 2.6021e+00, first-order optimality 3.39e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.2685e+01, final cost 2.6023e+00, first-order optimality 4.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.3170e+01, final cost 2.6037e+00, first-order optimality 1.57e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 50, initial cost 3.3268e+01, final cost 2.6131e+00, first-order optimality 1.87e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3209e+01, final cost 2.6131e+00, first-order optimality 3.10e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3215e+01, final cost 2.6038e+00, first-order optimality 1.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.3057e+01, final cost 2.6039e+00, first-order optimality 6.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 36, initial cost 3.2551e+01, final cost 2.6027e+00, first-order optimality 1.15e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 41, initial cost 3.2822e+01, final cost 2.5914e+00, first-order optimality 2.90e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 3.3233e+01, final cost 2.6018e+00, first-order optimality 5.38e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3344e+01, final cost 2.6038e+00, first-order optimality 1.00e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.3278e+01, final cost 2.6037e+00, first-order optimality 3.40e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 48, initial cost 3.3686e+01, final cost 2.6031e+00, first-order optimality 1.33e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.3506e+01, final cost 2.6032e+00, first-order optimality 3.11e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 39, initial cost 3.3493e+01, final cost 2.6031e+00, first-order optimality 3.79e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.3292e+01, final cost 2.6014e+00, first-order optimality 4.56e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.2759e+01, final cost 2.5933e+00, first-order optimality 2.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 48, initial cost 3.2470e+01, final cost 2.5904e+00, first-order optimality 1.73e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 44, initial cost 3.2734e+01, final cost 2.5923e+00, first-order optimality 2.16e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2824e+01, final cost 2.5933e+00, first-order optimality 8.83e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 44, initial cost 3.2458e+01, final cost 2.5921e+00, first-order optimality 1.62e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2473e+01, final cost 2.5920e+00, first-order optimality 2.59e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 43, initial cost 3.2617e+01, final cost 2.5934e+00, first-order optimality 4.24e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2935e+01, final cost 2.5984e+00, first-order optimality 2.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.3182e+01, final cost 2.5980e+00, first-order optimality 6.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.3137e+01, final cost 2.5962e+00, first-order optimality 7.52e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2918e+01, final cost 2.5954e+00, first-order optimality 3.58e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.2530e+01, final cost 2.5893e+00, first-order optimality 1.40e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.2756e+01, final cost 2.5920e+00, first-order optimality 2.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2640e+01, final cost 2.5932e+00, first-order optimality 1.63e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.2422e+01, final cost 2.5931e+00, first-order optimality 1.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2709e+01, final cost 2.5930e+00, first-order optimality 5.24e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3035e+01, final cost 2.5924e+00, first-order optimality 2.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.2828e+01, final cost 2.5902e+00, first-order optimality 3.63e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.3068e+01, final cost 2.5914e+00, first-order optimality 1.57e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.2739e+01, final cost 2.5916e+00, first-order optimality 1.56e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.2698e+01, final cost 2.5913e+00, first-order optimality 2.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 41, initial cost 3.2725e+01, final cost 2.5912e+00, first-order optimality 1.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.2551e+01, final cost 2.5906e+00, first-order optimality 4.56e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2715e+01, final cost 2.5885e+00, first-order optimality 8.51e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.2563e+01, final cost 2.5884e+00, first-order optimality 2.01e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 37, initial cost 3.2893e+01, final cost 2.5881e+00, first-order optimality 1.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2919e+01, final cost 2.5874e+00, first-order optimality 1.23e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 3.2584e+01, final cost 2.5874e+00, first-order optimality 1.02e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 3.2587e+01, final cost 2.5859e+00, first-order optimality 7.96e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.2561e+01, final cost 2.5869e+00, first-order optimality 9.67e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.2538e+01, final cost 2.5867e+00, first-order optimality 1.60e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2977e+01, final cost 2.5857e+00, first-order optimality 5.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2979e+01, final cost 2.5848e+00, first-order optimality 5.02e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 44, initial cost 3.2633e+01, final cost 2.5838e+00, first-order optimality 4.88e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 3.3001e+01, final cost 2.5832e+00, first-order optimality 3.73e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.2980e+01, final cost 2.5833e+00, first-order optimality 8.88e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2695e+01, final cost 2.5829e+00, first-order optimality 7.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.2734e+01, final cost 2.5813e+00, first-order optimality 5.34e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 42, initial cost 3.2766e+01, final cost 2.5787e+00, first-order optimality 9.10e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 3.2765e+01, final cost 2.5778e+00, first-order optimality 5.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2712e+01, final cost 2.5774e+00, first-order optimality 2.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2679e+01, final cost 2.5768e+00, first-order optimality 1.82e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2655e+01, final cost 2.5760e+00, first-order optimality 6.83e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 22, initial cost 3.2644e+01, final cost 2.5758e+00, first-order optimality 1.10e-03.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 39, initial cost 3.2750e+01, final cost 2.5748e+00, first-order optimality 1.02e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 3.2829e+01, final cost 2.5742e+00, first-order optimality 1.05e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 21, initial cost 3.2844e+01, final cost 2.5737e+00, first-order optimality 6.57e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2846e+01, final cost 2.5732e+00, first-order optimality 1.12e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.2727e+01, final cost 2.5724e+00, first-order optimality 3.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 3.2703e+01, final cost 2.5716e+00, first-order optimality 9.02e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 38, initial cost 3.2855e+01, final cost 2.5712e+00, first-order optimality 6.25e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 41, initial cost 3.2855e+01, final cost 2.5709e+00, first-order optimality 1.06e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 3.2730e+01, final cost 2.5708e+00, first-order optimality 1.51e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 3.2795e+01, final cost 2.5702e+00, first-order optimality 3.90e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 3.2727e+01, final cost 2.5687e+00, first-order optimality 1.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 3.2656e+01, final cost 2.5684e+00, first-order optimality 1.75e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 3.2868e+01, final cost 2.5675e+00, first-order optimality 3.34e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 3.2830e+01, final cost 2.5608e+00, first-order optimality 6.91e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 3.2888e+01, final cost 2.5603e+00, first-order optimality 3.31e-04.\n",
      "Processed 149 model pair combinations\n",
      "Failed: 0 combinations\n"
     ]
    }
   ],
   "source": [
    "all_runs = {}           # will map model_pair -> dict of outputs\n",
    "failed    = []          # keep track of anything that errors out\n",
    "\n",
    "# --- Create model pairs for anchoring -------------------------------------\n",
    "# Get unique models with their estimated capabilities\n",
    "models_with_capability = df_cm_anchor[['model', 'estimated_capability']].drop_duplicates()\n",
    "models_list = models_with_capability.to_dict('records')\n",
    "\n",
    "# Create pairs of models to use as anchors\n",
    "# You can adjust this logic based on your needs\n",
    "model_pairs = []\n",
    "for i in range(len(models_list) - 1):\n",
    "    # Each model paired with the next one\n",
    "    model_pairs.append((models_list[i], models_list[i + 1]))\n",
    "    \n",
    "# Alternatively, you could pair each model with a fixed reference model:\n",
    "# reference_model = models_list[0]  # or find a specific model\n",
    "# model_pairs = [(reference_model, model) for model in models_list[1:]]\n",
    "\n",
    "# --- loop over model pairs ------------------------------------------------\n",
    "for model1_info, model2_info in model_pairs:\n",
    "    anchor_model1 = model1_info['model']\n",
    "    anchor_model1_capability = float(model1_info['estimated_capability'])\n",
    "    anchor_model2 = model2_info['model']\n",
    "    anchor_model2_capability = float(model2_info['estimated_capability'])\n",
    "    \n",
    "    # Create a key for storing results\n",
    "    pair_key = f\"{anchor_model1}_{anchor_model2}\"\n",
    "    \n",
    "    try:\n",
    "        df, df_cm, df_db = fit_statistical_model(\n",
    "            scores_df,\n",
    "            anchor_mode=\"model\",\n",
    "            anchor_benchmark=anchor_benchmark,  # Keep the same benchmark\n",
    "            anchor_difficulty=anchor_difficulty,  # Keep the same difficulty\n",
    "            anchor_slope=anchor_slope,          # Keep the same slope\n",
    "            anchor_model1=anchor_model1,\n",
    "            anchor_model1_capability=anchor_model1_capability,\n",
    "            anchor_model2=anchor_model2,\n",
    "            anchor_model2_capability=anchor_model2_capability\n",
    "        )\n",
    "        \n",
    "        all_runs[pair_key] = {\n",
    "            \"df1\": df,\n",
    "            \"df_cm1\": df_cm,\n",
    "            \"df_db\": df_db,\n",
    "            # cache the anchor values for reference\n",
    "            \"anchor_model1\": anchor_model1,\n",
    "            \"anchor_model1_capability\": anchor_model1_capability,\n",
    "            \"anchor_model2\": anchor_model2,\n",
    "            \"anchor_model2_capability\": anchor_model2_capability,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        failed.append((pair_key, str(e)))\n",
    "\n",
    "# --- post-processing (optional) ----------------------------------------------\n",
    "# 1) quick glance at what failed\n",
    "if failed:\n",
    "    print(\"Model pairs that raised errors:\", failed)\n",
    "\n",
    "# 2) pull out the model capability estimates across all runs\n",
    "summary_models = pd.concat(\n",
    "    {k: v[\"df_cm1\"][[\"model\", \"estimated_capability\"]]\n",
    "     for k, v in all_runs.items()},\n",
    "    names=[\"anchor_model_pair\"]\n",
    ").reset_index(level=0)\n",
    "\n",
    "# 3) pull out the benchmark difficulty/slope estimates across all runs\n",
    "summary_benchmarks = pd.concat(\n",
    "    {k: v[\"df_db\"][[\"benchmark_name\", \"estimated_difficulty\", \"estimated_slope\"]]\n",
    "     for k, v in all_runs.items()},\n",
    "    names=[\"anchor_model_pair\"]\n",
    ").reset_index(level=0)\n",
    "\n",
    "print(f\"Processed {len(all_runs)} model pair combinations\")\n",
    "print(f\"Failed: {len(failed)} combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce8f885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Capabilities and difficulties over time with std error bars (from variation tables)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Expect these to exist from earlier cells:\n",
    "# - capability_stats: index=model, columns include ['mean','std']\n",
    "# - difficulty_stats: index=benchmark_name, columns include ['mean','std']\n",
    "# - df_cm_anchor: per-model table with 'model' and 'date' (string) or 'date_obj'\n",
    "# - df_db_anchor: per-benchmark table with 'benchmark_name' and 'benchmark_release_date'\n",
    "\n",
    "# Merge stats with model release dates\n",
    "cap_stats_df = capability_stats.reset_index()  # 'model', 'mean', 'std', ...\n",
    "model_dates = df_cm_anchor[[\"model\", \"date\"]].drop_duplicates(subset=[\"model\"]).copy()\n",
    "model_dates[\"date_obj\"] = pd.to_datetime(model_dates[\"date\"], errors=\"coerce\")\n",
    "cap_plot_df = (\n",
    "    cap_stats_df.merge(model_dates, on=\"model\", how=\"left\")\n",
    "    .dropna(subset=[\"date_obj\", \"mean\"])  # require a date and mean\n",
    "    .sort_values(\"date_obj\")\n",
    ")\n",
    "cap_plot_df[\"std\"] = cap_plot_df[\"std\"].fillna(0.0)\n",
    "\n",
    "# Merge stats with benchmark release dates\n",
    "diff_stats_df = difficulty_stats.reset_index()  # 'benchmark_name', 'mean', 'std', ...\n",
    "bench_dates = df_db_anchor[[\"benchmark_name\", \"benchmark_release_date\"]].drop_duplicates(subset=[\"benchmark_name\"]).copy()\n",
    "bench_dates[\"benchmark_release_date\"] = pd.to_datetime(bench_dates[\"benchmark_release_date\"], errors=\"coerce\")\n",
    "diff_plot_df = (\n",
    "    diff_stats_df.merge(bench_dates, on=\"benchmark_name\", how=\"left\")\n",
    "    .dropna(subset=[\"benchmark_release_date\", \"mean\"])  # require a date and mean\n",
    "    .sort_values(\"benchmark_release_date\")\n",
    ")\n",
    "diff_plot_df[\"std\"] = diff_plot_df[\"std\"].fillna(0.0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax.errorbar(\n",
    "    cap_plot_df[\"date_obj\"],\n",
    "    cap_plot_df[\"mean\"],\n",
    "    yerr=cap_plot_df[\"std\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"tab:blue\",\n",
    "    ecolor=\"#8ec2ff\",\n",
    "    elinewidth=1,\n",
    "    capsize=3,\n",
    "    alpha=0.9,\n",
    "    label=\"Model capability (mean ± std)\"\n",
    ")\n",
    "\n",
    "ax.errorbar(\n",
    "    diff_plot_df[\"benchmark_release_date\"],\n",
    "    diff_plot_df[\"mean\"],\n",
    "    yerr=diff_plot_df[\"std\"],\n",
    "    fmt=\"s\",\n",
    "    color=\"tab:orange\",\n",
    "    ecolor=\"#ffd39b\",\n",
    "    elinewidth=1,\n",
    "    capsize=3,\n",
    "    alpha=0.9,\n",
    "    label=\"Benchmark difficulty (mean ± std)\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Release date\", fontsize=14)\n",
    "ax.set_ylabel(\"Estimated capability / difficulty\", fontsize=14)\n",
    "ax.set_title(\"AI model capabilities & benchmark difficulties (with std error bars)\", fontsize=18)\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "ax.grid(True, alpha=0.25, linestyle='--')\n",
    "ax.legend(frameon=False, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"capabilities_and_benchmarks_over_time.pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cedf969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Variation in benchmark difficulties across model anchor pairs ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.576904</td>\n",
       "      <td>0.171304</td>\n",
       "      <td>0.148446</td>\n",
       "      <td>0.853594</td>\n",
       "      <td>149</td>\n",
       "      <td>0.295938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>-0.031989</td>\n",
       "      <td>0.221886</td>\n",
       "      <td>-0.572622</td>\n",
       "      <td>0.263367</td>\n",
       "      <td>149</td>\n",
       "      <td>-6.913003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>1.948494</td>\n",
       "      <td>0.273432</td>\n",
       "      <td>1.213769</td>\n",
       "      <td>2.212920</td>\n",
       "      <td>149</td>\n",
       "      <td>0.139858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>1.614525</td>\n",
       "      <td>0.237116</td>\n",
       "      <td>0.937043</td>\n",
       "      <td>1.854031</td>\n",
       "      <td>149</td>\n",
       "      <td>0.146371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.324886</td>\n",
       "      <td>0.180106</td>\n",
       "      <td>-0.148678</td>\n",
       "      <td>0.584454</td>\n",
       "      <td>149</td>\n",
       "      <td>0.552502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>2.368297</td>\n",
       "      <td>0.332024</td>\n",
       "      <td>1.558319</td>\n",
       "      <td>2.714604</td>\n",
       "      <td>149</td>\n",
       "      <td>0.139724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>-1.218257</td>\n",
       "      <td>0.447152</td>\n",
       "      <td>-2.080091</td>\n",
       "      <td>-0.602495</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.365809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>-0.329824</td>\n",
       "      <td>0.161517</td>\n",
       "      <td>-0.760793</td>\n",
       "      <td>-0.125501</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.488062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>1.653583</td>\n",
       "      <td>0.240238</td>\n",
       "      <td>0.970420</td>\n",
       "      <td>1.892235</td>\n",
       "      <td>149</td>\n",
       "      <td>0.144795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>2.624834</td>\n",
       "      <td>0.342001</td>\n",
       "      <td>1.813172</td>\n",
       "      <td>3.004368</td>\n",
       "      <td>149</td>\n",
       "      <td>0.129856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>2.026143</td>\n",
       "      <td>0.281046</td>\n",
       "      <td>1.281005</td>\n",
       "      <td>2.298657</td>\n",
       "      <td>149</td>\n",
       "      <td>0.138244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>3.089380</td>\n",
       "      <td>0.374788</td>\n",
       "      <td>2.255571</td>\n",
       "      <td>3.638008</td>\n",
       "      <td>149</td>\n",
       "      <td>0.120907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>2.717558</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>1.879115</td>\n",
       "      <td>3.108806</td>\n",
       "      <td>149</td>\n",
       "      <td>0.131420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.187227</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>0.596881</td>\n",
       "      <td>1.460580</td>\n",
       "      <td>149</td>\n",
       "      <td>0.168088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>3.344705</td>\n",
       "      <td>0.279304</td>\n",
       "      <td>2.650416</td>\n",
       "      <td>3.626853</td>\n",
       "      <td>149</td>\n",
       "      <td>0.083226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.200472</td>\n",
       "      <td>0.237256</td>\n",
       "      <td>-0.518416</td>\n",
       "      <td>0.582646</td>\n",
       "      <td>149</td>\n",
       "      <td>1.179508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>-0.822732</td>\n",
       "      <td>0.365867</td>\n",
       "      <td>-1.566462</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.443203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>1.148314</td>\n",
       "      <td>0.199474</td>\n",
       "      <td>0.564125</td>\n",
       "      <td>1.427669</td>\n",
       "      <td>149</td>\n",
       "      <td>0.173126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.133153</td>\n",
       "      <td>0.199575</td>\n",
       "      <td>-0.377287</td>\n",
       "      <td>0.385396</td>\n",
       "      <td>149</td>\n",
       "      <td>1.493795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>3.954557</td>\n",
       "      <td>0.356858</td>\n",
       "      <td>3.197051</td>\n",
       "      <td>4.504084</td>\n",
       "      <td>149</td>\n",
       "      <td>0.089936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>2.169621</td>\n",
       "      <td>0.263194</td>\n",
       "      <td>1.457812</td>\n",
       "      <td>2.463596</td>\n",
       "      <td>149</td>\n",
       "      <td>0.120901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>1.628528</td>\n",
       "      <td>0.239105</td>\n",
       "      <td>0.947641</td>\n",
       "      <td>1.867289</td>\n",
       "      <td>149</td>\n",
       "      <td>0.146329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.013585</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>-0.518672</td>\n",
       "      <td>0.298280</td>\n",
       "      <td>149</td>\n",
       "      <td>15.795612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>2.858395</td>\n",
       "      <td>0.273963</td>\n",
       "      <td>2.190634</td>\n",
       "      <td>3.240134</td>\n",
       "      <td>149</td>\n",
       "      <td>0.095523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>2.030469</td>\n",
       "      <td>0.285972</td>\n",
       "      <td>1.278678</td>\n",
       "      <td>2.311704</td>\n",
       "      <td>149</td>\n",
       "      <td>0.140367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>3.076576</td>\n",
       "      <td>0.373991</td>\n",
       "      <td>2.244720</td>\n",
       "      <td>3.608909</td>\n",
       "      <td>149</td>\n",
       "      <td>0.121152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>-0.739751</td>\n",
       "      <td>0.349003</td>\n",
       "      <td>-1.506936</td>\n",
       "      <td>-0.263312</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.470199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>2.319608</td>\n",
       "      <td>0.326949</td>\n",
       "      <td>1.516098</td>\n",
       "      <td>2.661901</td>\n",
       "      <td>149</td>\n",
       "      <td>0.140476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>-0.885066</td>\n",
       "      <td>0.161061</td>\n",
       "      <td>-1.302365</td>\n",
       "      <td>-0.573860</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.181365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>2.078987</td>\n",
       "      <td>0.288501</td>\n",
       "      <td>1.327180</td>\n",
       "      <td>2.362700</td>\n",
       "      <td>149</td>\n",
       "      <td>0.138304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>-1.455591</td>\n",
       "      <td>0.498654</td>\n",
       "      <td>-2.409633</td>\n",
       "      <td>-0.761618</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.341427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean       std       min       max  \\\n",
       "benchmark_name                                                            \n",
       "ANLI                             0.576904  0.171304  0.148446  0.853594   \n",
       "ARC AI2                         -0.031989  0.221886 -0.572622  0.263367   \n",
       "ARC-AGI                          1.948494  0.273432  1.213769  2.212920   \n",
       "Aider polyglot                   1.614525  0.237116  0.937043  1.854031   \n",
       "BBH                              0.324886  0.180106 -0.148678  0.584454   \n",
       "Balrog                           2.368297  0.332024  1.558319  2.714604   \n",
       "BoolQ                           -1.218257  0.447152 -2.080091 -0.602495   \n",
       "CSQA2                           -0.329824  0.161517 -0.760793 -0.125501   \n",
       "CadEval                          1.653583  0.240238  0.970420  1.892235   \n",
       "Cybench                          2.624834  0.342001  1.813172  3.004368   \n",
       "DeepResearch Bench               2.026143  0.281046  1.281005  2.298657   \n",
       "Factorio learning environment    3.089380  0.374788  2.255571  3.638008   \n",
       "FrontierMath-2025-02-28-Private  2.717558  0.358346  1.879115  3.108806   \n",
       "GPQA diamond                     1.187227  0.200232  0.596881  1.460580   \n",
       "GSO-Bench                        3.344705  0.279304  2.650416  3.626853   \n",
       "GeoBench                         0.200472  0.237256 -0.518416  0.582646   \n",
       "HellaSwag                       -0.822732  0.365867 -1.566462 -0.321051   \n",
       "MATH level 5                     1.148314  0.199474  0.564125  1.427669   \n",
       "MMLU                             0.133153  0.199575 -0.377287  0.385396   \n",
       "OSUniverse                       3.954557  0.356858  3.197051  4.504084   \n",
       "OSWorld                          2.169621  0.263194  1.457812  2.463596   \n",
       "OTIS Mock AIME 2024-2025         1.628528  0.239105  0.947641  1.867289   \n",
       "OpenBookQA                       0.013585  0.215308 -0.518672  0.298280   \n",
       "SWE-Bench verified               2.858395  0.273963  2.190634  3.240134   \n",
       "SimpleBench                      2.030469  0.285972  1.278678  2.311704   \n",
       "Terminal Bench                   3.076576  0.373991  2.244720  3.608909   \n",
       "TriviaQA                        -0.739751  0.349003 -1.506936 -0.263312   \n",
       "VPCT                             2.319608  0.326949  1.516098  2.661901   \n",
       "VideoMME                        -0.885066  0.161061 -1.302365 -0.573860   \n",
       "WeirdML                          2.078987  0.288501  1.327180  2.362700   \n",
       "Winogrande                      -1.455591  0.498654 -2.409633 -0.761618   \n",
       "\n",
       "                                 count         cv  \n",
       "benchmark_name                                     \n",
       "ANLI                               149   0.295938  \n",
       "ARC AI2                            149  -6.913003  \n",
       "ARC-AGI                            149   0.139858  \n",
       "Aider polyglot                     149   0.146371  \n",
       "BBH                                149   0.552502  \n",
       "Balrog                             149   0.139724  \n",
       "BoolQ                              149  -0.365809  \n",
       "CSQA2                              149  -0.488062  \n",
       "CadEval                            149   0.144795  \n",
       "Cybench                            149   0.129856  \n",
       "DeepResearch Bench                 149   0.138244  \n",
       "Factorio learning environment      149   0.120907  \n",
       "FrontierMath-2025-02-28-Private    149   0.131420  \n",
       "GPQA diamond                       149   0.168088  \n",
       "GSO-Bench                          149   0.083226  \n",
       "GeoBench                           149   1.179508  \n",
       "HellaSwag                          149  -0.443203  \n",
       "MATH level 5                       149   0.173126  \n",
       "MMLU                               149   1.493795  \n",
       "OSUniverse                         149   0.089936  \n",
       "OSWorld                            149   0.120901  \n",
       "OTIS Mock AIME 2024-2025           149   0.146329  \n",
       "OpenBookQA                         149  15.795612  \n",
       "SWE-Bench verified                 149   0.095523  \n",
       "SimpleBench                        149   0.140367  \n",
       "Terminal Bench                     149   0.121152  \n",
       "TriviaQA                           149  -0.470199  \n",
       "VPCT                               149   0.140476  \n",
       "VideoMME                           149  -0.181365  \n",
       "WeirdML                            149   0.138304  \n",
       "Winogrande                         149  -0.341427  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in benchmark slopes across model anchor pairs ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.949958</td>\n",
       "      <td>0.247404</td>\n",
       "      <td>0.676248</td>\n",
       "      <td>1.395438</td>\n",
       "      <td>149</td>\n",
       "      <td>0.259561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>1.511995</td>\n",
       "      <td>0.411552</td>\n",
       "      <td>1.070354</td>\n",
       "      <td>2.288111</td>\n",
       "      <td>149</td>\n",
       "      <td>0.271277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>4.478621</td>\n",
       "      <td>0.708559</td>\n",
       "      <td>2.984404</td>\n",
       "      <td>5.299933</td>\n",
       "      <td>149</td>\n",
       "      <td>0.157677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>3.244570</td>\n",
       "      <td>0.554589</td>\n",
       "      <td>2.250287</td>\n",
       "      <td>3.901585</td>\n",
       "      <td>149</td>\n",
       "      <td>0.170354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>1.433160</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>0.993533</td>\n",
       "      <td>2.153350</td>\n",
       "      <td>149</td>\n",
       "      <td>0.268945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>1.090131</td>\n",
       "      <td>0.187621</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>1.317417</td>\n",
       "      <td>149</td>\n",
       "      <td>0.171531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>1.008272</td>\n",
       "      <td>0.274833</td>\n",
       "      <td>0.720922</td>\n",
       "      <td>1.546536</td>\n",
       "      <td>149</td>\n",
       "      <td>0.271662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA2</th>\n",
       "      <td>0.326550</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>0.255513</td>\n",
       "      <td>0.427432</td>\n",
       "      <td>149</td>\n",
       "      <td>0.148275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>2.272964</td>\n",
       "      <td>0.388145</td>\n",
       "      <td>1.568320</td>\n",
       "      <td>2.734986</td>\n",
       "      <td>149</td>\n",
       "      <td>0.170192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>1.514883</td>\n",
       "      <td>0.220294</td>\n",
       "      <td>1.136790</td>\n",
       "      <td>1.768655</td>\n",
       "      <td>149</td>\n",
       "      <td>0.144931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>1.786276</td>\n",
       "      <td>0.208198</td>\n",
       "      <td>1.077785</td>\n",
       "      <td>2.014284</td>\n",
       "      <td>149</td>\n",
       "      <td>0.116163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.983832</td>\n",
       "      <td>0.129129</td>\n",
       "      <td>0.692443</td>\n",
       "      <td>1.126748</td>\n",
       "      <td>149</td>\n",
       "      <td>0.130809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>2.846115</td>\n",
       "      <td>0.392604</td>\n",
       "      <td>1.921386</td>\n",
       "      <td>3.292237</td>\n",
       "      <td>149</td>\n",
       "      <td>0.137480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.976358</td>\n",
       "      <td>0.369805</td>\n",
       "      <td>1.391562</td>\n",
       "      <td>2.448865</td>\n",
       "      <td>149</td>\n",
       "      <td>0.186486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>1.966086</td>\n",
       "      <td>0.058438</td>\n",
       "      <td>1.798012</td>\n",
       "      <td>2.044672</td>\n",
       "      <td>149</td>\n",
       "      <td>0.029623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.421385</td>\n",
       "      <td>0.073349</td>\n",
       "      <td>0.284468</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>149</td>\n",
       "      <td>0.173480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>1.142522</td>\n",
       "      <td>0.310237</td>\n",
       "      <td>0.811887</td>\n",
       "      <td>1.730546</td>\n",
       "      <td>149</td>\n",
       "      <td>0.270624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>4.054979</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>2.865316</td>\n",
       "      <td>5.034238</td>\n",
       "      <td>149</td>\n",
       "      <td>0.187971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>1.287200</td>\n",
       "      <td>0.349209</td>\n",
       "      <td>0.933610</td>\n",
       "      <td>1.922992</td>\n",
       "      <td>149</td>\n",
       "      <td>0.270381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.804524</td>\n",
       "      <td>0.065488</td>\n",
       "      <td>0.636564</td>\n",
       "      <td>0.874449</td>\n",
       "      <td>149</td>\n",
       "      <td>0.081126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>2.489533</td>\n",
       "      <td>0.291283</td>\n",
       "      <td>1.967193</td>\n",
       "      <td>2.802127</td>\n",
       "      <td>149</td>\n",
       "      <td>0.116610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>5.269133</td>\n",
       "      <td>0.929806</td>\n",
       "      <td>3.686315</td>\n",
       "      <td>6.392673</td>\n",
       "      <td>149</td>\n",
       "      <td>0.175870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>1.308167</td>\n",
       "      <td>0.366135</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>2.002583</td>\n",
       "      <td>149</td>\n",
       "      <td>0.278943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.300955</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.327093</td>\n",
       "      <td>149</td>\n",
       "      <td>0.077658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>1.520359</td>\n",
       "      <td>0.263484</td>\n",
       "      <td>1.054793</td>\n",
       "      <td>1.835006</td>\n",
       "      <td>149</td>\n",
       "      <td>0.172721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.955044</td>\n",
       "      <td>0.116421</td>\n",
       "      <td>0.691470</td>\n",
       "      <td>1.078302</td>\n",
       "      <td>149</td>\n",
       "      <td>0.121491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.753252</td>\n",
       "      <td>0.200825</td>\n",
       "      <td>0.516775</td>\n",
       "      <td>1.131481</td>\n",
       "      <td>149</td>\n",
       "      <td>0.265715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.645896</td>\n",
       "      <td>0.110994</td>\n",
       "      <td>0.449487</td>\n",
       "      <td>0.780313</td>\n",
       "      <td>149</td>\n",
       "      <td>0.171268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.406961</td>\n",
       "      <td>0.040932</td>\n",
       "      <td>0.354980</td>\n",
       "      <td>0.501210</td>\n",
       "      <td>149</td>\n",
       "      <td>0.100241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>1.056381</td>\n",
       "      <td>0.173236</td>\n",
       "      <td>0.703163</td>\n",
       "      <td>1.237619</td>\n",
       "      <td>149</td>\n",
       "      <td>0.163439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.600502</td>\n",
       "      <td>0.163828</td>\n",
       "      <td>0.424570</td>\n",
       "      <td>0.909301</td>\n",
       "      <td>149</td>\n",
       "      <td>0.271901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean       std       min       max  \\\n",
       "benchmark_name                                                            \n",
       "ANLI                             0.949958  0.247404  0.676248  1.395438   \n",
       "ARC AI2                          1.511995  0.411552  1.070354  2.288111   \n",
       "ARC-AGI                          4.478621  0.708559  2.984404  5.299933   \n",
       "Aider polyglot                   3.244570  0.554589  2.250287  3.901585   \n",
       "BBH                              1.433160  0.386742  0.993533  2.153350   \n",
       "Balrog                           1.090131  0.187621  0.755459  1.317417   \n",
       "BoolQ                            1.008272  0.274833  0.720922  1.546536   \n",
       "CSQA2                            0.326550  0.048583  0.255513  0.427432   \n",
       "CadEval                          2.272964  0.388145  1.568320  2.734986   \n",
       "Cybench                          1.514883  0.220294  1.136790  1.768655   \n",
       "DeepResearch Bench               1.786276  0.208198  1.077785  2.014284   \n",
       "Factorio learning environment    0.983832  0.129129  0.692443  1.126748   \n",
       "FrontierMath-2025-02-28-Private  2.846115  0.392604  1.921386  3.292237   \n",
       "GPQA diamond                     1.976358  0.369805  1.391562  2.448865   \n",
       "GSO-Bench                        1.966086  0.058438  1.798012  2.044672   \n",
       "GeoBench                         0.421385  0.073349  0.284468  0.512605   \n",
       "HellaSwag                        1.142522  0.310237  0.811887  1.730546   \n",
       "MATH level 5                     4.054979  0.764789  2.865316  5.034238   \n",
       "MMLU                             1.287200  0.349209  0.933610  1.922992   \n",
       "OSUniverse                       0.804524  0.065488  0.636564  0.874449   \n",
       "OSWorld                          2.489533  0.291283  1.967193  2.802127   \n",
       "OTIS Mock AIME 2024-2025         5.269133  0.929806  3.686315  6.392673   \n",
       "OpenBookQA                       1.308167  0.366135  0.931499  2.002583   \n",
       "SWE-Bench verified               0.300955  0.023450  0.233501  0.327093   \n",
       "SimpleBench                      1.520359  0.263484  1.054793  1.835006   \n",
       "Terminal Bench                   0.955044  0.116421  0.691470  1.078302   \n",
       "TriviaQA                         0.753252  0.200825  0.516775  1.131481   \n",
       "VPCT                             0.645896  0.110994  0.449487  0.780313   \n",
       "VideoMME                         0.406961  0.040932  0.354980  0.501210   \n",
       "WeirdML                          1.056381  0.173236  0.703163  1.237619   \n",
       "Winogrande                       0.600502  0.163828  0.424570  0.909301   \n",
       "\n",
       "                                 count        cv  \n",
       "benchmark_name                                    \n",
       "ANLI                               149  0.259561  \n",
       "ARC AI2                            149  0.271277  \n",
       "ARC-AGI                            149  0.157677  \n",
       "Aider polyglot                     149  0.170354  \n",
       "BBH                                149  0.268945  \n",
       "Balrog                             149  0.171531  \n",
       "BoolQ                              149  0.271662  \n",
       "CSQA2                              149  0.148275  \n",
       "CadEval                            149  0.170192  \n",
       "Cybench                            149  0.144931  \n",
       "DeepResearch Bench                 149  0.116163  \n",
       "Factorio learning environment      149  0.130809  \n",
       "FrontierMath-2025-02-28-Private    149  0.137480  \n",
       "GPQA diamond                       149  0.186486  \n",
       "GSO-Bench                          149  0.029623  \n",
       "GeoBench                           149  0.173480  \n",
       "HellaSwag                          149  0.270624  \n",
       "MATH level 5                       149  0.187971  \n",
       "MMLU                               149  0.270381  \n",
       "OSUniverse                         149  0.081126  \n",
       "OSWorld                            149  0.116610  \n",
       "OTIS Mock AIME 2024-2025           149  0.175870  \n",
       "OpenBookQA                         149  0.278943  \n",
       "SWE-Bench verified                 149  0.077658  \n",
       "SimpleBench                        149  0.172721  \n",
       "Terminal Bench                     149  0.121491  \n",
       "TriviaQA                           149  0.265715  \n",
       "VPCT                               149  0.171268  \n",
       "VideoMME                           149  0.100241  \n",
       "WeirdML                            149  0.163439  \n",
       "Winogrande                         149  0.271901  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in model capabilities (all models) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.022723</td>\n",
       "      <td>0.215473</td>\n",
       "      <td>-0.510097</td>\n",
       "      <td>0.304139</td>\n",
       "      <td>149</td>\n",
       "      <td>9.450721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>-0.163597</td>\n",
       "      <td>0.243944</td>\n",
       "      <td>-0.731591</td>\n",
       "      <td>0.166295</td>\n",
       "      <td>149</td>\n",
       "      <td>-1.486114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.587071</td>\n",
       "      <td>0.319552</td>\n",
       "      <td>-1.252025</td>\n",
       "      <td>-0.146496</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.542487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)</th>\n",
       "      <td>0.474530</td>\n",
       "      <td>0.172668</td>\n",
       "      <td>0.028658</td>\n",
       "      <td>0.738817</td>\n",
       "      <td>149</td>\n",
       "      <td>0.362649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1</th>\n",
       "      <td>1.647710</td>\n",
       "      <td>0.240956</td>\n",
       "      <td>0.963706</td>\n",
       "      <td>1.887455</td>\n",
       "      <td>149</td>\n",
       "      <td>0.145745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablelm-tuned-alpha-7b</th>\n",
       "      <td>-0.880515</td>\n",
       "      <td>0.377027</td>\n",
       "      <td>-1.638438</td>\n",
       "      <td>-0.363670</td>\n",
       "      <td>149</td>\n",
       "      <td>-0.426750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-001</th>\n",
       "      <td>0.011444</td>\n",
       "      <td>0.215855</td>\n",
       "      <td>-0.521015</td>\n",
       "      <td>0.295527</td>\n",
       "      <td>149</td>\n",
       "      <td>18.798225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.743699</td>\n",
       "      <td>0.174332</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.019313</td>\n",
       "      <td>149</td>\n",
       "      <td>0.233624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.197130</td>\n",
       "      <td>0.248311</td>\n",
       "      <td>-0.768657</td>\n",
       "      <td>0.140212</td>\n",
       "      <td>149</td>\n",
       "      <td>-1.255393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.252937</td>\n",
       "      <td>0.257418</td>\n",
       "      <td>-0.833983</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>149</td>\n",
       "      <td>-1.014296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean       std       min       max  count  \\\n",
       "model                                                                    \n",
       "Baichuan-2-13B-Base      0.022723  0.215473 -0.510097  0.304139    149   \n",
       "Baichuan-2-7B-Base      -0.163597  0.243944 -0.731591  0.166295    149   \n",
       "Cerebras-GPT-13B        -0.587071  0.319552 -1.252025 -0.146496    149   \n",
       "Chinchilla (70B)         0.474530  0.172668  0.028658  0.738817    149   \n",
       "DeepSeek-R1              1.647710  0.240956  0.963706  1.887455    149   \n",
       "...                           ...       ...       ...       ...    ...   \n",
       "stablelm-tuned-alpha-7b -0.880515  0.377027 -1.638438 -0.363670    149   \n",
       "text-davinci-001         0.011444  0.215855 -0.521015  0.295527    149   \n",
       "text-davinci-002         0.743699  0.174332  0.279800  1.019313    149   \n",
       "vicuna-13b-v1.1         -0.197130  0.248311 -0.768657  0.140212    149   \n",
       "xgen-7b-8k-base         -0.252937  0.257418 -0.833983  0.099999    149   \n",
       "\n",
       "                                cv  \n",
       "model                               \n",
       "Baichuan-2-13B-Base       9.450721  \n",
       "Baichuan-2-7B-Base       -1.486114  \n",
       "Cerebras-GPT-13B         -0.542487  \n",
       "Chinchilla (70B)          0.362649  \n",
       "DeepSeek-R1               0.145745  \n",
       "...                            ...  \n",
       "stablelm-tuned-alpha-7b  -0.426750  \n",
       "text-davinci-001         18.798225  \n",
       "text-davinci-002          0.233624  \n",
       "vicuna-13b-v1.1          -1.255393  \n",
       "xgen-7b-8k-base          -1.014296  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in model capabilities (excluding anchored models) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.019426</td>\n",
       "      <td>0.215056</td>\n",
       "      <td>-0.510097</td>\n",
       "      <td>0.304139</td>\n",
       "      <td>147</td>\n",
       "      <td>11.033022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>-0.166798</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>-0.731591</td>\n",
       "      <td>0.166295</td>\n",
       "      <td>147</td>\n",
       "      <td>-1.458106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.590008</td>\n",
       "      <td>0.320727</td>\n",
       "      <td>-1.252025</td>\n",
       "      <td>-0.146496</td>\n",
       "      <td>147</td>\n",
       "      <td>-0.541745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)</th>\n",
       "      <td>0.471035</td>\n",
       "      <td>0.171192</td>\n",
       "      <td>0.028658</td>\n",
       "      <td>0.738817</td>\n",
       "      <td>147</td>\n",
       "      <td>0.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1</th>\n",
       "      <td>1.645051</td>\n",
       "      <td>0.241504</td>\n",
       "      <td>0.963706</td>\n",
       "      <td>1.887455</td>\n",
       "      <td>147</td>\n",
       "      <td>0.146307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablelm-tuned-alpha-7b</th>\n",
       "      <td>-0.883271</td>\n",
       "      <td>0.378849</td>\n",
       "      <td>-1.638438</td>\n",
       "      <td>-0.363670</td>\n",
       "      <td>147</td>\n",
       "      <td>-0.427455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-001</th>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.215451</td>\n",
       "      <td>-0.521015</td>\n",
       "      <td>0.295527</td>\n",
       "      <td>147</td>\n",
       "      <td>26.337233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002</th>\n",
       "      <td>0.740088</td>\n",
       "      <td>0.172714</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.019313</td>\n",
       "      <td>147</td>\n",
       "      <td>0.232574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.200307</td>\n",
       "      <td>0.248487</td>\n",
       "      <td>-0.768657</td>\n",
       "      <td>0.140212</td>\n",
       "      <td>147</td>\n",
       "      <td>-1.236304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.256070</td>\n",
       "      <td>0.257751</td>\n",
       "      <td>-0.833983</td>\n",
       "      <td>0.099999</td>\n",
       "      <td>147</td>\n",
       "      <td>-1.003134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean       std       min       max  count  \\\n",
       "model                                                                    \n",
       "Baichuan-2-13B-Base      0.019426  0.215056 -0.510097  0.304139    147   \n",
       "Baichuan-2-7B-Base      -0.166798  0.244040 -0.731591  0.166295    147   \n",
       "Cerebras-GPT-13B        -0.590008  0.320727 -1.252025 -0.146496    147   \n",
       "Chinchilla (70B)         0.471035  0.171192  0.028658  0.738817    147   \n",
       "DeepSeek-R1              1.645051  0.241504  0.963706  1.887455    147   \n",
       "...                           ...       ...       ...       ...    ...   \n",
       "stablelm-tuned-alpha-7b -0.883271  0.378849 -1.638438 -0.363670    147   \n",
       "text-davinci-001         0.008153  0.215451 -0.521015  0.295527    147   \n",
       "text-davinci-002         0.740088  0.172714  0.279800  1.019313    147   \n",
       "vicuna-13b-v1.1         -0.200307  0.248487 -0.768657  0.140212    147   \n",
       "xgen-7b-8k-base         -0.256070  0.257751 -0.833983  0.099999    147   \n",
       "\n",
       "                                cv  \n",
       "model                               \n",
       "Baichuan-2-13B-Base      11.033022  \n",
       "Baichuan-2-7B-Base       -1.458106  \n",
       "Cerebras-GPT-13B         -0.541745  \n",
       "Chinchilla (70B)          0.362200  \n",
       "DeepSeek-R1               0.146307  \n",
       "...                            ...  \n",
       "stablelm-tuned-alpha-7b  -0.427455  \n",
       "text-davinci-001         26.337233  \n",
       "text-davinci-002          0.232574  \n",
       "vicuna-13b-v1.1          -1.236304  \n",
       "xgen-7b-8k-base          -1.003134  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model pair stability (lower deviation = more stable) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_difficulty_deviation</th>\n",
       "      <th>mean_capability_deviation</th>\n",
       "      <th>combined_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1_text-davinci-002</th>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.033914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-14B_falcon-180B</th>\n",
       "      <td>0.070134</td>\n",
       "      <td>0.035910</td>\n",
       "      <td>0.041837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0613_internlm-20b</th>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>0.054030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>falcon-180B_gpt-3.5-turbo-0613</th>\n",
       "      <td>0.082704</td>\n",
       "      <td>0.053932</td>\n",
       "      <td>0.058914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internlm-20b_Qwen2.5-Coder-32B</th>\n",
       "      <td>0.097957</td>\n",
       "      <td>0.056632</td>\n",
       "      <td>0.063789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <td>0.109445</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.078703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-32B_Qwen-14B</th>\n",
       "      <td>0.119925</td>\n",
       "      <td>0.083617</td>\n",
       "      <td>0.089905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct_PaLM 2-L</th>\n",
       "      <td>0.125860</td>\n",
       "      <td>0.094214</td>\n",
       "      <td>0.099695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)_Qwen2.5-Coder-7B</th>\n",
       "      <td>0.151842</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.100849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-7B_PaLM 540B</th>\n",
       "      <td>0.180110</td>\n",
       "      <td>0.117983</td>\n",
       "      <td>0.128742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mean_difficulty_deviation  \\\n",
       "Mixtral-8x7B-v0.1_text-davinci-002                   0.060466   \n",
       "Qwen2.5-Coder-14B_falcon-180B                        0.070134   \n",
       "gpt-3.5-turbo-0613_internlm-20b                      0.085505   \n",
       "falcon-180B_gpt-3.5-turbo-0613                       0.082704   \n",
       "internlm-20b_Qwen2.5-Coder-32B                       0.097957   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                   0.109445   \n",
       "Qwen2.5-Coder-32B_Qwen-14B                           0.119925   \n",
       "Phi-3-mini-4k-instruct_PaLM 2-L                      0.125860   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                    0.151842   \n",
       "Qwen2.5-Coder-7B_PaLM 540B                           0.180110   \n",
       "\n",
       "                                    mean_capability_deviation  \\\n",
       "Mixtral-8x7B-v0.1_text-davinci-002                   0.028353   \n",
       "Qwen2.5-Coder-14B_falcon-180B                        0.035910   \n",
       "gpt-3.5-turbo-0613_internlm-20b                      0.047437   \n",
       "falcon-180B_gpt-3.5-turbo-0613                       0.053932   \n",
       "internlm-20b_Qwen2.5-Coder-32B                       0.056632   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                   0.072264   \n",
       "Qwen2.5-Coder-32B_Qwen-14B                           0.083617   \n",
       "Phi-3-mini-4k-instruct_PaLM 2-L                      0.094214   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                    0.090167   \n",
       "Qwen2.5-Coder-7B_PaLM 540B                           0.117983   \n",
       "\n",
       "                                    combined_deviation  \n",
       "Mixtral-8x7B-v0.1_text-davinci-002            0.033914  \n",
       "Qwen2.5-Coder-14B_falcon-180B                 0.041837  \n",
       "gpt-3.5-turbo-0613_internlm-20b               0.054030  \n",
       "falcon-180B_gpt-3.5-turbo-0613                0.058914  \n",
       "internlm-20b_Qwen2.5-Coder-32B                0.063789  \n",
       "text-davinci-002_Qwen2.5-Coder-14B            0.078703  \n",
       "Qwen2.5-Coder-32B_Qwen-14B                    0.089905  \n",
       "Phi-3-mini-4k-instruct_PaLM 2-L               0.099695  \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B             0.100849  \n",
       "Qwen2.5-Coder-7B_PaLM 540B                    0.128742  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1)  DIFFICULTY  ––  variation of each benchmark's difficulty estimate\n",
    "#     across different model anchor pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "difficulty_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]                                  # difficulty table from that fit\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_difficulty\"]].copy()\n",
    "    out[\"anchor_model_pair\"] = anchor_pair                # remember which model pair this came from\n",
    "    # Also store the individual models for more detailed analysis if needed\n",
    "    out[\"anchor_model1\"] = run[\"anchor_model1\"]\n",
    "    out[\"anchor_model2\"] = run[\"anchor_model2\"]\n",
    "    difficulty_rows.append(out)\n",
    "\n",
    "difficulty_long = pd.concat(difficulty_rows, ignore_index=True)\n",
    "\n",
    "# No need to drop trivial rows since we're not anchoring on benchmarks\n",
    "# All benchmark estimates are free to vary\n",
    "\n",
    "difficulty_stats = (\n",
    "    difficulty_long\n",
    "      .groupby(\"benchmark_name\")[\"estimated_difficulty\"]\n",
    "      .agg(mean   = \"mean\",\n",
    "           std    = \"std\",\n",
    "           min    = \"min\",\n",
    "           max    = \"max\",\n",
    "           count  = \"count\",                              # how many model pairs estimated this\n",
    "           cv     = lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2)  CAPABILITY  ––  variation of each model's capability estimate\n",
    "#     across different model anchor pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "capability_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_cm = run[\"df_cm1\"]                                 # capability table from that fit\n",
    "    # Check the actual column name - might be 'model' or 'model_name'\n",
    "    model_col = \"model_name\" if \"model_name\" in df_cm.columns else \"model\"\n",
    "    out = df_cm[[model_col, \"estimated_capability\"]].copy()\n",
    "    out.rename(columns={model_col: \"model\"}, inplace=True)  # standardize column name\n",
    "    out[\"anchor_model_pair\"] = anchor_pair\n",
    "    # Also store the individual anchor models\n",
    "    out[\"anchor_model1\"] = run[\"anchor_model1\"]\n",
    "    out[\"anchor_model2\"] = run[\"anchor_model2\"]\n",
    "    capability_rows.append(out)\n",
    "\n",
    "capability_long = pd.concat(capability_rows, ignore_index=True)\n",
    "\n",
    "# For model capabilities, we might want to exclude rows where the model \n",
    "# was one of the anchors (since those were fixed)\n",
    "capability_long_free = capability_long[\n",
    "    (capability_long[\"model\"] != capability_long[\"anchor_model1\"]) &\n",
    "    (capability_long[\"model\"] != capability_long[\"anchor_model2\"])\n",
    "]\n",
    "\n",
    "# Stats for all models (including anchored ones)\n",
    "capability_stats_all = (\n",
    "    capability_long\n",
    "      .groupby(\"model\")[\"estimated_capability\"]\n",
    "      .agg(mean  = \"mean\",\n",
    "           std   = \"std\",\n",
    "           min   = \"min\",\n",
    "           max   = \"max\",\n",
    "           count = \"count\",\n",
    "           cv    = lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# Stats for non-anchored models only (more meaningful variation)\n",
    "capability_stats_free = (\n",
    "    capability_long_free\n",
    "      .groupby(\"model\")[\"estimated_capability\"]\n",
    "      .agg(mean  = \"mean\",\n",
    "           std   = \"std\",\n",
    "           min   = \"min\",\n",
    "           max   = \"max\",\n",
    "           count = \"count\",\n",
    "           cv    = lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3)  SLOPE  ––  variation of each benchmark's slope estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "slope_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_slope\"]].copy()\n",
    "    out[\"anchor_model_pair\"] = anchor_pair\n",
    "    slope_rows.append(out)\n",
    "\n",
    "slope_long = pd.concat(slope_rows, ignore_index=True)\n",
    "\n",
    "slope_stats = (\n",
    "    slope_long\n",
    "      .groupby(\"benchmark_name\")[\"estimated_slope\"]\n",
    "      .agg(mean  = \"mean\",\n",
    "           std   = \"std\",\n",
    "           min   = \"min\",\n",
    "           max   = \"max\",\n",
    "           count = \"count\",\n",
    "           cv    = lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan\n",
    "      )\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4)  Quick look at results\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"=== Variation in benchmark difficulties across model anchor pairs ===\")\n",
    "display(difficulty_stats)\n",
    "\n",
    "print(\"\\n=== Variation in benchmark slopes across model anchor pairs ===\")\n",
    "display(slope_stats)\n",
    "\n",
    "print(\"\\n=== Variation in model capabilities (all models) ===\")\n",
    "display(capability_stats_all)\n",
    "\n",
    "print(\"\\n=== Variation in model capabilities (excluding anchored models) ===\")\n",
    "display(capability_stats_free)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5)  Additional analysis: which model pairs give most stable estimates?\n",
    "# ---------------------------------------------------------------------------\n",
    "# Calculate overall stability metric for each model pair\n",
    "stability_by_pair = {}\n",
    "\n",
    "for anchor_pair in all_runs.keys():\n",
    "    # Get difficulty variations for this pair\n",
    "    diff_subset = difficulty_long[difficulty_long[\"anchor_model_pair\"] == anchor_pair]\n",
    "    cap_subset = capability_long_free[capability_long_free[\"anchor_model_pair\"] == anchor_pair]\n",
    "    \n",
    "    # Calculate average deviation from overall means\n",
    "    diff_devs = []\n",
    "    for bench in diff_subset[\"benchmark_name\"].unique():\n",
    "        estimate = diff_subset[diff_subset[\"benchmark_name\"] == bench][\"estimated_difficulty\"].iloc[0]\n",
    "        overall_mean = difficulty_stats.loc[bench, \"mean\"]\n",
    "        diff_devs.append(abs(estimate - overall_mean))\n",
    "    \n",
    "    cap_devs = []\n",
    "    for model in cap_subset[\"model\"].unique():\n",
    "        if model in capability_stats_free.index:\n",
    "            estimate = cap_subset[cap_subset[\"model\"] == model][\"estimated_capability\"].iloc[0]\n",
    "            overall_mean = capability_stats_free.loc[model, \"mean\"]\n",
    "            cap_devs.append(abs(estimate - overall_mean))\n",
    "    \n",
    "    stability_by_pair[anchor_pair] = {\n",
    "        \"mean_difficulty_deviation\": np.mean(diff_devs) if diff_devs else np.nan,\n",
    "        \"mean_capability_deviation\": np.mean(cap_devs) if cap_devs else np.nan,\n",
    "        \"combined_deviation\": np.mean(diff_devs + cap_devs) if (diff_devs or cap_devs) else np.nan\n",
    "    }\n",
    "\n",
    "stability_df = pd.DataFrame(stability_by_pair).T.sort_values(\"combined_deviation\")\n",
    "\n",
    "print(\"\\n=== Model pair stability (lower deviation = more stable) ===\")\n",
    "display(stability_df.head(10))  # Show top 10 most stable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f156dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spearman across anchor model pairs (benchmark difficulties) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor</th>\n",
       "      <th>Baichuan-2-13B-Base_text-davinci-001</th>\n",
       "      <th>Baichuan-2-7B-Base_vicuna-13b-v1.1</th>\n",
       "      <th>Cerebras-GPT-13B_stablelm-tuned-alpha-7b</th>\n",
       "      <th>Chinchilla (70B)_Qwen2.5-Coder-7B</th>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-20250514_16K</th>\n",
       "      <th>DeepSeek-R1_claude-3-7-sonnet-20250219_16K</th>\n",
       "      <th>DeepSeek-V2_Qwen2.5-72B</th>\n",
       "      <th>DeepSeek-V3-0324_gpt-4.1-2025-04-14</th>\n",
       "      <th>DeepSeek-V3_gemini-1.5-pro-002</th>\n",
       "      <th>GLaM (MoE)_LLaMA-33B</th>\n",
       "      <th>...</th>\n",
       "      <th>phi-2_Llama-2-34b</th>\n",
       "      <th>phi-4_gpt-4.1-nano-2025-04-14</th>\n",
       "      <th>qwen-max-2025-01-25_phi-4</th>\n",
       "      <th>qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Instruct</th>\n",
       "      <th>qwen3-235b-a22b_gemini-2.0-pro-exp-02-05</th>\n",
       "      <th>stablelm-tuned-alpha-7b_opt-1.3b</th>\n",
       "      <th>text-davinci-001_mpt-30b</th>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <th>vicuna-13b-v1.1_gemma-2b</th>\n",
       "      <th>xgen-7b-8k-base_Llama-2-7b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base_text-davinci-001</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.994758</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.994758</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base_vicuna-13b-v1.1</th>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B_stablelm-tuned-alpha-7b</th>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)_Qwen2.5-Coder-7B</th>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.997177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-20250514_16K</th>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablelm-tuned-alpha-7b_opt-1.3b</th>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-001_mpt-30b</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.994758</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.995161</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.994758</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <td>0.996774</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.995968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1_gemma-2b</th>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base_Llama-2-7b</th>\n",
       "      <td>0.999597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.997177</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor                                       Baichuan-2-13B-Base_text-davinci-001  \\\n",
       "anchor                                                                              \n",
       "Baichuan-2-13B-Base_text-davinci-001                                     1.000000   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                       0.999597   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                 0.999194   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                        0.997984   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                              0.995161   \n",
       "...                                                                           ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                         0.999194   \n",
       "text-davinci-001_mpt-30b                                                 1.000000   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                       0.996774   \n",
       "vicuna-13b-v1.1_gemma-2b                                                 0.999597   \n",
       "xgen-7b-8k-base_Llama-2-7b                                               0.999597   \n",
       "\n",
       "anchor                                       Baichuan-2-7B-Base_vicuna-13b-v1.1  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_text-davinci-001                                   0.999597   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                     1.000000   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                               0.999597   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                      0.997177   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                            0.994355   \n",
       "...                                                                         ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                       0.999597   \n",
       "text-davinci-001_mpt-30b                                               0.999597   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                     0.995968   \n",
       "vicuna-13b-v1.1_gemma-2b                                               1.000000   \n",
       "xgen-7b-8k-base_Llama-2-7b                                             1.000000   \n",
       "\n",
       "anchor                                       Cerebras-GPT-13B_stablelm-tuned-alpha-7b  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                                         0.999194   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                           0.999597   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                     1.000000   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                            0.997984   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                  0.995968   \n",
       "...                                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                             1.000000   \n",
       "text-davinci-001_mpt-30b                                                     0.999194   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                           0.997177   \n",
       "vicuna-13b-v1.1_gemma-2b                                                     0.999597   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                   0.999597   \n",
       "\n",
       "anchor                                       Chinchilla (70B)_Qwen2.5-Coder-7B  \\\n",
       "anchor                                                                           \n",
       "Baichuan-2-13B-Base_text-davinci-001                                  0.997984   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                    0.997177   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                              0.997984   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                     1.000000   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                           0.998790   \n",
       "...                                                                        ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                      0.997984   \n",
       "text-davinci-001_mpt-30b                                              0.997984   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                    0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                              0.997177   \n",
       "xgen-7b-8k-base_Llama-2-7b                                            0.997177   \n",
       "\n",
       "anchor                                       DeepSeek-R1-0528_claude-opus-4-20250514_16K  \\\n",
       "anchor                                                                                     \n",
       "Baichuan-2-13B-Base_text-davinci-001                                            0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                              0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                        0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                               0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                     1.000000   \n",
       "...                                                                                  ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                                0.995968   \n",
       "text-davinci-001_mpt-30b                                                        0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                              0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                                        0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                      0.994355   \n",
       "\n",
       "anchor                                       DeepSeek-R1_claude-3-7-sonnet-20250219_16K  \\\n",
       "anchor                                                                                    \n",
       "Baichuan-2-13B-Base_text-davinci-001                                           0.994758   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                             0.993952   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                       0.995565   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                              0.998387   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                    0.999597   \n",
       "...                                                                                 ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                               0.995565   \n",
       "text-davinci-001_mpt-30b                                                       0.994758   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                             0.999194   \n",
       "vicuna-13b-v1.1_gemma-2b                                                       0.993952   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                     0.993952   \n",
       "\n",
       "anchor                                       DeepSeek-V2_Qwen2.5-72B  \\\n",
       "anchor                                                                 \n",
       "Baichuan-2-13B-Base_text-davinci-001                        0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                          0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                    0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                           0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                 1.000000   \n",
       "...                                                              ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                            0.995968   \n",
       "text-davinci-001_mpt-30b                                    0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                          0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                    0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                  0.994355   \n",
       "\n",
       "anchor                                       DeepSeek-V3-0324_gpt-4.1-2025-04-14  \\\n",
       "anchor                                                                             \n",
       "Baichuan-2-13B-Base_text-davinci-001                                    0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                      0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                       0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                             1.000000   \n",
       "...                                                                          ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                        0.995968   \n",
       "text-davinci-001_mpt-30b                                                0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                      0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                                0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                              0.994355   \n",
       "\n",
       "anchor                                       DeepSeek-V3_gemini-1.5-pro-002  \\\n",
       "anchor                                                                        \n",
       "Baichuan-2-13B-Base_text-davinci-001                               0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                 0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                           0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                  0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                        1.000000   \n",
       "...                                                                     ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                   0.995968   \n",
       "text-davinci-001_mpt-30b                                           0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                 0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                           0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                         0.994355   \n",
       "\n",
       "anchor                                       GLaM (MoE)_LLaMA-33B  ...  \\\n",
       "anchor                                                             ...   \n",
       "Baichuan-2-13B-Base_text-davinci-001                     0.999597  ...   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                       0.999194  ...   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                 0.999597  ...   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                        0.998790  ...   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K              0.996774  ...   \n",
       "...                                                           ...  ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                         0.999597  ...   \n",
       "text-davinci-001_mpt-30b                                 0.999597  ...   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                       0.997984  ...   \n",
       "vicuna-13b-v1.1_gemma-2b                                 0.999194  ...   \n",
       "xgen-7b-8k-base_Llama-2-7b                               0.999194  ...   \n",
       "\n",
       "anchor                                       phi-2_Llama-2-34b  \\\n",
       "anchor                                                           \n",
       "Baichuan-2-13B-Base_text-davinci-001                  0.999597   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                    0.999194   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b              0.999597   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                     0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K           0.996774   \n",
       "...                                                        ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                      0.999597   \n",
       "text-davinci-001_mpt-30b                              0.999597   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                    0.997984   \n",
       "vicuna-13b-v1.1_gemma-2b                              0.999194   \n",
       "xgen-7b-8k-base_Llama-2-7b                            0.999194   \n",
       "\n",
       "anchor                                       phi-4_gpt-4.1-nano-2025-04-14  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_text-davinci-001                              0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                          0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                 0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                       1.000000   \n",
       "...                                                                    ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                  0.995968   \n",
       "text-davinci-001_mpt-30b                                          0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                          0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                        0.994355   \n",
       "\n",
       "anchor                                       qwen-max-2025-01-25_phi-4  \\\n",
       "anchor                                                                   \n",
       "Baichuan-2-13B-Base_text-davinci-001                          0.995161   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                            0.994355   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                      0.995968   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                             0.998790   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                   1.000000   \n",
       "...                                                                ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                              0.995968   \n",
       "text-davinci-001_mpt-30b                                      0.995161   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                            0.999597   \n",
       "vicuna-13b-v1.1_gemma-2b                                      0.994355   \n",
       "xgen-7b-8k-base_Llama-2-7b                                    0.994355   \n",
       "\n",
       "anchor                                       qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Instruct  \\\n",
       "anchor                                                                                             \n",
       "Baichuan-2-13B-Base_text-davinci-001                                                  0.996774     \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                                    0.995968     \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                              0.997177     \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                                     0.999597     \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                           0.999597     \n",
       "...                                                                                        ...     \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                                      0.997177     \n",
       "text-davinci-001_mpt-30b                                                              0.996774     \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                                    1.000000     \n",
       "vicuna-13b-v1.1_gemma-2b                                                              0.995968     \n",
       "xgen-7b-8k-base_Llama-2-7b                                                            0.995968     \n",
       "\n",
       "anchor                                       qwen3-235b-a22b_gemini-2.0-pro-exp-02-05  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                                         0.994758   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                           0.993952   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                     0.995565   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                            0.998387   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                  0.999597   \n",
       "...                                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                             0.995565   \n",
       "text-davinci-001_mpt-30b                                                     0.994758   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                           0.999194   \n",
       "vicuna-13b-v1.1_gemma-2b                                                     0.993952   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                   0.993952   \n",
       "\n",
       "anchor                                       stablelm-tuned-alpha-7b_opt-1.3b  \\\n",
       "anchor                                                                          \n",
       "Baichuan-2-13B-Base_text-davinci-001                                 0.999194   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                   0.999597   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                             1.000000   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                    0.997984   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                          0.995968   \n",
       "...                                                                       ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                     1.000000   \n",
       "text-davinci-001_mpt-30b                                             0.999194   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                   0.997177   \n",
       "vicuna-13b-v1.1_gemma-2b                                             0.999597   \n",
       "xgen-7b-8k-base_Llama-2-7b                                           0.999597   \n",
       "\n",
       "anchor                                       text-davinci-001_mpt-30b  \\\n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                         1.000000   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                           0.999597   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                     0.999194   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                            0.997984   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                  0.995161   \n",
       "...                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                             0.999194   \n",
       "text-davinci-001_mpt-30b                                     1.000000   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                           0.996774   \n",
       "vicuna-13b-v1.1_gemma-2b                                     0.999597   \n",
       "xgen-7b-8k-base_Llama-2-7b                                   0.999597   \n",
       "\n",
       "anchor                                       text-davinci-002_Qwen2.5-Coder-14B  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_text-davinci-001                                   0.996774   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                     0.995968   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                               0.997177   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                      0.999597   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                            0.999597   \n",
       "...                                                                         ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                       0.997177   \n",
       "text-davinci-001_mpt-30b                                               0.996774   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                     1.000000   \n",
       "vicuna-13b-v1.1_gemma-2b                                               0.995968   \n",
       "xgen-7b-8k-base_Llama-2-7b                                             0.995968   \n",
       "\n",
       "anchor                                       vicuna-13b-v1.1_gemma-2b  \\\n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                         0.999597   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                           1.000000   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                     0.999597   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                            0.997177   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                  0.994355   \n",
       "...                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                             0.999597   \n",
       "text-davinci-001_mpt-30b                                     0.999597   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                           0.995968   \n",
       "vicuna-13b-v1.1_gemma-2b                                     1.000000   \n",
       "xgen-7b-8k-base_Llama-2-7b                                   1.000000   \n",
       "\n",
       "anchor                                       xgen-7b-8k-base_Llama-2-7b  \n",
       "anchor                                                                   \n",
       "Baichuan-2-13B-Base_text-davinci-001                           0.999597  \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                             1.000000  \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                       0.999597  \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                              0.997177  \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                    0.994355  \n",
       "...                                                                 ...  \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                               0.999597  \n",
       "text-davinci-001_mpt-30b                                       0.999597  \n",
       "text-davinci-002_Qwen2.5-Coder-14B                             0.995968  \n",
       "vicuna-13b-v1.1_gemma-2b                                       1.000000  \n",
       "xgen-7b-8k-base_Llama-2-7b                                     1.000000  \n",
       "\n",
       "[149 rows x 149 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per model-pair fit (difficulties):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229_Llama-3.2-90B-Vision-Instruct</th>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Instruct</th>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1_text-davinci-002</th>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-70B-Instruct_StableBeluga2</th>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.2-90B-Vision-Instruct_Llama-3.1-70B-Instruct</th>\n",
       "      <td>0.998660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-j-6b_LLaMA-7B</th>\n",
       "      <td>0.996464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-neox-20b_open_llama_7b</th>\n",
       "      <td>0.996464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-2b_xgen-7b-8k-base</th>\n",
       "      <td>0.996464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1_gemma-2b</th>\n",
       "      <td>0.996464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base_Llama-2-7b</th>\n",
       "      <td>0.996464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rho\n",
       "anchor                                                      \n",
       "claude-3-opus-20240229_Llama-3.2-90B-Vision-Ins...  0.998660\n",
       "qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Inst...  0.998660\n",
       "Mixtral-8x7B-v0.1_text-davinci-002                  0.998660\n",
       "Llama-3.1-70B-Instruct_StableBeluga2                0.998660\n",
       "Llama-3.2-90B-Vision-Instruct_Llama-3.1-70B-Ins...  0.998660\n",
       "...                                                      ...\n",
       "gpt-j-6b_LLaMA-7B                                   0.996464\n",
       "gpt-neox-20b_open_llama_7b                          0.996464\n",
       "gemma-2b_xgen-7b-8k-base                            0.996464\n",
       "vicuna-13b-v1.1_gemma-2b                            0.996464\n",
       "xgen-7b-8k-base_Llama-2-7b                          0.996464\n",
       "\n",
       "[149 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spearman across anchor model pairs (model capabilities) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor</th>\n",
       "      <th>Baichuan-2-13B-Base_text-davinci-001</th>\n",
       "      <th>Baichuan-2-7B-Base_vicuna-13b-v1.1</th>\n",
       "      <th>Cerebras-GPT-13B_stablelm-tuned-alpha-7b</th>\n",
       "      <th>Chinchilla (70B)_Qwen2.5-Coder-7B</th>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-20250514_16K</th>\n",
       "      <th>DeepSeek-R1_claude-3-7-sonnet-20250219_16K</th>\n",
       "      <th>DeepSeek-V2_Qwen2.5-72B</th>\n",
       "      <th>DeepSeek-V3-0324_gpt-4.1-2025-04-14</th>\n",
       "      <th>DeepSeek-V3_gemini-1.5-pro-002</th>\n",
       "      <th>GLaM (MoE)_LLaMA-33B</th>\n",
       "      <th>...</th>\n",
       "      <th>phi-2_Llama-2-34b</th>\n",
       "      <th>phi-4_gpt-4.1-nano-2025-04-14</th>\n",
       "      <th>qwen-max-2025-01-25_phi-4</th>\n",
       "      <th>qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Instruct</th>\n",
       "      <th>qwen3-235b-a22b_gemini-2.0-pro-exp-02-05</th>\n",
       "      <th>stablelm-tuned-alpha-7b_opt-1.3b</th>\n",
       "      <th>text-davinci-001_mpt-30b</th>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <th>vicuna-13b-v1.1_gemma-2b</th>\n",
       "      <th>xgen-7b-8k-base_Llama-2-7b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base_text-davinci-001</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>0.999605</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.999470</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999410</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.998254</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base_vicuna-13b-v1.1</th>\n",
       "      <td>0.999940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>0.992764</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.999314</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B_stablelm-tuned-alpha-7b</th>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.992739</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinchilla (70B)_Qwen2.5-Coder-7B</th>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.994563</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.999424</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.999275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-20250514_16K</th>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.993635</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.999822</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.998176</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.999662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablelm-tuned-alpha-7b_opt-1.3b</th>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.992163</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.999189</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.997678</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-001_mpt-30b</th>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.993194</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999413</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <td>0.998254</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.998176</td>\n",
       "      <td>0.998158</td>\n",
       "      <td>0.994421</td>\n",
       "      <td>0.998208</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998585</td>\n",
       "      <td>0.998315</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.997678</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>0.997984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1_gemma-2b</th>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.992757</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base_Llama-2-7b</th>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.992761</td>\n",
       "      <td>0.999524</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor                                       Baichuan-2-13B-Base_text-davinci-001  \\\n",
       "anchor                                                                              \n",
       "Baichuan-2-13B-Base_text-davinci-001                                     1.000000   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                       0.999940   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                 0.999911   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                        0.999417   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                              0.999716   \n",
       "...                                                                           ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                         0.999844   \n",
       "text-davinci-001_mpt-30b                                                 0.999972   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                       0.998254   \n",
       "vicuna-13b-v1.1_gemma-2b                                                 0.999932   \n",
       "xgen-7b-8k-base_Llama-2-7b                                               0.999932   \n",
       "\n",
       "anchor                                       Baichuan-2-7B-Base_vicuna-13b-v1.1  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_text-davinci-001                                   0.999940   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                     1.000000   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                               0.999950   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                      0.999253   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                            0.999652   \n",
       "...                                                                         ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                       0.999929   \n",
       "text-davinci-001_mpt-30b                                               0.999929   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                     0.997987   \n",
       "vicuna-13b-v1.1_gemma-2b                                               0.999979   \n",
       "xgen-7b-8k-base_Llama-2-7b                                             0.999986   \n",
       "\n",
       "anchor                                       Cerebras-GPT-13B_stablelm-tuned-alpha-7b  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                                         0.999911   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                           0.999950   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                     1.000000   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                            0.999246   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                  0.999655   \n",
       "...                                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                             0.999936   \n",
       "text-davinci-001_mpt-30b                                                     0.999897   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                           0.997952   \n",
       "vicuna-13b-v1.1_gemma-2b                                                     0.999943   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                   0.999964   \n",
       "\n",
       "anchor                                       Chinchilla (70B)_Qwen2.5-Coder-7B  \\\n",
       "anchor                                                                           \n",
       "Baichuan-2-13B-Base_text-davinci-001                                  0.999417   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                    0.999253   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                              0.999246   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                     1.000000   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                           0.999420   \n",
       "...                                                                        ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                      0.999068   \n",
       "text-davinci-001_mpt-30b                                              0.999392   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                    0.998414   \n",
       "vicuna-13b-v1.1_gemma-2b                                              0.999246   \n",
       "xgen-7b-8k-base_Llama-2-7b                                            0.999275   \n",
       "\n",
       "anchor                                       DeepSeek-R1-0528_claude-opus-4-20250514_16K  \\\n",
       "anchor                                                                                     \n",
       "Baichuan-2-13B-Base_text-davinci-001                                            0.999716   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                              0.999652   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                        0.999655   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                               0.999420   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                     1.000000   \n",
       "...                                                                                  ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                                0.999584   \n",
       "text-davinci-001_mpt-30b                                                        0.999691   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                              0.998176   \n",
       "vicuna-13b-v1.1_gemma-2b                                                        0.999644   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                      0.999662   \n",
       "\n",
       "anchor                                       DeepSeek-R1_claude-3-7-sonnet-20250219_16K  \\\n",
       "anchor                                                                                    \n",
       "Baichuan-2-13B-Base_text-davinci-001                                           0.999648   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                             0.999570   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                       0.999577   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                              0.999438   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                    0.999950   \n",
       "...                                                                                 ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                               0.999495   \n",
       "text-davinci-001_mpt-30b                                                       0.999623   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                             0.998158   \n",
       "vicuna-13b-v1.1_gemma-2b                                                       0.999563   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                     0.999580   \n",
       "\n",
       "anchor                                       DeepSeek-V2_Qwen2.5-72B  \\\n",
       "anchor                                                                 \n",
       "Baichuan-2-13B-Base_text-davinci-001                        0.993223   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                          0.992764   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                    0.992739   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                           0.994563   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                 0.993635   \n",
       "...                                                              ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                            0.992163   \n",
       "text-davinci-001_mpt-30b                                    0.993194   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                          0.994421   \n",
       "vicuna-13b-v1.1_gemma-2b                                    0.992757   \n",
       "xgen-7b-8k-base_Llama-2-7b                                  0.992761   \n",
       "\n",
       "anchor                                       DeepSeek-V3-0324_gpt-4.1-2025-04-14  \\\n",
       "anchor                                                                             \n",
       "Baichuan-2-13B-Base_text-davinci-001                                    0.999605   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                      0.999516   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                0.999520   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                       0.999438   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                             0.999932   \n",
       "...                                                                          ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                        0.999428   \n",
       "text-davinci-001_mpt-30b                                                0.999580   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                      0.998208   \n",
       "vicuna-13b-v1.1_gemma-2b                                                0.999509   \n",
       "xgen-7b-8k-base_Llama-2-7b                                              0.999524   \n",
       "\n",
       "anchor                                       DeepSeek-V3_gemini-1.5-pro-002  \\\n",
       "anchor                                                                        \n",
       "Baichuan-2-13B-Base_text-davinci-001                               0.999492   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                 0.999378   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                           0.999385   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                  0.999396   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                        0.999872   \n",
       "...                                                                     ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                   0.999271   \n",
       "text-davinci-001_mpt-30b                                           0.999467   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                 0.998275   \n",
       "vicuna-13b-v1.1_gemma-2b                                           0.999371   \n",
       "xgen-7b-8k-base_Llama-2-7b                                         0.999388   \n",
       "\n",
       "anchor                                       GLaM (MoE)_LLaMA-33B  ...  \\\n",
       "anchor                                                             ...   \n",
       "Baichuan-2-13B-Base_text-davinci-001                     0.999829  ...   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                       0.999758  ...   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                 0.999708  ...   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                        0.999488  ...   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K              0.999666  ...   \n",
       "...                                                           ...  ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                         0.999602  ...   \n",
       "text-davinci-001_mpt-30b                                 0.999808  ...   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                       0.998435  ...   \n",
       "vicuna-13b-v1.1_gemma-2b                                 0.999751  ...   \n",
       "xgen-7b-8k-base_Llama-2-7b                               0.999751  ...   \n",
       "\n",
       "anchor                                       phi-2_Llama-2-34b  \\\n",
       "anchor                                                           \n",
       "Baichuan-2-13B-Base_text-davinci-001                  0.999783   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                    0.999669   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b              0.999623   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                     0.999637   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K           0.999716   \n",
       "...                                                        ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                      0.999492   \n",
       "text-davinci-001_mpt-30b                              0.999762   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                    0.998585   \n",
       "vicuna-13b-v1.1_gemma-2b                              0.999662   \n",
       "xgen-7b-8k-base_Llama-2-7b                            0.999659   \n",
       "\n",
       "anchor                                       phi-4_gpt-4.1-nano-2025-04-14  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_text-davinci-001                              0.999460   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                0.999328   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                          0.999335   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                 0.999424   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                       0.999812   \n",
       "...                                                                    ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                  0.999204   \n",
       "text-davinci-001_mpt-30b                                          0.999431   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                0.998315   \n",
       "vicuna-13b-v1.1_gemma-2b                                          0.999321   \n",
       "xgen-7b-8k-base_Llama-2-7b                                        0.999339   \n",
       "\n",
       "anchor                                       qwen-max-2025-01-25_phi-4  \\\n",
       "anchor                                                                   \n",
       "Baichuan-2-13B-Base_text-davinci-001                          0.999470   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                            0.999346   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                      0.999353   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                             0.999435   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                   0.999822   \n",
       "...                                                                ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                              0.999225   \n",
       "text-davinci-001_mpt-30b                                      0.999442   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                            0.998325   \n",
       "vicuna-13b-v1.1_gemma-2b                                      0.999339   \n",
       "xgen-7b-8k-base_Llama-2-7b                                    0.999356   \n",
       "\n",
       "anchor                                       qwen2.5-72b-instruct_Llama-4-Scout-17B-16E-Instruct  \\\n",
       "anchor                                                                                             \n",
       "Baichuan-2-13B-Base_text-davinci-001                                                  0.999442     \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                                    0.999314     \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                              0.999321     \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                                     0.999388     \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                           0.999776     \n",
       "...                                                                                        ...     \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                                      0.999189     \n",
       "text-davinci-001_mpt-30b                                                              0.999413     \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                                    0.998290     \n",
       "vicuna-13b-v1.1_gemma-2b                                                              0.999307     \n",
       "xgen-7b-8k-base_Llama-2-7b                                                            0.999324     \n",
       "\n",
       "anchor                                       qwen3-235b-a22b_gemini-2.0-pro-exp-02-05  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                                         0.999410   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                           0.999342   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                                     0.999346   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                            0.999307   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                                  0.999772   \n",
       "...                                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                             0.999243   \n",
       "text-davinci-001_mpt-30b                                                     0.999385   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                           0.998108   \n",
       "vicuna-13b-v1.1_gemma-2b                                                     0.999335   \n",
       "xgen-7b-8k-base_Llama-2-7b                                                   0.999349   \n",
       "\n",
       "anchor                                       stablelm-tuned-alpha-7b_opt-1.3b  \\\n",
       "anchor                                                                          \n",
       "Baichuan-2-13B-Base_text-davinci-001                                 0.999844   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                   0.999929   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                             0.999936   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                    0.999068   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                          0.999584   \n",
       "...                                                                       ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                     1.000000   \n",
       "text-davinci-001_mpt-30b                                             0.999829   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                   0.997678   \n",
       "vicuna-13b-v1.1_gemma-2b                                             0.999922   \n",
       "xgen-7b-8k-base_Llama-2-7b                                           0.999947   \n",
       "\n",
       "anchor                                       text-davinci-001_mpt-30b  \\\n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                         0.999972   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                           0.999929   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                     0.999897   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                            0.999392   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                  0.999691   \n",
       "...                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                             0.999829   \n",
       "text-davinci-001_mpt-30b                                     1.000000   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                           0.998226   \n",
       "vicuna-13b-v1.1_gemma-2b                                     0.999922   \n",
       "xgen-7b-8k-base_Llama-2-7b                                   0.999922   \n",
       "\n",
       "anchor                                       text-davinci-002_Qwen2.5-Coder-14B  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_text-davinci-001                                   0.998254   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                                     0.997987   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                               0.997952   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                                      0.998414   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                            0.998176   \n",
       "...                                                                         ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                                       0.997678   \n",
       "text-davinci-001_mpt-30b                                               0.998226   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                                     1.000000   \n",
       "vicuna-13b-v1.1_gemma-2b                                               0.997980   \n",
       "xgen-7b-8k-base_Llama-2-7b                                             0.997984   \n",
       "\n",
       "anchor                                       vicuna-13b-v1.1_gemma-2b  \\\n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_text-davinci-001                         0.999932   \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                           0.999979   \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                     0.999943   \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                            0.999246   \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                  0.999644   \n",
       "...                                                               ...   \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                             0.999922   \n",
       "text-davinci-001_mpt-30b                                     0.999922   \n",
       "text-davinci-002_Qwen2.5-Coder-14B                           0.997980   \n",
       "vicuna-13b-v1.1_gemma-2b                                     1.000000   \n",
       "xgen-7b-8k-base_Llama-2-7b                                   0.999979   \n",
       "\n",
       "anchor                                       xgen-7b-8k-base_Llama-2-7b  \n",
       "anchor                                                                   \n",
       "Baichuan-2-13B-Base_text-davinci-001                           0.999932  \n",
       "Baichuan-2-7B-Base_vicuna-13b-v1.1                             0.999986  \n",
       "Cerebras-GPT-13B_stablelm-tuned-alpha-7b                       0.999964  \n",
       "Chinchilla (70B)_Qwen2.5-Coder-7B                              0.999275  \n",
       "DeepSeek-R1-0528_claude-opus-4-20250514_16K                    0.999662  \n",
       "...                                                                 ...  \n",
       "stablelm-tuned-alpha-7b_opt-1.3b                               0.999947  \n",
       "text-davinci-001_mpt-30b                                       0.999922  \n",
       "text-davinci-002_Qwen2.5-Coder-14B                             0.997984  \n",
       "vicuna-13b-v1.1_gemma-2b                                       0.999979  \n",
       "xgen-7b-8k-base_Llama-2-7b                                     1.000000  \n",
       "\n",
       "[149 rows x 149 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per model-pair fit (capabilities):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o1-mini-2024-09-12_high_claude-opus-4-1-20250805</th>\n",
       "      <td>0.999630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-7-sonnet-20250219_16K_o1-mini-2024-09-12_high</th>\n",
       "      <td>0.999630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-3-beta_claude-opus-4-20250514</th>\n",
       "      <td>0.999628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini-2024-09-12_medium_qwen3-235b-a22b</th>\n",
       "      <td>0.999627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grok-3-mini-beta_low_grok-3-beta</th>\n",
       "      <td>0.999625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0613_internlm-20b</th>\n",
       "      <td>0.998529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-14B_falcon-180B</th>\n",
       "      <td>0.998440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-davinci-002_Qwen2.5-Coder-14B</th>\n",
       "      <td>0.998211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3-mini-4k-instruct_PaLM 2-L</th>\n",
       "      <td>0.997282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-V2_Qwen2.5-72B</th>\n",
       "      <td>0.994050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rho\n",
       "anchor                                                      \n",
       "o1-mini-2024-09-12_high_claude-opus-4-1-20250805    0.999630\n",
       "claude-3-7-sonnet-20250219_16K_o1-mini-2024-09-...  0.999630\n",
       "grok-3-beta_claude-opus-4-20250514                  0.999628\n",
       "o1-mini-2024-09-12_medium_qwen3-235b-a22b           0.999627\n",
       "grok-3-mini-beta_low_grok-3-beta                    0.999625\n",
       "...                                                      ...\n",
       "gpt-3.5-turbo-0613_internlm-20b                     0.998529\n",
       "Qwen2.5-Coder-14B_falcon-180B                       0.998440\n",
       "text-davinci-002_Qwen2.5-Coder-14B                  0.998211\n",
       "Phi-3-mini-4k-instruct_PaLM 2-L                     0.997282\n",
       "DeepSeek-V2_Qwen2.5-72B                             0.994050\n",
       "\n",
       "[149 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Spearman rank correlation across anchor model pairs\n",
    "# - Difficulties (by benchmark)\n",
    "# - Capabilities (by model)\n",
    "# Robust to duplicates and missing values\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def _spearman_corr_from_long(df_long: pd.DataFrame, index_col: str, columns_col: str, values_col: str) -> pd.DataFrame:\n",
    "    wide = df_long.pivot_table(\n",
    "        index=index_col,\n",
    "        columns=columns_col,\n",
    "        values=values_col,\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    wide = wide.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=0, how=\"all\")\n",
    "    if wide.shape[1] < 2:\n",
    "        return pd.DataFrame()\n",
    "    ranks = wide.rank(axis=0, method=\"average\", na_option=\"keep\")\n",
    "    return ranks.corr(method=\"pearson\", min_periods=2)\n",
    "\n",
    "# --- Difficulties across anchor model pairs ---------------------------------\n",
    "print(\"=== Spearman across anchor model pairs (benchmark difficulties) ===\")\n",
    "spearman_difficulty_pairs = _spearman_corr_from_long(\n",
    "    summary_benchmarks.rename(columns={\"anchor_model_pair\": \"anchor\"}),\n",
    "    index_col=\"benchmark_name\",\n",
    "    columns_col=\"anchor\",\n",
    "    values_col=\"estimated_difficulty\",\n",
    ")\n",
    "if spearman_difficulty_pairs.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for difficulties across model pairs.\")\n",
    "else:\n",
    "    display(spearman_difficulty_pairs)\n",
    "    mean_rho_difficulty_pairs = spearman_difficulty_pairs.apply(\n",
    "        lambda s: s.drop(labels=s.name).mean(), axis=0\n",
    "    ).sort_values(ascending=False).to_frame(\"mean_rho\")\n",
    "    print(\"\\nMean off-diagonal Spearman per model-pair fit (difficulties):\")\n",
    "    display(mean_rho_difficulty_pairs)\n",
    "\n",
    "# --- Capabilities across anchor model pairs ---------------------------------\n",
    "print(\"\\n=== Spearman across anchor model pairs (model capabilities) ===\")\n",
    "spearman_capability_pairs = _spearman_corr_from_long(\n",
    "    summary_models.rename(columns={\"anchor_model_pair\": \"anchor\"}),\n",
    "    index_col=\"model\",\n",
    "    columns_col=\"anchor\",\n",
    "    values_col=\"estimated_capability\",\n",
    ")\n",
    "if spearman_capability_pairs.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for capabilities across model pairs.\")\n",
    "else:\n",
    "    display(spearman_capability_pairs)\n",
    "    mean_rho_capability_pairs = spearman_capability_pairs.apply(\n",
    "        lambda s: s.drop(labels=s.name).mean(), axis=0\n",
    "    ).sort_values(ascending=False).to_frame(\"mean_rho\")\n",
    "    print(\"\\nMean off-diagonal Spearman per model-pair fit (capabilities):\")\n",
    "    display(mean_rho_capability_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8ab8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_stitching_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
