{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a733e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path.cwd().parent)\n",
    "# print(\"cwd is now:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59f7aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null performances after coercion: 0\n",
      "after saturation filter 2408\n",
      "after filter num benchmarks 1965\n",
      "after merge with model versions 1961\n",
      "after date filter (>= 2022-11-01) 1762\n",
      "after merge with benchmark dates 1762\n",
      "Original number of rows: 1762\n",
      "Number of rows after aggregation: 1320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "from data_loader import scores_df\n",
    "from fit import fit_statistical_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4df6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Custom color palette\n",
    "custom_colors = [\n",
    "    '#00A5A6',  # teal\n",
    "    '#E03D90',  # pink\n",
    "    '#FC6538',  # orange\n",
    "    '#6A3ECB',  # purple\n",
    "    '#0058DC',  # blue\n",
    "    '#EA8D00',  # yellow\n",
    "    '#B087F4',  # lightPurple\n",
    "    '#279E27',  # green\n",
    "    '#009AF1',  # lightBlue\n",
    "    '#015D90',  # darkBlue\n",
    "    '#EA4831',  # red\n",
    "    '#E1C700',  # yellow2\n",
    "    '#46FFFF',  # turquoise\n",
    "    '#63F039',  # lightGreen\n",
    "]\n",
    "\n",
    "sns.set_palette(custom_colors)\n",
    "colors = sns.color_palette()\n",
    "\n",
    "# === Seaborn global settings ===\n",
    "sns.set_theme(\n",
    "    style=\"whitegrid\",        # or \"darkgrid\", \"ticks\", \"white\"\n",
    "    palette=custom_colors,    # your custom color palette\n",
    "    context=\"notebook\"        # scaling for labels/titles (\"paper\", \"notebook\", \"talk\", \"poster\")\n",
    ")\n",
    "\n",
    "# === Matplotlib global settings (rcParams) ===\n",
    "plt.rcParams.update({\n",
    "    # Figure\n",
    "    \"figure.figsize\": (8, 5),\n",
    "    \"figure.dpi\": 120,\n",
    "    \n",
    "    # Axes\n",
    "    \"axes.titley\": 1.02,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.titlelocation\": 'center',\n",
    "    \"axes.titlepad\": 0,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"axes.labelpad\": 10,           # spacing between axis and label\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \n",
    "    # Ticks\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    # tick marks size\n",
    "    \"xtick.major.size\": 5,\n",
    "    \"ytick.major.size\": 5,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \n",
    "    # tick visibility\n",
    "    \"xtick.top\": False,\n",
    "    \"xtick.bottom\": True,\n",
    "    \"ytick.left\": True,\n",
    "    \"ytick.right\": False,\n",
    "    \n",
    "    # Legend\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"legend.loc\": \"upper left\",\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.borderaxespad\": 0,\n",
    "\n",
    "    \n",
    "    # Lines and markers\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"lines.markersize\": 8,\n",
    "    \"lines.markeredgecolor\": 'auto',   # white outline (stroke)\n",
    "    \"lines.markeredgewidth\": 0.5,   \n",
    "    # title alignment left\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Error bars\n",
    "    \"errorbar.capsize\": 3,\n",
    "    \n",
    "    # Font\n",
    "    \"font.family\": \"Arial\",\n",
    "    \"font.sans-serif\": [\"DejaVu Sans\"],\n",
    "    \n",
    "    # Grid\n",
    "    \"grid.alpha\": 0.3,\n",
    "    \"grid.linestyle\": \"-\",\n",
    "    \"grid.color\": \"lightgray\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fbd2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7806e+01, final cost 3.5079e+00, first-order optimality 5.77e-04.\n"
     ]
    }
   ],
   "source": [
    "anchor_mode = \"model\"  # \"model\", \"benchmark\"\n",
    "anchor_benchmark = \"Winogrande\"\n",
    "anchor_difficulty = 0\n",
    "anchor_slope = 1\n",
    "anchor_model1 = \"claude-2.0\"\n",
    "anchor_model1_capability = 1.177630\n",
    "anchor_model2 = \"claude-3-opus-20240229\"\n",
    "anchor_model2_capability = 1.311554\n",
    "\n",
    "df_anchor, df_cm_anchor, df_db_anchor = fit_statistical_model(\n",
    "    scores_df,\n",
    "    anchor_mode=anchor_mode,\n",
    "    anchor_benchmark=anchor_benchmark,\n",
    "    anchor_difficulty=anchor_difficulty,\n",
    "    anchor_slope=anchor_slope,\n",
    "    anchor_model1=anchor_model1,\n",
    "    anchor_model1_capability=anchor_model1_capability,\n",
    "    anchor_model2=anchor_model2,\n",
    "    anchor_model2_capability=anchor_model2_capability,\n",
    ")\n",
    "\n",
    "df_cm_anchor[\"date_obj\"] = pd.to_datetime(df_cm_anchor[\"date\"])\n",
    "\n",
    "# anchor_benchmark = \"Winogrande\"\n",
    "# anchor_difficulty = 0\n",
    "# anchor_slope = 1\n",
    "# df_anchor, df_cm_anchor, df_db_anchor = fit_statistical_model(scores_df, anchor_benchmark, anchor_difficulty, anchor_slope)\n",
    "\n",
    "# # Convert date strings to datetime objects\n",
    "# df_cm_anchor['date_obj'] = pd.to_datetime(df_cm_anchor['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193f1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8329e+01, final cost 3.4375e+00, first-order optimality 5.59e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8431e+01, final cost 3.4374e+00, first-order optimality 5.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8099e+01, final cost 3.4373e+00, first-order optimality 4.51e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8577e+01, final cost 3.4380e+00, first-order optimality 3.72e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.8422e+01, final cost 3.4379e+00, first-order optimality 1.77e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8455e+01, final cost 3.4372e+00, first-order optimality 5.26e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8461e+01, final cost 3.4380e+00, first-order optimality 2.53e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8513e+01, final cost 3.4379e+00, first-order optimality 2.49e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8483e+01, final cost 3.4381e+00, first-order optimality 2.99e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8466e+01, final cost 3.4373e+00, first-order optimality 4.68e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8447e+01, final cost 3.4378e+00, first-order optimality 4.34e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8494e+01, final cost 3.4371e+00, first-order optimality 3.75e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8466e+01, final cost 3.4372e+00, first-order optimality 7.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8461e+01, final cost 3.4372e+00, first-order optimality 5.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8490e+01, final cost 3.4372e+00, first-order optimality 2.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.9516e+01, final cost 3.4338e+00, first-order optimality 3.51e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8571e+01, final cost 3.4371e+00, first-order optimality 7.21e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8495e+01, final cost 3.4366e+00, first-order optimality 8.16e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8374e+01, final cost 3.4356e+00, first-order optimality 3.48e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8640e+01, final cost 3.4350e+00, first-order optimality 4.12e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 4.8567e+01, final cost 3.4312e+00, first-order optimality 8.03e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.8479e+01, final cost 3.4362e+00, first-order optimality 1.99e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8458e+01, final cost 3.4370e+00, first-order optimality 2.51e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8327e+01, final cost 3.4342e+00, first-order optimality 1.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8567e+01, final cost 3.4350e+00, first-order optimality 4.86e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8860e+01, final cost 3.4337e+00, first-order optimality 1.77e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8572e+01, final cost 3.4372e+00, first-order optimality 6.49e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8424e+01, final cost 3.4371e+00, first-order optimality 7.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8457e+01, final cost 3.4372e+00, first-order optimality 1.78e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8462e+01, final cost 3.4371e+00, first-order optimality 4.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8458e+01, final cost 3.4371e+00, first-order optimality 2.23e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 5.0719e+01, final cost 3.4337e+00, first-order optimality 2.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 4.8451e+01, final cost 3.4371e+00, first-order optimality 4.84e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8390e+01, final cost 3.4367e+00, first-order optimality 3.88e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8027e+01, final cost 3.4343e+00, first-order optimality 3.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.8464e+01, final cost 3.4370e+00, first-order optimality 9.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8569e+01, final cost 3.4368e+00, first-order optimality 4.24e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.8473e+01, final cost 3.4371e+00, first-order optimality 3.18e-04.\n"
     ]
    }
   ],
   "source": [
    "all_runs = {}  # will map benchmark_name -> dict of outputs\n",
    "failed = []  # keep track of anything that errors out\n",
    "\n",
    "# --- loop --------------------------------------------------------------------\n",
    "for _, row in df_db_anchor.iterrows():\n",
    "    anchor_benchmark = row[\"benchmark_name\"]  # e.g. \"HellaSwag\"\n",
    "    anchor_difficulty = float(row[\"estimated_difficulty\"])\n",
    "    anchor_slope = float(row[\"estimated_slope\"])\n",
    "\n",
    "    try:\n",
    "        df, df_cm, df_db = fit_statistical_model(\n",
    "            scores_df,\n",
    "            anchor_mode=\"benchmark\",\n",
    "            anchor_benchmark=anchor_benchmark,\n",
    "            anchor_difficulty=anchor_difficulty,\n",
    "            anchor_slope=anchor_slope,\n",
    "        )\n",
    "        all_runs[anchor_benchmark] = {\n",
    "            \"df1\": df,\n",
    "            \"df_cm1\": df_cm,\n",
    "            \"df_db\": df_db,\n",
    "            # cache the anchor values for reference\n",
    "            \"anchor_difficulty\": anchor_difficulty,\n",
    "            \"anchor_slope\": anchor_slope,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        failed.append((anchor_benchmark, str(e)))\n",
    "\n",
    "# --- post-processing (optional) ----------------------------------------------\n",
    "# 1) quick glance at what failed\n",
    "if failed:\n",
    "    print(\"Benchmarks that raised errors:\", failed)\n",
    "\n",
    "# 2) pull out the difficulty/slope re-estimates across all runs\n",
    "summary = pd.concat(\n",
    "    {\n",
    "        k: v[\"df_db\"][[\"benchmark_name\", \"estimated_difficulty\", \"estimated_slope\"]]\n",
    "        for k, v in all_runs.items()\n",
    "    },\n",
    "    names=[\"anchor_benchmark\"],\n",
    ").reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31753a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== variation in benchmark difficulties ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.713370</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.637281</td>\n",
       "      <td>0.783698</td>\n",
       "      <td>0.051878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.121934</td>\n",
       "      <td>0.059864</td>\n",
       "      <td>0.032295</td>\n",
       "      <td>0.224582</td>\n",
       "      <td>0.484275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>2.147092</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>2.088145</td>\n",
       "      <td>2.237996</td>\n",
       "      <td>0.016130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>1.804525</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>1.739926</td>\n",
       "      <td>1.876165</td>\n",
       "      <td>0.015648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.398362</td>\n",
       "      <td>0.048738</td>\n",
       "      <td>0.318491</td>\n",
       "      <td>0.485545</td>\n",
       "      <td>0.120681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>2.433161</td>\n",
       "      <td>0.042823</td>\n",
       "      <td>2.379396</td>\n",
       "      <td>2.541812</td>\n",
       "      <td>0.017360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>1.842318</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>1.778418</td>\n",
       "      <td>1.916093</td>\n",
       "      <td>0.015626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>2.784575</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>2.727842</td>\n",
       "      <td>2.901720</td>\n",
       "      <td>0.016632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>2.324813</td>\n",
       "      <td>0.039045</td>\n",
       "      <td>2.268867</td>\n",
       "      <td>2.424508</td>\n",
       "      <td>0.016566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>3.169196</td>\n",
       "      <td>0.055880</td>\n",
       "      <td>3.099703</td>\n",
       "      <td>3.302127</td>\n",
       "      <td>0.017392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>1.687705</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>1.621175</td>\n",
       "      <td>1.752599</td>\n",
       "      <td>0.015901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>2.536606</td>\n",
       "      <td>0.044727</td>\n",
       "      <td>2.484021</td>\n",
       "      <td>2.648221</td>\n",
       "      <td>0.017393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>2.964186</td>\n",
       "      <td>0.045278</td>\n",
       "      <td>2.912195</td>\n",
       "      <td>3.076665</td>\n",
       "      <td>0.015067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.408435</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>1.337914</td>\n",
       "      <td>1.456171</td>\n",
       "      <td>0.018087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>0.447007</td>\n",
       "      <td>0.046811</td>\n",
       "      <td>0.368318</td>\n",
       "      <td>0.531502</td>\n",
       "      <td>0.103297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>4.151262</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>4.080818</td>\n",
       "      <td>4.282236</td>\n",
       "      <td>0.013344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.802669</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.720420</td>\n",
       "      <td>0.866712</td>\n",
       "      <td>0.044183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>-0.846136</td>\n",
       "      <td>0.104364</td>\n",
       "      <td>-1.044827</td>\n",
       "      <td>-0.688410</td>\n",
       "      <td>-0.121664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>-1.711995</td>\n",
       "      <td>0.126259</td>\n",
       "      <td>-1.951220</td>\n",
       "      <td>-1.529358</td>\n",
       "      <td>-0.072746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.423870</td>\n",
       "      <td>0.045941</td>\n",
       "      <td>0.335066</td>\n",
       "      <td>0.511753</td>\n",
       "      <td>0.106910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>1.420684</td>\n",
       "      <td>0.025915</td>\n",
       "      <td>1.350170</td>\n",
       "      <td>1.469035</td>\n",
       "      <td>0.017993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>1.363486</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>1.292192</td>\n",
       "      <td>1.409074</td>\n",
       "      <td>0.018802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.234083</td>\n",
       "      <td>0.055326</td>\n",
       "      <td>0.150012</td>\n",
       "      <td>0.330616</td>\n",
       "      <td>0.233135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>4.341863</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>4.272566</td>\n",
       "      <td>4.466502</td>\n",
       "      <td>0.011980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>2.008384</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>1.945905</td>\n",
       "      <td>2.087528</td>\n",
       "      <td>0.015005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>1.823912</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>1.759596</td>\n",
       "      <td>1.896768</td>\n",
       "      <td>0.015641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.025580</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>-0.076876</td>\n",
       "      <td>0.133711</td>\n",
       "      <td>2.474223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>-2.510814</td>\n",
       "      <td>0.172058</td>\n",
       "      <td>-2.857189</td>\n",
       "      <td>-2.273477</td>\n",
       "      <td>-0.067594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>2.008350</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>1.947383</td>\n",
       "      <td>2.091587</td>\n",
       "      <td>0.015822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>0.273511</td>\n",
       "      <td>0.053775</td>\n",
       "      <td>0.190452</td>\n",
       "      <td>0.367664</td>\n",
       "      <td>0.193934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>2.159893</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>2.101333</td>\n",
       "      <td>2.251888</td>\n",
       "      <td>0.016252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>2.639469</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>2.587122</td>\n",
       "      <td>2.757735</td>\n",
       "      <td>0.018002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>2.141015</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>2.081724</td>\n",
       "      <td>2.229865</td>\n",
       "      <td>0.015761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>-1.822855</td>\n",
       "      <td>0.139901</td>\n",
       "      <td>-2.095358</td>\n",
       "      <td>-1.619587</td>\n",
       "      <td>-0.075704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>2.269983</td>\n",
       "      <td>0.038460</td>\n",
       "      <td>2.213270</td>\n",
       "      <td>2.368709</td>\n",
       "      <td>0.016712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>-0.554708</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>-0.638943</td>\n",
       "      <td>-0.459360</td>\n",
       "      <td>-0.076463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>2.153093</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>2.094342</td>\n",
       "      <td>2.244893</td>\n",
       "      <td>0.016252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>-0.952100</td>\n",
       "      <td>0.109210</td>\n",
       "      <td>-1.164376</td>\n",
       "      <td>-0.788836</td>\n",
       "      <td>-0.113144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean       std       min  \\\n",
       "benchmark_name                                                         \n",
       "ANLI                                    0.713370  0.037519  0.637281   \n",
       "ARC AI2                                 0.121934  0.059864  0.032295   \n",
       "ARC-AGI                                 2.147092  0.035111  2.088145   \n",
       "Aider polyglot                          1.804525  0.028626  1.739926   \n",
       "BBH                                     0.398362  0.048738  0.318491   \n",
       "Balrog                                  2.433161  0.042823  2.379396   \n",
       "CadEval                                 1.842318  0.029184  1.778418   \n",
       "Cybench                                 2.784575  0.046952  2.727842   \n",
       "DeepResearch Bench                      2.324813  0.039045  2.268867   \n",
       "Factorio learning environment           3.169196  0.055880  3.099703   \n",
       "Fiction.LiveBench                       1.687705  0.027206  1.621175   \n",
       "FrontierMath-2025-02-28-Private         2.536606  0.044727  2.484021   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  2.964186  0.045278  2.912195   \n",
       "GPQA diamond                            1.408435  0.025826  1.337914   \n",
       "GSM8K                                   0.447007  0.046811  0.368318   \n",
       "GSO-Bench                               4.151262  0.056160  4.080818   \n",
       "GeoBench                                0.802669  0.035953  0.720420   \n",
       "HellaSwag                              -0.846136  0.104364 -1.044827   \n",
       "LAMBADA                                -1.711995  0.126259 -1.951220   \n",
       "Lech Mazur Writing                      0.423870  0.045941  0.335066   \n",
       "LiveBench                               1.420684  0.025915  1.350170   \n",
       "MATH level 5                            1.363486  0.025989  1.292192   \n",
       "MMLU                                    0.234083  0.055326  0.150012   \n",
       "OSUniverse                              4.341863  0.052734  4.272566   \n",
       "OSWorld                                 2.008384  0.030552  1.945905   \n",
       "OTIS Mock AIME 2024-2025                1.823912  0.028922  1.759596   \n",
       "OpenBookQA                              0.025580  0.064163 -0.076876   \n",
       "PIQA                                   -2.510814  0.172058 -2.857189   \n",
       "SWE-Bench verified                      2.008350  0.032215  1.947383   \n",
       "ScienceQA                               0.273511  0.053775  0.190452   \n",
       "SimpleBench                             2.159893  0.035587  2.101333   \n",
       "Terminal Bench                          2.639469  0.048170  2.587122   \n",
       "The Agent Company                       2.141015  0.034211  2.081724   \n",
       "TriviaQA                               -1.822855  0.139901 -2.095358   \n",
       "VPCT                                    2.269983  0.038460  2.213270   \n",
       "VideoMME                               -0.554708  0.043000 -0.638943   \n",
       "WeirdML                                 2.153093  0.035475  2.094342   \n",
       "Winogrande                             -0.952100  0.109210 -1.164376   \n",
       "\n",
       "                                             max        cv  \n",
       "benchmark_name                                              \n",
       "ANLI                                    0.783698  0.051878  \n",
       "ARC AI2                                 0.224582  0.484275  \n",
       "ARC-AGI                                 2.237996  0.016130  \n",
       "Aider polyglot                          1.876165  0.015648  \n",
       "BBH                                     0.485545  0.120681  \n",
       "Balrog                                  2.541812  0.017360  \n",
       "CadEval                                 1.916093  0.015626  \n",
       "Cybench                                 2.901720  0.016632  \n",
       "DeepResearch Bench                      2.424508  0.016566  \n",
       "Factorio learning environment           3.302127  0.017392  \n",
       "Fiction.LiveBench                       1.752599  0.015901  \n",
       "FrontierMath-2025-02-28-Private         2.648221  0.017393  \n",
       "FrontierMath-Tier-4-2025-07-01-Private  3.076665  0.015067  \n",
       "GPQA diamond                            1.456171  0.018087  \n",
       "GSM8K                                   0.531502  0.103297  \n",
       "GSO-Bench                               4.282236  0.013344  \n",
       "GeoBench                                0.866712  0.044183  \n",
       "HellaSwag                              -0.688410 -0.121664  \n",
       "LAMBADA                                -1.529358 -0.072746  \n",
       "Lech Mazur Writing                      0.511753  0.106910  \n",
       "LiveBench                               1.469035  0.017993  \n",
       "MATH level 5                            1.409074  0.018802  \n",
       "MMLU                                    0.330616  0.233135  \n",
       "OSUniverse                              4.466502  0.011980  \n",
       "OSWorld                                 2.087528  0.015005  \n",
       "OTIS Mock AIME 2024-2025                1.896768  0.015641  \n",
       "OpenBookQA                              0.133711  2.474223  \n",
       "PIQA                                   -2.273477 -0.067594  \n",
       "SWE-Bench verified                      2.091587  0.015822  \n",
       "ScienceQA                               0.367664  0.193934  \n",
       "SimpleBench                             2.251888  0.016252  \n",
       "Terminal Bench                          2.757735  0.018002  \n",
       "The Agent Company                       2.229865  0.015761  \n",
       "TriviaQA                               -1.619587 -0.075704  \n",
       "VPCT                                    2.368709  0.016712  \n",
       "VideoMME                               -0.459360 -0.076463  \n",
       "WeirdML                                 2.244893  0.016252  \n",
       "Winogrande                             -0.788836 -0.113144  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== variation in model capabilities ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.050996</td>\n",
       "      <td>0.265982</td>\n",
       "      <td>0.436859</td>\n",
       "      <td>0.145771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>0.048814</td>\n",
       "      <td>0.063980</td>\n",
       "      <td>-0.047694</td>\n",
       "      <td>0.158007</td>\n",
       "      <td>1.293345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-7B</th>\n",
       "      <td>-0.130421</td>\n",
       "      <td>0.072253</td>\n",
       "      <td>-0.247740</td>\n",
       "      <td>-0.010548</td>\n",
       "      <td>-0.546660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.406902</td>\n",
       "      <td>0.085634</td>\n",
       "      <td>-0.555842</td>\n",
       "      <td>-0.270654</td>\n",
       "      <td>-0.207666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeQwen1.5-7B</th>\n",
       "      <td>0.056085</td>\n",
       "      <td>0.063733</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>0.164786</td>\n",
       "      <td>1.121315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b</th>\n",
       "      <td>0.451700</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>0.374496</td>\n",
       "      <td>0.537072</td>\n",
       "      <td>0.101801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b</th>\n",
       "      <td>-0.163630</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>-0.285025</td>\n",
       "      <td>-0.041850</td>\n",
       "      <td>-0.445408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-7b</th>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>-0.094898</td>\n",
       "      <td>0.120279</td>\n",
       "      <td>7.424784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.011060</td>\n",
       "      <td>0.066840</td>\n",
       "      <td>-0.115404</td>\n",
       "      <td>0.101683</td>\n",
       "      <td>-5.963485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.118304</td>\n",
       "      <td>0.071896</td>\n",
       "      <td>-0.234971</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>-0.599671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       std       min       max        cv\n",
       "model                                                                \n",
       "Baichuan-2-13B-Base  0.345200  0.050996  0.265982  0.436859  0.145771\n",
       "Baichuan-2-7B-Base   0.048814  0.063980 -0.047694  0.158007  1.293345\n",
       "Baichuan-7B         -0.130421  0.072253 -0.247740 -0.010548 -0.546660\n",
       "Cerebras-GPT-13B    -0.406902  0.085634 -0.555842 -0.270654 -0.207666\n",
       "CodeQwen1.5-7B       0.056085  0.063733 -0.042750  0.164786  1.121315\n",
       "...                       ...       ...       ...       ...       ...\n",
       "starcoder2-15b       0.451700  0.046601  0.374496  0.537072  0.101801\n",
       "starcoder2-3b       -0.163630  0.073860 -0.285025 -0.041850 -0.445408\n",
       "starcoder2-7b        0.008758  0.065900 -0.094898  0.120279  7.424784\n",
       "vicuna-13b-v1.1     -0.011060  0.066840 -0.115404  0.101683 -5.963485\n",
       "xgen-7b-8k-base     -0.118304  0.071896 -0.234971  0.000898 -0.599671\n",
       "\n",
       "[178 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1)  DIFFICULTY  ––  variation of each benchmark’s difficulty estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "difficulty_rows = []\n",
    "\n",
    "for anchor, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]  # difficulty table from that fit\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_difficulty\"]].copy()\n",
    "    out[\"anchor_benchmark\"] = anchor  # remember which fit this came from\n",
    "    difficulty_rows.append(out)\n",
    "\n",
    "difficulty_long = pd.concat(difficulty_rows, ignore_index=True)\n",
    "\n",
    "# drop the trivial row where the benchmark was forced to be the anchor (always fixed):\n",
    "difficulty_long = difficulty_long[\n",
    "    difficulty_long[\"benchmark_name\"] != difficulty_long[\"anchor_benchmark\"]\n",
    "]\n",
    "\n",
    "difficulty_stats = (\n",
    "    difficulty_long.groupby(\"benchmark_name\")[\"estimated_difficulty\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean(),  # coefficient of variation\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2)  CAPABILITY  ––  variation of each model’s capability estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "capability_rows = []\n",
    "\n",
    "for anchor, run in all_runs.items():\n",
    "    df_cm = run[\"df_cm1\"]  # capability table from that fit\n",
    "    out = df_cm[[\"model\", \"estimated_capability\"]].copy()\n",
    "    out[\"anchor_benchmark\"] = anchor\n",
    "    capability_rows.append(out)\n",
    "\n",
    "capability_long = pd.concat(capability_rows, ignore_index=True)\n",
    "\n",
    "capability_stats = (\n",
    "    capability_long.groupby(\"model\")[\"estimated_capability\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean(),\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3)  quick look\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"=== variation in benchmark difficulties ===\")\n",
    "display(difficulty_stats)\n",
    "\n",
    "print(\"\\n=== variation in model capabilities ===\")\n",
    "display(capability_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85924acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spearman rank correlation across fits (benchmark difficulties) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th>ANLI</th>\n",
       "      <th>ARC AI2</th>\n",
       "      <th>ARC-AGI</th>\n",
       "      <th>Aider polyglot</th>\n",
       "      <th>BBH</th>\n",
       "      <th>Balrog</th>\n",
       "      <th>CadEval</th>\n",
       "      <th>Cybench</th>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <th>...</th>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <th>ScienceQA</th>\n",
       "      <th>SimpleBench</th>\n",
       "      <th>Terminal Bench</th>\n",
       "      <th>The Agent Company</th>\n",
       "      <th>TriviaQA</th>\n",
       "      <th>VPCT</th>\n",
       "      <th>VideoMME</th>\n",
       "      <th>WeirdML</th>\n",
       "      <th>Winogrande</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.998777</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.998808</td>\n",
       "      <td>0.999456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998488</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.998623</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.998694</td>\n",
       "      <td>0.999061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998789</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.998544</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.999464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.998488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.998499</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.998804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.999024</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.999087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.998499</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.998679</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.998448</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.998537</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.998469</td>\n",
       "      <td>0.999304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.998757</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.998946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.998623</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.998909</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.999044</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.999101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.999281</td>\n",
       "      <td>0.999302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.998694</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.999024</td>\n",
       "      <td>0.998679</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999525</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.999020</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999061</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>0.999466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.998760</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998878</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999064</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.999107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.998781</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.999548</td>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.998482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.998817</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.998967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>0.999229</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.999304</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>0.999266</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.998869</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.999164</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.999081</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.998804</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998730</td>\n",
       "      <td>0.999028</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.998739</td>\n",
       "      <td>0.998804</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999505</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999325</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.999585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999761</td>\n",
       "      <td>0.998985</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.999203</td>\n",
       "      <td>0.999030</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.998785</td>\n",
       "      <td>0.999122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.999095</td>\n",
       "      <td>0.999188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.998873</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.999090</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.999089</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.999061</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>0.999550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.998695</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>0.999030</td>\n",
       "      <td>0.999047</td>\n",
       "      <td>0.999326</td>\n",
       "      <td>0.998937</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.998974</td>\n",
       "      <td>0.999268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>0.999147</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999578</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.999223</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.999410</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.999184</td>\n",
       "      <td>0.999043</td>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.999127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999647</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.999113</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>0.999139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.999276</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0.999080</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999150</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>0.998729</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998450</td>\n",
       "      <td>0.998629</td>\n",
       "      <td>0.998844</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998785</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.998530</td>\n",
       "      <td>0.998508</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999472</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999386</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.999476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999080</td>\n",
       "      <td>0.999682</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.999269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999172</td>\n",
       "      <td>0.998666</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.999083</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998944</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.999066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.998635</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.998482</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.998539</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.998477</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.998495</td>\n",
       "      <td>0.999541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>0.999682</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999636</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.999448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>0.999799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999196</td>\n",
       "      <td>0.998789</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.999525</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.999248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.998670</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.999594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.998777</td>\n",
       "      <td>0.998452</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>0.998448</td>\n",
       "      <td>0.999783</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.998544</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.998537</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.999318</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.999530</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999303</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.998670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.998804</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.998909</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.999020</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.998826</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998787</td>\n",
       "      <td>0.999885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.998808</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.998469</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999281</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.999282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.998966</td>\n",
       "      <td>0.999087</td>\n",
       "      <td>0.999304</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.999045</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor_benchmark                            ANLI   ARC AI2   ARC-AGI  \\\n",
       "anchor_benchmark                                                       \n",
       "ANLI                                    1.000000  0.999294  0.998850   \n",
       "ARC AI2                                 0.999294  1.000000  0.998488   \n",
       "ARC-AGI                                 0.998850  0.998488  1.000000   \n",
       "Aider polyglot                          0.999255  0.998711  0.999496   \n",
       "BBH                                     0.999539  0.999783  0.998499   \n",
       "Balrog                                  0.998757  0.998466  0.999610   \n",
       "CadEval                                 0.999095  0.998623  0.999678   \n",
       "Cybench                                 0.999136  0.998857  0.999237   \n",
       "DeepResearch Bench                      0.998990  0.998694  0.999447   \n",
       "Factorio learning environment           0.999350  0.999061  0.999266   \n",
       "Fiction.LiveBench                       0.999344  0.998760  0.999414   \n",
       "FrontierMath-2025-02-28-Private         0.998781  0.998497  0.999548   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999229  0.998946  0.999238   \n",
       "GPQA diamond                            0.999539  0.998865  0.999266   \n",
       "GSM8K                                   1.000000  0.999692  0.998804   \n",
       "GSO-Bench                               0.999505  0.999206  0.999325   \n",
       "GeoBench                                0.999761  0.998985  0.999141   \n",
       "HellaSwag                               0.999442  0.999541  0.998873   \n",
       "LAMBADA                                 0.999498  0.999411  0.999089   \n",
       "Lech Mazur Writing                      0.999645  0.999368  0.999006   \n",
       "LiveBench                               0.999438  0.998811  0.999338   \n",
       "MATH level 5                            0.999647  0.998923  0.999201   \n",
       "MMLU                                    0.999362  1.000000  0.998478   \n",
       "OSUniverse                              0.999696  0.999384  0.999419   \n",
       "OSWorld                                 0.999261  0.998825  0.999885   \n",
       "OTIS Mock AIME 2024-2025                0.999172  0.998666  0.999584   \n",
       "OpenBookQA                              0.999242  1.000000  0.998515   \n",
       "PIQA                                    0.999682  0.999390  0.999433   \n",
       "SWE-Bench verified                      0.999196  0.998789  0.999778   \n",
       "ScienceQA                               0.999685  0.999641  0.998723   \n",
       "SimpleBench                             0.998777  0.998452  0.999885   \n",
       "Terminal Bench                          0.998826  0.998544  0.999504   \n",
       "The Agent Company                       0.998900  0.998515  1.000000   \n",
       "TriviaQA                                0.999572  0.999385  0.999243   \n",
       "VPCT                                    0.998756  0.998446  0.999780   \n",
       "VideoMME                                0.999452  0.999639  0.998804   \n",
       "WeirdML                                 0.998808  0.998466  1.000000   \n",
       "Winogrande                              0.999456  0.999464  0.998966   \n",
       "\n",
       "anchor_benchmark                        Aider polyglot       BBH    Balrog  \\\n",
       "anchor_benchmark                                                             \n",
       "ANLI                                          0.999255  0.999539  0.998757   \n",
       "ARC AI2                                       0.998711  0.999783  0.998466   \n",
       "ARC-AGI                                       0.999496  0.998499  0.999610   \n",
       "Aider polyglot                                1.000000  0.998810  0.999241   \n",
       "BBH                                           0.998810  1.000000  0.998452   \n",
       "Balrog                                        0.999241  0.998452  1.000000   \n",
       "CadEval                                       0.999885  0.998686  0.999347   \n",
       "Cybench                                       0.999044  0.998846  0.999541   \n",
       "DeepResearch Bench                            0.999024  0.998679  0.999756   \n",
       "Factorio learning environment                 0.999199  0.999063  0.999411   \n",
       "Fiction.LiveBench                             1.000000  0.998878  0.999193   \n",
       "FrontierMath-2025-02-28-Private               0.999235  0.998482  1.000000   \n",
       "FrontierMath-Tier-4-2025-07-01-Private        0.999107  0.998940  0.999464   \n",
       "GPQA diamond                                  0.999776  0.999029  0.999105   \n",
       "GSM8K                                         0.999176  1.000000  0.998730   \n",
       "GSO-Bench                                     0.999323  0.999216  0.999385   \n",
       "GeoBench                                      0.999580  0.999203  0.999030   \n",
       "HellaSwag                                     0.999017  0.999331  0.998857   \n",
       "LAMBADA                                       0.999186  0.999303  0.999061   \n",
       "Lech Mazur Writing                            0.999346  0.999644  0.998951   \n",
       "LiveBench                                     0.999885  0.998951  0.999147   \n",
       "MATH level 5                                  0.999674  0.999113  0.999066   \n",
       "MMLU                                          0.998729  0.999885  0.998450   \n",
       "OSUniverse                                    0.999485  0.999405  0.999390   \n",
       "OSWorld                                       0.999675  0.998870  0.999467   \n",
       "OTIS Mock AIME 2024-2025                      1.000000  0.998745  0.999292   \n",
       "OpenBookQA                                    0.998711  0.999696  0.998497   \n",
       "PIQA                                          0.999487  0.999394  0.999384   \n",
       "SWE-Bench verified                            0.999776  0.998820  0.999405   \n",
       "ScienceQA                                     0.999002  0.999758  0.998689   \n",
       "SimpleBench                                   0.999356  0.998448  0.999783   \n",
       "Terminal Bench                                0.999250  0.998531  0.999885   \n",
       "The Agent Company                             0.999581  0.998537  0.999535   \n",
       "TriviaQA                                      0.999318  0.999331  0.999206   \n",
       "VPCT                                          0.999303  0.998437  0.999885   \n",
       "VideoMME                                      0.998973  0.999382  0.998790   \n",
       "WeirdML                                       0.999421  0.998469  0.999692   \n",
       "Winogrande                                    0.999087  0.999304  0.998946   \n",
       "\n",
       "anchor_benchmark                         CadEval   Cybench  \\\n",
       "anchor_benchmark                                             \n",
       "ANLI                                    0.999095  0.999136   \n",
       "ARC AI2                                 0.998623  0.998857   \n",
       "ARC-AGI                                 0.999678  0.999237   \n",
       "Aider polyglot                          0.999885  0.999044   \n",
       "BBH                                     0.998686  0.998846   \n",
       "Balrog                                  0.999347  0.999541   \n",
       "CadEval                                 1.000000  0.999101   \n",
       "Cybench                                 0.999101  1.000000   \n",
       "DeepResearch Bench                      0.999145  0.999706   \n",
       "Factorio learning environment           0.999221  0.999886   \n",
       "Fiction.LiveBench                       0.999776  0.999017   \n",
       "FrontierMath-2025-02-28-Private         0.999325  0.999637   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999146  1.000000   \n",
       "GPQA diamond                            0.999578  0.998964   \n",
       "GSM8K                                   0.999028  0.999117   \n",
       "GSO-Bench                               0.999328  0.999796   \n",
       "GeoBench                                0.999407  0.998915   \n",
       "HellaSwag                               0.998964  0.999225   \n",
       "LAMBADA                                 0.999156  0.999403   \n",
       "Lech Mazur Writing                      0.999210  0.998857   \n",
       "LiveBench                               0.999674  0.998990   \n",
       "MATH level 5                            0.999489  0.998939   \n",
       "MMLU                                    0.998629  0.998844   \n",
       "OSUniverse                              0.999472  0.999734   \n",
       "OSWorld                                 0.999885  0.999374   \n",
       "OTIS Mock AIME 2024-2025                1.000000  0.999072   \n",
       "OpenBookQA                              0.998635  0.998881   \n",
       "PIQA                                    0.999480  0.999689   \n",
       "SWE-Bench verified                      1.000000  0.999407   \n",
       "ScienceQA                               0.998890  0.999086   \n",
       "SimpleBench                             0.999508  0.999331   \n",
       "Terminal Bench                          0.999323  0.999751   \n",
       "The Agent Company                       0.999777  0.999198   \n",
       "TriviaQA                                0.999299  0.999530   \n",
       "VPCT                                    0.999440  0.999390   \n",
       "VideoMME                                0.998909  0.999169   \n",
       "WeirdML                                 0.999588  0.999281   \n",
       "Winogrande                              0.999045  0.999302   \n",
       "\n",
       "anchor_benchmark                        DeepResearch Bench  \\\n",
       "anchor_benchmark                                             \n",
       "ANLI                                              0.998990   \n",
       "ARC AI2                                           0.998694   \n",
       "ARC-AGI                                           0.999447   \n",
       "Aider polyglot                                    0.999024   \n",
       "BBH                                               0.998679   \n",
       "Balrog                                            0.999756   \n",
       "CadEval                                           0.999145   \n",
       "Cybench                                           0.999706   \n",
       "DeepResearch Bench                                1.000000   \n",
       "Factorio learning environment                     0.999614   \n",
       "Fiction.LiveBench                                 0.998969   \n",
       "FrontierMath-2025-02-28-Private                   0.999640   \n",
       "FrontierMath-Tier-4-2025-07-01-Private            0.999647   \n",
       "GPQA diamond                                      0.998869   \n",
       "GSM8K                                             0.998960   \n",
       "GSO-Bench                                         0.999608   \n",
       "GeoBench                                          0.998785   \n",
       "HellaSwag                                         0.999090   \n",
       "LAMBADA                                           0.999302   \n",
       "Lech Mazur Writing                                0.998695   \n",
       "LiveBench                                         0.998918   \n",
       "MATH level 5                                      0.998825   \n",
       "MMLU                                              0.998677   \n",
       "OSUniverse                                        0.999635   \n",
       "OSWorld                                           0.999453   \n",
       "OTIS Mock AIME 2024-2025                          0.999083   \n",
       "OpenBookQA                                        0.998726   \n",
       "PIQA                                              0.999636   \n",
       "SWE-Bench verified                                0.999525   \n",
       "ScienceQA                                         0.998915   \n",
       "SimpleBench                                       0.999643   \n",
       "Terminal Bench                                    0.999540   \n",
       "The Agent Company                                 0.999362   \n",
       "TriviaQA                                          0.999452   \n",
       "VPCT                                              0.999757   \n",
       "VideoMME                                          0.999020   \n",
       "WeirdML                                           0.999540   \n",
       "Winogrande                                        0.999183   \n",
       "\n",
       "anchor_benchmark                        Factorio learning environment  ...  \\\n",
       "anchor_benchmark                                                       ...   \n",
       "ANLI                                                         0.999350  ...   \n",
       "ARC AI2                                                      0.999061  ...   \n",
       "ARC-AGI                                                      0.999266  ...   \n",
       "Aider polyglot                                               0.999199  ...   \n",
       "BBH                                                          0.999063  ...   \n",
       "Balrog                                                       0.999411  ...   \n",
       "CadEval                                                      0.999221  ...   \n",
       "Cybench                                                      0.999886  ...   \n",
       "DeepResearch Bench                                           0.999614  ...   \n",
       "Factorio learning environment                                1.000000  ...   \n",
       "Fiction.LiveBench                                            0.999186  ...   \n",
       "FrontierMath-2025-02-28-Private                              0.999469  ...   \n",
       "FrontierMath-Tier-4-2025-07-01-Private                       1.000000  ...   \n",
       "GPQA diamond                                                 0.999156  ...   \n",
       "GSM8K                                                        0.999334  ...   \n",
       "GSO-Bench                                                    1.000000  ...   \n",
       "GeoBench                                                     0.999122  ...   \n",
       "HellaSwag                                                    0.999403  ...   \n",
       "LAMBADA                                                      0.999550  ...   \n",
       "Lech Mazur Writing                                           0.999074  ...   \n",
       "LiveBench                                                    0.999171  ...   \n",
       "MATH level 5                                                 0.999139  ...   \n",
       "MMLU                                                         0.999054  ...   \n",
       "OSUniverse                                                   0.999886  ...   \n",
       "OSWorld                                                      0.999476  ...   \n",
       "OTIS Mock AIME 2024-2025                                     0.999210  ...   \n",
       "OpenBookQA                                                   0.999078  ...   \n",
       "PIQA                                                         0.999799  ...   \n",
       "SWE-Bench verified                                           0.999487  ...   \n",
       "ScienceQA                                                    0.999303  ...   \n",
       "SimpleBench                                                  0.999303  ...   \n",
       "Terminal Bench                                               0.999542  ...   \n",
       "The Agent Company                                            0.999252  ...   \n",
       "TriviaQA                                                     0.999660  ...   \n",
       "VPCT                                                         0.999330  ...   \n",
       "VideoMME                                                     0.999358  ...   \n",
       "WeirdML                                                      0.999282  ...   \n",
       "Winogrande                                                   0.999466  ...   \n",
       "\n",
       "anchor_benchmark                        SWE-Bench verified  ScienceQA  \\\n",
       "anchor_benchmark                                                        \n",
       "ANLI                                              0.999196   0.999685   \n",
       "ARC AI2                                           0.998789   0.999641   \n",
       "ARC-AGI                                           0.999778   0.998723   \n",
       "Aider polyglot                                    0.999776   0.999002   \n",
       "BBH                                               0.998820   0.999758   \n",
       "Balrog                                            0.999405   0.998689   \n",
       "CadEval                                           1.000000   0.998890   \n",
       "Cybench                                           0.999407   0.999086   \n",
       "DeepResearch Bench                                0.999525   0.998915   \n",
       "Factorio learning environment                     0.999487   0.999303   \n",
       "Fiction.LiveBench                                 0.999674   0.999064   \n",
       "FrontierMath-2025-02-28-Private                   0.999374   0.998721   \n",
       "FrontierMath-Tier-4-2025-07-01-Private            0.999433   0.999181   \n",
       "GPQA diamond                                      0.999489   0.999200   \n",
       "GSM8K                                             0.999141   0.999780   \n",
       "GSO-Bench                                         0.999573   0.999455   \n",
       "GeoBench                                          0.999330   0.999357   \n",
       "HellaSwag                                         0.999158   0.999636   \n",
       "LAMBADA                                           0.999367   0.999578   \n",
       "Lech Mazur Writing                                0.999150   0.999644   \n",
       "LiveBench                                         0.999578   0.999130   \n",
       "MATH level 5                                      0.999406   0.999276   \n",
       "MMLU                                              0.998785   0.999757   \n",
       "OSUniverse                                        0.999696   0.999643   \n",
       "OSWorld                                           1.000000   0.999080   \n",
       "OTIS Mock AIME 2024-2025                          0.999885   0.998944   \n",
       "OpenBookQA                                        0.998810   0.999540   \n",
       "PIQA                                              0.999708   0.999636   \n",
       "SWE-Bench verified                                1.000000   0.999036   \n",
       "ScienceQA                                         0.999036   1.000000   \n",
       "SimpleBench                                       0.999592   0.998678   \n",
       "Terminal Bench                                    0.999363   0.998771   \n",
       "The Agent Company                                 0.999885   0.998756   \n",
       "TriviaQA                                          0.999519   0.999590   \n",
       "VPCT                                              0.999516   0.998670   \n",
       "VideoMME                                          0.999094   0.999701   \n",
       "WeirdML                                           0.999680   0.998696   \n",
       "Winogrande                                        0.999248   0.999594   \n",
       "\n",
       "anchor_benchmark                        SimpleBench  Terminal Bench  \\\n",
       "anchor_benchmark                                                      \n",
       "ANLI                                       0.998777        0.998826   \n",
       "ARC AI2                                    0.998452        0.998544   \n",
       "ARC-AGI                                    0.999885        0.999504   \n",
       "Aider polyglot                             0.999356        0.999250   \n",
       "BBH                                        0.998448        0.998531   \n",
       "Balrog                                     0.999783        0.999885   \n",
       "CadEval                                    0.999508        0.999323   \n",
       "Cybench                                    0.999331        0.999751   \n",
       "DeepResearch Bench                         0.999643        0.999540   \n",
       "Factorio learning environment              0.999303        0.999542   \n",
       "Fiction.LiveBench                          0.999287        0.999216   \n",
       "FrontierMath-2025-02-28-Private            0.999696        1.000000   \n",
       "FrontierMath-Tier-4-2025-07-01-Private     0.999304        0.999636   \n",
       "GPQA diamond                               0.999164        0.999151   \n",
       "GSM8K                                      0.998739        0.998804   \n",
       "GSO-Bench                                  0.999331        0.999474   \n",
       "GeoBench                                   0.999060        0.999094   \n",
       "HellaSwag                                  0.998846        0.998920   \n",
       "LAMBADA                                    0.999063        0.999107   \n",
       "Lech Mazur Writing                         0.998950        0.999030   \n",
       "LiveBench                                  0.999223        0.999183   \n",
       "MATH level 5                               0.999109        0.999121   \n",
       "MMLU                                       0.998438        0.998530   \n",
       "OSUniverse                                 0.999394        0.999435   \n",
       "OSWorld                                    0.999682        0.999406   \n",
       "OTIS Mock AIME 2024-2025                   0.999430        0.999286   \n",
       "OpenBookQA                                 0.998482        0.998571   \n",
       "PIQA                                       0.999405        0.999406   \n",
       "SWE-Bench verified                         0.999592        0.999363   \n",
       "ScienceQA                                  0.998678        0.998771   \n",
       "SimpleBench                                1.000000        0.999626   \n",
       "Terminal Bench                             0.999626        1.000000   \n",
       "The Agent Company                          0.999779        0.999452   \n",
       "TriviaQA                                   0.999216        0.999241   \n",
       "VPCT                                       1.000000        0.999701   \n",
       "VideoMME                                   0.998775        0.998860   \n",
       "WeirdML                                    1.000000        0.999561   \n",
       "Winogrande                                 0.998940        0.999002   \n",
       "\n",
       "anchor_benchmark                        The Agent Company  TriviaQA      VPCT  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                                             0.998900  0.999572  0.998756   \n",
       "ARC AI2                                          0.998515  0.999385  0.998446   \n",
       "ARC-AGI                                          1.000000  0.999243  0.999780   \n",
       "Aider polyglot                                   0.999581  0.999318  0.999303   \n",
       "BBH                                              0.998537  0.999331  0.998437   \n",
       "Balrog                                           0.999535  0.999206  0.999885   \n",
       "CadEval                                          0.999777  0.999299  0.999440   \n",
       "Cybench                                          0.999198  0.999530  0.999390   \n",
       "DeepResearch Bench                               0.999362  0.999452  0.999757   \n",
       "Factorio learning environment                    0.999252  0.999660  0.999330   \n",
       "Fiction.LiveBench                                0.999493  0.999323  0.999242   \n",
       "FrontierMath-2025-02-28-Private                  0.999484  0.999218  0.999784   \n",
       "FrontierMath-Tier-4-2025-07-01-Private           0.999211  0.999585  0.999347   \n",
       "GPQA diamond                                     0.999332  0.999328  0.999130   \n",
       "GSM8K                                            0.998850  0.999572  0.998723   \n",
       "GSO-Bench                                        0.999325  0.999759  0.999341   \n",
       "GeoBench                                         0.999196  0.999326  0.999036   \n",
       "HellaSwag                                        0.998892  0.999796  0.998841   \n",
       "LAMBADA                                          0.999105  1.000000  0.999055   \n",
       "Lech Mazur Writing                               0.999047  0.999326  0.998937   \n",
       "LiveBench                                        0.999410  0.999327  0.999184   \n",
       "MATH level 5                                     0.999261  0.999328  0.999080   \n",
       "MMLU                                             0.998508  0.999359  0.998430   \n",
       "OSUniverse                                       0.999433  0.999886  0.999386   \n",
       "OSWorld                                          1.000000  0.999533  0.999597   \n",
       "OTIS Mock AIME 2024-2025                         0.999676  0.999310  0.999369   \n",
       "OpenBookQA                                       0.998539  0.999422  0.998477   \n",
       "PIQA                                             0.999448  1.000000  0.999394   \n",
       "SWE-Bench verified                               0.999885  0.999519  0.999516   \n",
       "ScienceQA                                        0.998756  0.999590  0.998670   \n",
       "SimpleBench                                      0.999779  0.999216  1.000000   \n",
       "Terminal Bench                                   0.999452  0.999241  0.999701   \n",
       "The Agent Company                                1.000000  0.999258  0.999685   \n",
       "TriviaQA                                         0.999258  1.000000  0.999207   \n",
       "VPCT                                             0.999685  0.999207  1.000000   \n",
       "VideoMME                                         0.998826  0.999726  0.998771   \n",
       "WeirdML                                          0.999885  0.999228  0.999885   \n",
       "Winogrande                                       0.998984  0.999886  0.998935   \n",
       "\n",
       "anchor_benchmark                        VideoMME   WeirdML  Winogrande  \n",
       "anchor_benchmark                                                        \n",
       "ANLI                                    0.999452  0.998808    0.999456  \n",
       "ARC AI2                                 0.999639  0.998466    0.999464  \n",
       "ARC-AGI                                 0.998804  1.000000    0.998966  \n",
       "Aider polyglot                          0.998973  0.999421    0.999087  \n",
       "BBH                                     0.999382  0.998469    0.999304  \n",
       "Balrog                                  0.998790  0.999692    0.998946  \n",
       "CadEval                                 0.998909  0.999588    0.999045  \n",
       "Cybench                                 0.999169  0.999281    0.999302  \n",
       "DeepResearch Bench                      0.999020  0.999540    0.999183  \n",
       "Factorio learning environment           0.999358  0.999282    0.999466  \n",
       "Fiction.LiveBench                       0.999008  0.999346    0.999107  \n",
       "FrontierMath-2025-02-28-Private         0.998817  0.999618    0.998967  \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999251  0.999268    0.999373  \n",
       "GPQA diamond                            0.999081  0.999210    0.999146  \n",
       "GSM8K                                   0.999504  0.998767    0.999483  \n",
       "GSO-Bench                               0.999492  0.999326    0.999585  \n",
       "GeoBench                                0.999163  0.999095    0.999188  \n",
       "HellaSwag                               1.000000  0.998857    1.000000  \n",
       "LAMBADA                                 0.999793  0.999074    1.000000  \n",
       "Lech Mazur Writing                      0.999317  0.998974    0.999268  \n",
       "LiveBench                               0.999043  0.999275    0.999127  \n",
       "MATH level 5                            0.999121  0.999150    0.999167  \n",
       "MMLU                                    0.999540  0.998454    0.999400  \n",
       "OSUniverse                              0.999659  0.999405    0.999734  \n",
       "OSWorld                                 0.999121  0.999778    0.999269  \n",
       "OTIS Mock AIME 2024-2025                0.998940  0.999502    0.999066  \n",
       "OpenBookQA                              0.999753  0.998495    0.999541  \n",
       "PIQA                                    0.999689  0.999419    0.999799  \n",
       "SWE-Bench verified                      0.999094  0.999680    0.999248  \n",
       "ScienceQA                               0.999701  0.998696    0.999594  \n",
       "SimpleBench                             0.998775  1.000000    0.998940  \n",
       "Terminal Bench                          0.998860  0.999561    0.999002  \n",
       "The Agent Company                       0.998826  0.999885    0.998984  \n",
       "TriviaQA                                0.999726  0.999228    0.999886  \n",
       "VPCT                                    0.998771  0.999885    0.998935  \n",
       "VideoMME                                1.000000  0.998787    0.999885  \n",
       "WeirdML                                 0.998787  1.000000    0.998951  \n",
       "Winogrande                              0.999885  0.998951    1.000000  \n",
       "\n",
       "[38 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per fit (difficulties):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>0.999576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>0.999328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>0.999324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>0.999321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>0.999316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.999296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>0.999281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.999277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.999266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.999265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>0.999238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.999235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.999234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.999223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.999218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.999213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mean_rho\n",
       "anchor_benchmark                                \n",
       "PIQA                                    0.999576\n",
       "OSUniverse                              0.999576\n",
       "TriviaQA                                0.999467\n",
       "GSO-Bench                               0.999467\n",
       "OSWorld                                 0.999428\n",
       "SWE-Bench verified                      0.999424\n",
       "LAMBADA                                 0.999383\n",
       "Factorio learning environment           0.999383\n",
       "Aider polyglot                          0.999328\n",
       "Fiction.LiveBench                       0.999328\n",
       "OTIS Mock AIME 2024-2025                0.999324\n",
       "LiveBench                               0.999324\n",
       "Winogrande                              0.999321\n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999321\n",
       "CadEval                                 0.999317\n",
       "GPQA diamond                            0.999317\n",
       "GSM8K                                   0.999316\n",
       "MATH level 5                            0.999307\n",
       "ANLI                                    0.999296\n",
       "GeoBench                                0.999295\n",
       "The Agent Company                       0.999281\n",
       "HellaSwag                               0.999277\n",
       "Cybench                                 0.999277\n",
       "Lech Mazur Writing                      0.999266\n",
       "ARC-AGI                                 0.999265\n",
       "WeirdML                                 0.999250\n",
       "VideoMME                                0.999249\n",
       "ScienceQA                               0.999238\n",
       "SimpleBench                             0.999235\n",
       "Terminal Bench                          0.999234\n",
       "DeepResearch Bench                      0.999230\n",
       "VPCT                                    0.999223\n",
       "FrontierMath-2025-02-28-Private         0.999218\n",
       "Balrog                                  0.999213\n",
       "BBH                                     0.999067\n",
       "OpenBookQA                              0.999048\n",
       "MMLU                                    0.999046\n",
       "ARC AI2                                 0.999043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spearman rank correlation across fits (model capabilities) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th>ANLI</th>\n",
       "      <th>ARC AI2</th>\n",
       "      <th>ARC-AGI</th>\n",
       "      <th>Aider polyglot</th>\n",
       "      <th>BBH</th>\n",
       "      <th>Balrog</th>\n",
       "      <th>CadEval</th>\n",
       "      <th>Cybench</th>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <th>...</th>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <th>ScienceQA</th>\n",
       "      <th>SimpleBench</th>\n",
       "      <th>Terminal Bench</th>\n",
       "      <th>The Agent Company</th>\n",
       "      <th>TriviaQA</th>\n",
       "      <th>VPCT</th>\n",
       "      <th>VideoMME</th>\n",
       "      <th>WeirdML</th>\n",
       "      <th>Winogrande</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor_benchmark                            ANLI   ARC AI2   ARC-AGI  \\\n",
       "anchor_benchmark                                                       \n",
       "ANLI                                    1.000000  0.999977  0.999987   \n",
       "ARC AI2                                 0.999977  1.000000  0.999983   \n",
       "ARC-AGI                                 0.999987  0.999983  1.000000   \n",
       "Aider polyglot                          0.999977  0.999974  0.999983   \n",
       "BBH                                     0.999981  0.999989  0.999987   \n",
       "Balrog                                  0.999998  0.999979  0.999989   \n",
       "CadEval                                 0.999991  0.999985  0.999991   \n",
       "Cybench                                 1.000000  0.999977  0.999987   \n",
       "DeepResearch Bench                      0.999996  0.999981  0.999994   \n",
       "Factorio learning environment           1.000000  0.999977  0.999987   \n",
       "Fiction.LiveBench                       0.999983  0.999977  0.999989   \n",
       "FrontierMath-2025-02-28-Private         0.999985  0.999981  0.999998   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999998  0.999979  0.999989   \n",
       "GPQA diamond                            0.999991  0.999977  0.999983   \n",
       "GSM8K                                   0.999979  0.999998  0.999985   \n",
       "GSO-Bench                               1.000000  0.999977  0.999987   \n",
       "GeoBench                                0.999989  0.999974  0.999981   \n",
       "HellaSwag                               0.999979  0.999991  0.999985   \n",
       "LAMBADA                                 0.999996  0.999972  0.999983   \n",
       "Lech Mazur Writing                      0.999998  0.999979  0.999989   \n",
       "LiveBench                               0.999996  0.999981  0.999991   \n",
       "MATH level 5                            0.999983  0.999979  0.999974   \n",
       "MMLU                                    0.999979  0.999994  0.999985   \n",
       "OSUniverse                              0.999998  0.999979  0.999985   \n",
       "OSWorld                                 0.999996  0.999977  0.999983   \n",
       "OTIS Mock AIME 2024-2025                0.999991  0.999977  0.999983   \n",
       "OpenBookQA                              0.999979  0.999991  0.999985   \n",
       "PIQA                                    0.999991  0.999985  0.999991   \n",
       "SWE-Bench verified                      0.999994  0.999979  0.999989   \n",
       "ScienceQA                               0.999987  0.999989  0.999987   \n",
       "SimpleBench                             0.999987  0.999972  0.999983   \n",
       "Terminal Bench                          0.999989  0.999974  0.999985   \n",
       "The Agent Company                       0.999991  0.999972  0.999983   \n",
       "TriviaQA                                0.999991  0.999985  0.999991   \n",
       "VPCT                                    0.999991  0.999970  0.999979   \n",
       "VideoMME                                1.000000  0.999977  0.999987   \n",
       "WeirdML                                 0.999991  0.999981  0.999987   \n",
       "Winogrande                              0.999979  0.999998  0.999985   \n",
       "\n",
       "anchor_benchmark                        Aider polyglot       BBH    Balrog  \\\n",
       "anchor_benchmark                                                             \n",
       "ANLI                                          0.999977  0.999981  0.999998   \n",
       "ARC AI2                                       0.999974  0.999989  0.999979   \n",
       "ARC-AGI                                       0.999983  0.999987  0.999989   \n",
       "Aider polyglot                                1.000000  0.999979  0.999979   \n",
       "BBH                                           0.999979  1.000000  0.999983   \n",
       "Balrog                                        0.999979  0.999983  1.000000   \n",
       "CadEval                                       0.999981  0.999985  0.999994   \n",
       "Cybench                                       0.999977  0.999981  0.999998   \n",
       "DeepResearch Bench                            0.999981  0.999985  0.999994   \n",
       "Factorio learning environment                 0.999977  0.999981  0.999998   \n",
       "Fiction.LiveBench                             0.999977  0.999981  0.999985   \n",
       "FrontierMath-2025-02-28-Private               0.999985  0.999985  0.999987   \n",
       "FrontierMath-Tier-4-2025-07-01-Private        0.999979  0.999983  0.999996   \n",
       "GPQA diamond                                  0.999977  0.999987  0.999994   \n",
       "GSM8K                                         0.999977  0.999991  0.999981   \n",
       "GSO-Bench                                     0.999977  0.999981  0.999998   \n",
       "GeoBench                                      0.999970  0.999979  0.999987   \n",
       "HellaSwag                                     0.999977  0.999985  0.999981   \n",
       "LAMBADA                                       0.999972  0.999977  0.999994   \n",
       "Lech Mazur Writing                            0.999979  0.999983  0.999996   \n",
       "LiveBench                                     0.999981  0.999985  0.999998   \n",
       "MATH level 5                                  0.999968  0.999985  0.999985   \n",
       "MMLU                                          0.999977  0.999998  0.999981   \n",
       "OSUniverse                                    0.999974  0.999983  0.999996   \n",
       "OSWorld                                       0.999972  0.999981  0.999994   \n",
       "OTIS Mock AIME 2024-2025                      0.999977  0.999981  0.999994   \n",
       "OpenBookQA                                    0.999977  0.999998  0.999981   \n",
       "PIQA                                          0.999981  0.999989  0.999994   \n",
       "SWE-Bench verified                            0.999979  0.999983  0.999991   \n",
       "ScienceQA                                     0.999981  0.999989  0.999989   \n",
       "SimpleBench                                   0.999987  0.999977  0.999989   \n",
       "Terminal Bench                                0.999981  0.999979  0.999987   \n",
       "The Agent Company                             0.999972  0.999977  0.999989   \n",
       "TriviaQA                                      0.999981  0.999989  0.999994   \n",
       "VPCT                                          0.999968  0.999974  0.999994   \n",
       "VideoMME                                      0.999977  0.999981  0.999998   \n",
       "WeirdML                                       0.999985  0.999985  0.999994   \n",
       "Winogrande                                    0.999977  0.999991  0.999981   \n",
       "\n",
       "anchor_benchmark                         CadEval   Cybench  \\\n",
       "anchor_benchmark                                             \n",
       "ANLI                                    0.999991  1.000000   \n",
       "ARC AI2                                 0.999985  0.999977   \n",
       "ARC-AGI                                 0.999991  0.999987   \n",
       "Aider polyglot                          0.999981  0.999977   \n",
       "BBH                                     0.999985  0.999981   \n",
       "Balrog                                  0.999994  0.999998   \n",
       "CadEval                                 1.000000  0.999991   \n",
       "Cybench                                 0.999991  1.000000   \n",
       "DeepResearch Bench                      0.999991  0.999996   \n",
       "Factorio learning environment           0.999991  1.000000   \n",
       "Fiction.LiveBench                       0.999987  0.999983   \n",
       "FrontierMath-2025-02-28-Private         0.999989  0.999985   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999994  0.999998   \n",
       "GPQA diamond                            0.999987  0.999991   \n",
       "GSM8K                                   0.999987  0.999979   \n",
       "GSO-Bench                               0.999991  1.000000   \n",
       "GeoBench                                0.999985  0.999989   \n",
       "HellaSwag                               0.999983  0.999979   \n",
       "LAMBADA                                 0.999987  0.999996   \n",
       "Lech Mazur Writing                      0.999994  0.999998   \n",
       "LiveBench                               0.999996  0.999996   \n",
       "MATH level 5                            0.999983  0.999983   \n",
       "MMLU                                    0.999983  0.999979   \n",
       "OSUniverse                              0.999989  0.999998   \n",
       "OSWorld                                 0.999987  0.999996   \n",
       "OTIS Mock AIME 2024-2025                0.999987  0.999991   \n",
       "OpenBookQA                              0.999987  0.999979   \n",
       "PIQA                                    0.999996  0.999991   \n",
       "SWE-Bench verified                      0.999994  0.999994   \n",
       "ScienceQA                               0.999996  0.999987   \n",
       "SimpleBench                             0.999987  0.999987   \n",
       "Terminal Bench                          0.999989  0.999989   \n",
       "The Agent Company                       0.999987  0.999991   \n",
       "TriviaQA                                0.999996  0.999991   \n",
       "VPCT                                    0.999987  0.999991   \n",
       "VideoMME                                0.999991  1.000000   \n",
       "WeirdML                                 0.999991  0.999991   \n",
       "Winogrande                              0.999987  0.999979   \n",
       "\n",
       "anchor_benchmark                        DeepResearch Bench  \\\n",
       "anchor_benchmark                                             \n",
       "ANLI                                              0.999996   \n",
       "ARC AI2                                           0.999981   \n",
       "ARC-AGI                                           0.999994   \n",
       "Aider polyglot                                    0.999981   \n",
       "BBH                                               0.999985   \n",
       "Balrog                                            0.999994   \n",
       "CadEval                                           0.999991   \n",
       "Cybench                                           0.999996   \n",
       "DeepResearch Bench                                1.000000   \n",
       "Factorio learning environment                     0.999996   \n",
       "Fiction.LiveBench                                 0.999987   \n",
       "FrontierMath-2025-02-28-Private                   0.999991   \n",
       "FrontierMath-Tier-4-2025-07-01-Private            0.999998   \n",
       "GPQA diamond                                      0.999987   \n",
       "GSM8K                                             0.999983   \n",
       "GSO-Bench                                         0.999996   \n",
       "GeoBench                                          0.999989   \n",
       "HellaSwag                                         0.999983   \n",
       "LAMBADA                                           0.999991   \n",
       "Lech Mazur Writing                                0.999994   \n",
       "LiveBench                                         0.999991   \n",
       "MATH level 5                                      0.999979   \n",
       "MMLU                                              0.999983   \n",
       "OSUniverse                                        0.999994   \n",
       "OSWorld                                           0.999991   \n",
       "OTIS Mock AIME 2024-2025                          0.999987   \n",
       "OpenBookQA                                        0.999983   \n",
       "PIQA                                              0.999991   \n",
       "SWE-Bench verified                                0.999994   \n",
       "ScienceQA                                         0.999987   \n",
       "SimpleBench                                       0.999983   \n",
       "Terminal Bench                                    0.999989   \n",
       "The Agent Company                                 0.999991   \n",
       "TriviaQA                                          0.999991   \n",
       "VPCT                                              0.999985   \n",
       "VideoMME                                          0.999996   \n",
       "WeirdML                                           0.999987   \n",
       "Winogrande                                        0.999983   \n",
       "\n",
       "anchor_benchmark                        Factorio learning environment  ...  \\\n",
       "anchor_benchmark                                                       ...   \n",
       "ANLI                                                         1.000000  ...   \n",
       "ARC AI2                                                      0.999977  ...   \n",
       "ARC-AGI                                                      0.999987  ...   \n",
       "Aider polyglot                                               0.999977  ...   \n",
       "BBH                                                          0.999981  ...   \n",
       "Balrog                                                       0.999998  ...   \n",
       "CadEval                                                      0.999991  ...   \n",
       "Cybench                                                      1.000000  ...   \n",
       "DeepResearch Bench                                           0.999996  ...   \n",
       "Factorio learning environment                                1.000000  ...   \n",
       "Fiction.LiveBench                                            0.999983  ...   \n",
       "FrontierMath-2025-02-28-Private                              0.999985  ...   \n",
       "FrontierMath-Tier-4-2025-07-01-Private                       0.999998  ...   \n",
       "GPQA diamond                                                 0.999991  ...   \n",
       "GSM8K                                                        0.999979  ...   \n",
       "GSO-Bench                                                    1.000000  ...   \n",
       "GeoBench                                                     0.999989  ...   \n",
       "HellaSwag                                                    0.999979  ...   \n",
       "LAMBADA                                                      0.999996  ...   \n",
       "Lech Mazur Writing                                           0.999998  ...   \n",
       "LiveBench                                                    0.999996  ...   \n",
       "MATH level 5                                                 0.999983  ...   \n",
       "MMLU                                                         0.999979  ...   \n",
       "OSUniverse                                                   0.999998  ...   \n",
       "OSWorld                                                      0.999996  ...   \n",
       "OTIS Mock AIME 2024-2025                                     0.999991  ...   \n",
       "OpenBookQA                                                   0.999979  ...   \n",
       "PIQA                                                         0.999991  ...   \n",
       "SWE-Bench verified                                           0.999994  ...   \n",
       "ScienceQA                                                    0.999987  ...   \n",
       "SimpleBench                                                  0.999987  ...   \n",
       "Terminal Bench                                               0.999989  ...   \n",
       "The Agent Company                                            0.999991  ...   \n",
       "TriviaQA                                                     0.999991  ...   \n",
       "VPCT                                                         0.999991  ...   \n",
       "VideoMME                                                     1.000000  ...   \n",
       "WeirdML                                                      0.999991  ...   \n",
       "Winogrande                                                   0.999979  ...   \n",
       "\n",
       "anchor_benchmark                        SWE-Bench verified  ScienceQA  \\\n",
       "anchor_benchmark                                                        \n",
       "ANLI                                              0.999994   0.999987   \n",
       "ARC AI2                                           0.999979   0.999989   \n",
       "ARC-AGI                                           0.999989   0.999987   \n",
       "Aider polyglot                                    0.999979   0.999981   \n",
       "BBH                                               0.999983   0.999989   \n",
       "Balrog                                            0.999991   0.999989   \n",
       "CadEval                                           0.999994   0.999996   \n",
       "Cybench                                           0.999994   0.999987   \n",
       "DeepResearch Bench                                0.999994   0.999987   \n",
       "Factorio learning environment                     0.999994   0.999987   \n",
       "Fiction.LiveBench                                 0.999985   0.999983   \n",
       "FrontierMath-2025-02-28-Private                   0.999987   0.999985   \n",
       "FrontierMath-Tier-4-2025-07-01-Private            0.999996   0.999989   \n",
       "GPQA diamond                                      0.999985   0.999987   \n",
       "GSM8K                                             0.999981   0.999991   \n",
       "GSO-Bench                                         0.999994   0.999987   \n",
       "GeoBench                                          0.999987   0.999985   \n",
       "HellaSwag                                         0.999981   0.999987   \n",
       "LAMBADA                                           0.999989   0.999983   \n",
       "Lech Mazur Writing                                0.999996   0.999989   \n",
       "LiveBench                                         0.999994   0.999991   \n",
       "MATH level 5                                      0.999977   0.999983   \n",
       "MMLU                                              0.999981   0.999987   \n",
       "OSUniverse                                        0.999991   0.999989   \n",
       "OSWorld                                           0.999989   0.999987   \n",
       "OTIS Mock AIME 2024-2025                          0.999983   0.999987   \n",
       "OpenBookQA                                        0.999981   0.999991   \n",
       "PIQA                                              0.999994   0.999996   \n",
       "SWE-Bench verified                                1.000000   0.999989   \n",
       "ScienceQA                                         0.999989   1.000000   \n",
       "SimpleBench                                       0.999985   0.999983   \n",
       "Terminal Bench                                    0.999996   0.999985   \n",
       "The Agent Company                                 0.999989   0.999983   \n",
       "TriviaQA                                          0.999994   0.999996   \n",
       "VPCT                                              0.999985   0.999983   \n",
       "VideoMME                                          0.999994   0.999987   \n",
       "WeirdML                                           0.999989   0.999991   \n",
       "Winogrande                                        0.999981   0.999991   \n",
       "\n",
       "anchor_benchmark                        SimpleBench  Terminal Bench  \\\n",
       "anchor_benchmark                                                      \n",
       "ANLI                                       0.999987        0.999989   \n",
       "ARC AI2                                    0.999972        0.999974   \n",
       "ARC-AGI                                    0.999983        0.999985   \n",
       "Aider polyglot                             0.999987        0.999981   \n",
       "BBH                                        0.999977        0.999979   \n",
       "Balrog                                     0.999989        0.999987   \n",
       "CadEval                                    0.999987        0.999989   \n",
       "Cybench                                    0.999987        0.999989   \n",
       "DeepResearch Bench                         0.999983        0.999989   \n",
       "Factorio learning environment              0.999987        0.999989   \n",
       "Fiction.LiveBench                          0.999979        0.999985   \n",
       "FrontierMath-2025-02-28-Private            0.999981        0.999983   \n",
       "FrontierMath-Tier-4-2025-07-01-Private     0.999985        0.999991   \n",
       "GPQA diamond                               0.999983        0.999981   \n",
       "GSM8K                                      0.999974        0.999977   \n",
       "GSO-Bench                                  0.999987        0.999989   \n",
       "GeoBench                                   0.999977        0.999983   \n",
       "HellaSwag                                  0.999974        0.999977   \n",
       "LAMBADA                                    0.999983        0.999985   \n",
       "Lech Mazur Writing                         0.999989        0.999991   \n",
       "LiveBench                                  0.999991        0.999989   \n",
       "MATH level 5                               0.999974        0.999972   \n",
       "MMLU                                       0.999974        0.999977   \n",
       "OSUniverse                                 0.999985        0.999987   \n",
       "OSWorld                                    0.999983        0.999985   \n",
       "OTIS Mock AIME 2024-2025                   0.999983        0.999979   \n",
       "OpenBookQA                                 0.999974        0.999977   \n",
       "PIQA                                       0.999987        0.999989   \n",
       "SWE-Bench verified                         0.999985        0.999996   \n",
       "ScienceQA                                  0.999983        0.999985   \n",
       "SimpleBench                                1.000000        0.999985   \n",
       "Terminal Bench                             0.999985        1.000000   \n",
       "The Agent Company                          0.999979        0.999985   \n",
       "TriviaQA                                   0.999987        0.999989   \n",
       "VPCT                                       0.999987        0.999981   \n",
       "VideoMME                                   0.999987        0.999989   \n",
       "WeirdML                                    0.999991        0.999985   \n",
       "Winogrande                                 0.999974        0.999977   \n",
       "\n",
       "anchor_benchmark                        The Agent Company  TriviaQA      VPCT  \\\n",
       "anchor_benchmark                                                                \n",
       "ANLI                                             0.999991  0.999991  0.999991   \n",
       "ARC AI2                                          0.999972  0.999985  0.999970   \n",
       "ARC-AGI                                          0.999983  0.999991  0.999979   \n",
       "Aider polyglot                                   0.999972  0.999981  0.999968   \n",
       "BBH                                              0.999977  0.999989  0.999974   \n",
       "Balrog                                           0.999989  0.999994  0.999994   \n",
       "CadEval                                          0.999987  0.999996  0.999987   \n",
       "Cybench                                          0.999991  0.999991  0.999991   \n",
       "DeepResearch Bench                               0.999991  0.999991  0.999985   \n",
       "Factorio learning environment                    0.999991  0.999991  0.999991   \n",
       "Fiction.LiveBench                                0.999979  0.999987  0.999977   \n",
       "FrontierMath-2025-02-28-Private                  0.999981  0.999989  0.999974   \n",
       "FrontierMath-Tier-4-2025-07-01-Private           0.999994  0.999994  0.999989   \n",
       "GPQA diamond                                     0.999983  0.999987  0.999987   \n",
       "GSM8K                                            0.999974  0.999987  0.999972   \n",
       "GSO-Bench                                        0.999991  0.999991  0.999991   \n",
       "GeoBench                                         0.999985  0.999989  0.999987   \n",
       "HellaSwag                                        0.999974  0.999987  0.999972   \n",
       "LAMBADA                                          0.999987  0.999987  0.999987   \n",
       "Lech Mazur Writing                               0.999989  0.999994  0.999989   \n",
       "LiveBench                                        0.999987  0.999996  0.999991   \n",
       "MATH level 5                                     0.999974  0.999979  0.999979   \n",
       "MMLU                                             0.999974  0.999987  0.999972   \n",
       "OSUniverse                                       0.999989  0.999994  0.999989   \n",
       "OSWorld                                          0.999987  0.999991  0.999987   \n",
       "OTIS Mock AIME 2024-2025                         0.999983  0.999987  0.999987   \n",
       "OpenBookQA                                       0.999974  0.999987  0.999972   \n",
       "PIQA                                             0.999987  1.000000  0.999987   \n",
       "SWE-Bench verified                               0.999989  0.999994  0.999985   \n",
       "ScienceQA                                        0.999983  0.999996  0.999983   \n",
       "SimpleBench                                      0.999979  0.999987  0.999987   \n",
       "Terminal Bench                                   0.999985  0.999989  0.999981   \n",
       "The Agent Company                                1.000000  0.999987  0.999983   \n",
       "TriviaQA                                         0.999987  1.000000  0.999987   \n",
       "VPCT                                             0.999983  0.999987  1.000000   \n",
       "VideoMME                                         0.999991  0.999991  0.999991   \n",
       "WeirdML                                          0.999983  0.999991  0.999987   \n",
       "Winogrande                                       0.999974  0.999987  0.999972   \n",
       "\n",
       "anchor_benchmark                        VideoMME   WeirdML  Winogrande  \n",
       "anchor_benchmark                                                        \n",
       "ANLI                                    1.000000  0.999991    0.999979  \n",
       "ARC AI2                                 0.999977  0.999981    0.999998  \n",
       "ARC-AGI                                 0.999987  0.999987    0.999985  \n",
       "Aider polyglot                          0.999977  0.999985    0.999977  \n",
       "BBH                                     0.999981  0.999985    0.999991  \n",
       "Balrog                                  0.999998  0.999994    0.999981  \n",
       "CadEval                                 0.999991  0.999991    0.999987  \n",
       "Cybench                                 1.000000  0.999991    0.999979  \n",
       "DeepResearch Bench                      0.999996  0.999987    0.999983  \n",
       "Factorio learning environment           1.000000  0.999991    0.999979  \n",
       "Fiction.LiveBench                       0.999983  0.999983    0.999979  \n",
       "FrontierMath-2025-02-28-Private         0.999985  0.999985    0.999983  \n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999998  0.999989    0.999981  \n",
       "GPQA diamond                            0.999991  0.999991    0.999979  \n",
       "GSM8K                                   0.999979  0.999983    1.000000  \n",
       "GSO-Bench                               1.000000  0.999991    0.999979  \n",
       "GeoBench                                0.999989  0.999981    0.999977  \n",
       "HellaSwag                               0.999979  0.999983    0.999989  \n",
       "LAMBADA                                 0.999996  0.999987    0.999974  \n",
       "Lech Mazur Writing                      0.999998  0.999994    0.999981  \n",
       "LiveBench                               0.999996  0.999996    0.999983  \n",
       "MATH level 5                            0.999983  0.999983    0.999981  \n",
       "MMLU                                    0.999979  0.999983    0.999996  \n",
       "OSUniverse                              0.999998  0.999989    0.999981  \n",
       "OSWorld                                 0.999996  0.999987    0.999979  \n",
       "OTIS Mock AIME 2024-2025                0.999991  0.999991    0.999979  \n",
       "OpenBookQA                              0.999979  0.999983    0.999994  \n",
       "PIQA                                    0.999991  0.999991    0.999987  \n",
       "SWE-Bench verified                      0.999994  0.999989    0.999981  \n",
       "ScienceQA                               0.999987  0.999991    0.999991  \n",
       "SimpleBench                             0.999987  0.999991    0.999974  \n",
       "Terminal Bench                          0.999989  0.999985    0.999977  \n",
       "The Agent Company                       0.999991  0.999983    0.999974  \n",
       "TriviaQA                                0.999991  0.999991    0.999987  \n",
       "VPCT                                    0.999991  0.999987    0.999972  \n",
       "VideoMME                                1.000000  0.999991    0.999979  \n",
       "WeirdML                                 0.999991  1.000000    0.999983  \n",
       "Winogrande                              0.999979  0.999983    1.000000  \n",
       "\n",
       "[38 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per fit (capabilities):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor_benchmark</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mean_rho\n",
       "anchor_benchmark                                \n",
       "LiveBench                               0.999990\n",
       "Balrog                                  0.999990\n",
       "Lech Mazur Writing                      0.999990\n",
       "FrontierMath-Tier-4-2025-07-01-Private  0.999990\n",
       "TriviaQA                                0.999990\n",
       "PIQA                                    0.999990\n",
       "Factorio learning environment           0.999990\n",
       "VideoMME                                0.999990\n",
       "GSO-Bench                               0.999990\n",
       "ANLI                                    0.999990\n",
       "Cybench                                 0.999990\n",
       "CadEval                                 0.999989\n",
       "DeepResearch Bench                      0.999989\n",
       "OSUniverse                              0.999989\n",
       "SWE-Bench verified                      0.999988\n",
       "WeirdML                                 0.999988\n",
       "ScienceQA                               0.999988\n",
       "OSWorld                                 0.999987\n",
       "ARC-AGI                                 0.999986\n",
       "GPQA diamond                            0.999986\n",
       "LAMBADA                                 0.999986\n",
       "OTIS Mock AIME 2024-2025                0.999985\n",
       "Terminal Bench                          0.999984\n",
       "FrontierMath-2025-02-28-Private         0.999984\n",
       "BBH                                     0.999984\n",
       "The Agent Company                       0.999984\n",
       "VPCT                                    0.999983\n",
       "GeoBench                                0.999983\n",
       "SimpleBench                             0.999983\n",
       "Winogrande                              0.999983\n",
       "OpenBookQA                              0.999983\n",
       "GSM8K                                   0.999983\n",
       "MMLU                                    0.999983\n",
       "Fiction.LiveBench                       0.999982\n",
       "HellaSwag                               0.999981\n",
       "ARC AI2                                 0.999981\n",
       "MATH level 5                            0.999980\n",
       "Aider polyglot                          0.999978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 4)  Rank correlation across fits (Spearman) for difficulties and capabilities\n",
    "#     Robust to duplicates and missing values\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _spearman_corr_from_long(\n",
    "    df_long: pd.DataFrame, index_col: str, columns_col: str, values_col: str\n",
    ") -> pd.DataFrame:\n",
    "    # Allow duplicates by aggregating with mean; coerce to numeric in case of stray dtypes\n",
    "    wide = df_long.pivot_table(\n",
    "        index=index_col,\n",
    "        columns=columns_col,\n",
    "        values=values_col,\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    wide = wide.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # Drop rows that are entirely NaN\n",
    "    wide = wide.dropna(axis=0, how=\"all\")\n",
    "\n",
    "    # Need at least two fits (columns) to compute a correlation matrix\n",
    "    if wide.shape[1] < 2:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Compute Spearman by ranking then applying Pearson correlation\n",
    "    ranks = wide.rank(axis=0, method=\"average\", na_option=\"keep\")\n",
    "    corr = ranks.corr(method=\"pearson\", min_periods=2)\n",
    "    return corr\n",
    "\n",
    "\n",
    "print(\"=== Spearman rank correlation across fits (benchmark difficulties) ===\")\n",
    "spearman_difficulty = _spearman_corr_from_long(\n",
    "    difficulty_long,\n",
    "    index_col=\"benchmark_name\",\n",
    "    columns_col=\"anchor_benchmark\",\n",
    "    values_col=\"estimated_difficulty\",\n",
    ")\n",
    "if spearman_difficulty.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for difficulties.\")\n",
    "else:\n",
    "    display(spearman_difficulty)\n",
    "    mean_rho_difficulty = (\n",
    "        spearman_difficulty.apply(lambda s: s.drop(labels=s.name).mean(), axis=0)\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame(\"mean_rho\")\n",
    "    )\n",
    "    print(\"\\nMean off-diagonal Spearman per fit (difficulties):\")\n",
    "    display(mean_rho_difficulty)\n",
    "\n",
    "print(\"\\n=== Spearman rank correlation across fits (model capabilities) ===\")\n",
    "spearman_capability = _spearman_corr_from_long(\n",
    "    capability_long,\n",
    "    index_col=\"model\",\n",
    "    columns_col=\"anchor_benchmark\",\n",
    "    values_col=\"estimated_capability\",\n",
    ")\n",
    "if spearman_capability.empty:\n",
    "    print(\"Not enough comparable fits to compute correlations for capabilities.\")\n",
    "else:\n",
    "    display(spearman_capability)\n",
    "    mean_rho_capability = (\n",
    "        spearman_capability.apply(lambda s: s.drop(labels=s.name).mean(), axis=0)\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame(\"mean_rho\")\n",
    "    )\n",
    "    print(\"\\nMean off-diagonal Spearman per fit (capabilities):\")\n",
    "    display(mean_rho_capability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bf280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7049e+01, final cost 3.4689e+00, first-order optimality 3.10e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7572e+01, final cost 3.4695e+00, first-order optimality 1.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 4.7394e+01, final cost 3.4705e+00, first-order optimality 2.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.6950e+01, final cost 3.4713e+00, first-order optimality 2.46e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 24, initial cost 4.7328e+01, final cost 3.4737e+00, first-order optimality 9.30e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8106e+01, final cost 3.4742e+00, first-order optimality 1.55e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7865e+01, final cost 3.4736e+00, first-order optimality 6.82e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7650e+01, final cost 3.4739e+00, first-order optimality 3.65e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.7981e+01, final cost 3.4747e+00, first-order optimality 4.48e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7046e+01, final cost 3.4745e+00, first-order optimality 8.67e-05.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7746e+01, final cost 3.4751e+00, first-order optimality 4.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8175e+01, final cost 3.4756e+00, first-order optimality 2.81e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.7785e+01, final cost 3.4768e+00, first-order optimality 2.48e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7780e+01, final cost 3.4775e+00, first-order optimality 1.90e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7934e+01, final cost 3.4782e+00, first-order optimality 2.07e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8026e+01, final cost 3.4787e+00, first-order optimality 3.53e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7707e+01, final cost 3.4795e+00, first-order optimality 2.18e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7245e+01, final cost 3.4804e+00, first-order optimality 3.27e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7135e+01, final cost 3.4810e+00, first-order optimality 4.37e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.6784e+01, final cost 3.4811e+00, first-order optimality 3.45e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.6583e+01, final cost 3.4809e+00, first-order optimality 4.25e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8046e+01, final cost 3.4819e+00, first-order optimality 2.64e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8143e+01, final cost 3.4818e+00, first-order optimality 2.04e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7469e+01, final cost 3.4812e+00, first-order optimality 4.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7311e+01, final cost 3.4819e+00, first-order optimality 4.62e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7300e+01, final cost 3.4823e+00, first-order optimality 1.96e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6942e+01, final cost 3.4826e+00, first-order optimality 4.32e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7189e+01, final cost 3.4825e+00, first-order optimality 5.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7689e+01, final cost 3.4824e+00, first-order optimality 3.82e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7725e+01, final cost 3.4831e+00, first-order optimality 3.27e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7597e+01, final cost 3.4831e+00, first-order optimality 2.53e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7299e+01, final cost 3.4827e+00, first-order optimality 2.91e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7589e+01, final cost 3.4838e+00, first-order optimality 3.47e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7493e+01, final cost 3.4844e+00, first-order optimality 1.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7283e+01, final cost 3.4843e+00, first-order optimality 8.99e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7257e+01, final cost 3.4848e+00, first-order optimality 1.15e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.7395e+01, final cost 3.4849e+00, first-order optimality 1.69e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 23, initial cost 4.8369e+01, final cost 3.4853e+00, first-order optimality 1.43e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8943e+01, final cost 3.4856e+00, first-order optimality 7.29e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8162e+01, final cost 3.4854e+00, first-order optimality 4.61e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.7746e+01, final cost 3.4859e+00, first-order optimality 3.89e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7932e+01, final cost 3.4861e+00, first-order optimality 5.30e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8127e+01, final cost 3.4861e+00, first-order optimality 5.69e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.8400e+01, final cost 3.4862e+00, first-order optimality 6.82e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7882e+01, final cost 3.4853e+00, first-order optimality 4.75e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.7356e+01, final cost 3.4867e+00, first-order optimality 4.61e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7646e+01, final cost 3.4872e+00, first-order optimality 3.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.7174e+01, final cost 3.4872e+00, first-order optimality 4.77e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8423e+01, final cost 3.4879e+00, first-order optimality 5.66e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8591e+01, final cost 3.4880e+00, first-order optimality 7.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8282e+01, final cost 3.4884e+00, first-order optimality 1.37e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.8950e+01, final cost 3.4887e+00, first-order optimality 4.72e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.9427e+01, final cost 3.4888e+00, first-order optimality 9.34e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8936e+01, final cost 3.4888e+00, first-order optimality 3.20e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.7518e+01, final cost 3.4890e+00, first-order optimality 3.95e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8476e+01, final cost 3.4894e+00, first-order optimality 2.95e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.8428e+01, final cost 3.4895e+00, first-order optimality 3.67e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.8001e+01, final cost 3.4894e+00, first-order optimality 1.57e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7549e+01, final cost 3.4895e+00, first-order optimality 4.03e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.8132e+01, final cost 3.4907e+00, first-order optimality 1.32e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.8988e+01, final cost 3.4910e+00, first-order optimality 5.24e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 25, initial cost 4.8193e+01, final cost 3.4908e+00, first-order optimality 5.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.9131e+01, final cost 3.4913e+00, first-order optimality 4.30e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.9200e+01, final cost 3.4917e+00, first-order optimality 3.29e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7674e+01, final cost 3.4922e+00, first-order optimality 5.26e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7437e+01, final cost 3.4925e+00, first-order optimality 4.23e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6574e+01, final cost 3.4919e+00, first-order optimality 5.30e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 4.7328e+01, final cost 3.4925e+00, first-order optimality 4.87e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 4.8454e+01, final cost 3.4941e+00, first-order optimality 1.87e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7120e+01, final cost 3.4941e+00, first-order optimality 4.54e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7613e+01, final cost 3.4940e+00, first-order optimality 4.37e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.8727e+01, final cost 3.4947e+00, first-order optimality 1.41e-03.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.8593e+01, final cost 3.4948e+00, first-order optimality 6.47e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7879e+01, final cost 3.4933e+00, first-order optimality 8.64e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7783e+01, final cost 3.4938e+00, first-order optimality 2.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8076e+01, final cost 3.4948e+00, first-order optimality 3.68e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.9060e+01, final cost 3.4947e+00, first-order optimality 5.49e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.8831e+01, final cost 3.4948e+00, first-order optimality 1.94e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8081e+01, final cost 3.4954e+00, first-order optimality 6.68e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.9543e+01, final cost 3.4956e+00, first-order optimality 2.16e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.9138e+01, final cost 3.4957e+00, first-order optimality 7.20e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7963e+01, final cost 3.4958e+00, first-order optimality 6.81e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8367e+01, final cost 3.4960e+00, first-order optimality 8.10e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.8837e+01, final cost 3.4963e+00, first-order optimality 4.96e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7209e+01, final cost 3.4955e+00, first-order optimality 6.19e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7055e+01, final cost 3.4902e+00, first-order optimality 5.25e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7773e+01, final cost 3.4953e+00, first-order optimality 1.52e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7922e+01, final cost 3.4963e+00, first-order optimality 2.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 4.8501e+01, final cost 3.4964e+00, first-order optimality 3.25e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.8235e+01, final cost 3.4965e+00, first-order optimality 4.38e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 4.7744e+01, final cost 3.4965e+00, first-order optimality 1.92e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7657e+01, final cost 3.4966e+00, first-order optimality 2.96e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.6922e+01, final cost 3.4954e+00, first-order optimality 2.73e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7574e+01, final cost 3.4962e+00, first-order optimality 5.27e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.8754e+01, final cost 3.4964e+00, first-order optimality 3.61e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7942e+01, final cost 3.4960e+00, first-order optimality 5.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7516e+01, final cost 3.4969e+00, first-order optimality 3.73e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7750e+01, final cost 3.4970e+00, first-order optimality 6.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7889e+01, final cost 3.4961e+00, first-order optimality 5.91e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7179e+01, final cost 3.4927e+00, first-order optimality 2.69e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7197e+01, final cost 3.4964e+00, first-order optimality 6.40e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7425e+01, final cost 3.5072e+00, first-order optimality 8.10e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.7276e+01, final cost 3.5071e+00, first-order optimality 4.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7233e+01, final cost 3.4973e+00, first-order optimality 6.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7576e+01, final cost 3.4971e+00, first-order optimality 5.98e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7674e+01, final cost 3.4968e+00, first-order optimality 2.58e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7223e+01, final cost 3.4956e+00, first-order optimality 6.27e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6794e+01, final cost 3.4958e+00, first-order optimality 6.87e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.6705e+01, final cost 3.4959e+00, first-order optimality 1.11e-03.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6212e+01, final cost 3.4920e+00, first-order optimality 1.65e-03.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 35, initial cost 4.6445e+01, final cost 3.4958e+00, first-order optimality 4.46e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7231e+01, final cost 3.4967e+00, first-order optimality 6.59e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.7668e+01, final cost 3.4966e+00, first-order optimality 5.16e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.7687e+01, final cost 3.4954e+00, first-order optimality 2.24e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.7447e+01, final cost 3.4948e+00, first-order optimality 5.64e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6578e+01, final cost 3.4946e+00, first-order optimality 2.38e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6769e+01, final cost 3.4937e+00, first-order optimality 4.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.7221e+01, final cost 3.4936e+00, first-order optimality 8.76e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6288e+01, final cost 3.4922e+00, first-order optimality 5.41e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6695e+01, final cost 3.4945e+00, first-order optimality 7.40e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.7264e+01, final cost 3.4947e+00, first-order optimality 6.52e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6845e+01, final cost 3.4933e+00, first-order optimality 6.31e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 32, initial cost 4.6694e+01, final cost 3.4933e+00, first-order optimality 4.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 34, initial cost 4.6633e+01, final cost 3.4924e+00, first-order optimality 5.30e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6293e+01, final cost 3.4878e+00, first-order optimality 7.35e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6221e+01, final cost 3.4911e+00, first-order optimality 4.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6331e+01, final cost 3.4905e+00, first-order optimality 8.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6580e+01, final cost 3.4891e+00, first-order optimality 3.50e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6537e+01, final cost 3.4885e+00, first-order optimality 2.86e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6575e+01, final cost 3.4884e+00, first-order optimality 3.13e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6207e+01, final cost 3.4889e+00, first-order optimality 7.07e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6189e+01, final cost 3.4888e+00, first-order optimality 7.24e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6358e+01, final cost 3.4881e+00, first-order optimality 8.58e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.6367e+01, final cost 3.4880e+00, first-order optimality 3.29e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6228e+01, final cost 3.4880e+00, first-order optimality 3.61e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6314e+01, final cost 3.4868e+00, first-order optimality 3.68e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.6342e+01, final cost 3.4851e+00, first-order optimality 6.16e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6421e+01, final cost 3.4854e+00, first-order optimality 6.49e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.6552e+01, final cost 3.4839e+00, first-order optimality 2.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6481e+01, final cost 3.4840e+00, first-order optimality 3.85e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6511e+01, final cost 3.4845e+00, first-order optimality 5.37e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6601e+01, final cost 3.4846e+00, first-order optimality 2.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6589e+01, final cost 3.4844e+00, first-order optimality 4.79e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6631e+01, final cost 3.4841e+00, first-order optimality 5.31e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6564e+01, final cost 3.4834e+00, first-order optimality 4.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6440e+01, final cost 3.4821e+00, first-order optimality 1.05e-03.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.6591e+01, final cost 3.4822e+00, first-order optimality 4.70e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6514e+01, final cost 3.4818e+00, first-order optimality 3.47e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6496e+01, final cost 3.4810e+00, first-order optimality 4.09e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6559e+01, final cost 3.4794e+00, first-order optimality 9.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6679e+01, final cost 3.4792e+00, first-order optimality 6.89e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6765e+01, final cost 3.4782e+00, first-order optimality 8.79e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6804e+01, final cost 3.4761e+00, first-order optimality 5.39e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6763e+01, final cost 3.4752e+00, first-order optimality 6.36e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6602e+01, final cost 3.4746e+00, first-order optimality 4.51e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6696e+01, final cost 3.4745e+00, first-order optimality 4.74e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.6624e+01, final cost 3.4739e+00, first-order optimality 1.88e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6694e+01, final cost 3.4735e+00, first-order optimality 7.11e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6692e+01, final cost 3.4731e+00, first-order optimality 9.58e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6770e+01, final cost 3.4719e+00, first-order optimality 1.94e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 27, initial cost 4.6721e+01, final cost 3.4719e+00, first-order optimality 5.86e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6762e+01, final cost 3.4716e+00, first-order optimality 2.93e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6742e+01, final cost 3.4706e+00, first-order optimality 2.43e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6791e+01, final cost 3.4702e+00, first-order optimality 4.22e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 33, initial cost 4.6626e+01, final cost 3.4696e+00, first-order optimality 3.59e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6784e+01, final cost 3.4697e+00, first-order optimality 8.80e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6671e+01, final cost 3.4696e+00, first-order optimality 3.75e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.6880e+01, final cost 3.4687e+00, first-order optimality 6.14e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 26, initial cost 4.6679e+01, final cost 3.4683e+00, first-order optimality 2.95e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6736e+01, final cost 3.4678e+00, first-order optimality 7.75e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6723e+01, final cost 3.4671e+00, first-order optimality 5.48e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 29, initial cost 4.6828e+01, final cost 3.4667e+00, first-order optimality 4.79e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 31, initial cost 4.6887e+01, final cost 3.4663e+00, first-order optimality 6.46e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6895e+01, final cost 3.4658e+00, first-order optimality 5.54e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6891e+01, final cost 3.4646e+00, first-order optimality 4.13e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 28, initial cost 4.6549e+01, final cost 3.4609e+00, first-order optimality 6.17e-04.\n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 30, initial cost 4.6560e+01, final cost 3.4572e+00, first-order optimality 1.12e-04.\n",
      "Processed 177 model pair combinations\n",
      "Failed: 0 combinations\n"
     ]
    }
   ],
   "source": [
    "all_runs = {}  # will map model_pair -> dict of outputs\n",
    "failed = []  # keep track of anything that errors out\n",
    "\n",
    "# --- Create model pairs for anchoring -------------------------------------\n",
    "# Get unique models with their estimated capabilities\n",
    "models_with_capability = df_cm_anchor[\n",
    "    [\"model\", \"estimated_capability\"]\n",
    "].drop_duplicates()\n",
    "models_list = models_with_capability.to_dict(\"records\")\n",
    "\n",
    "# Create pairs of models to use as anchors\n",
    "# You can adjust this logic based on your needs\n",
    "model_pairs = []\n",
    "for i in range(len(models_list) - 1):\n",
    "    # Each model paired with the next one\n",
    "    model_pairs.append((models_list[i], models_list[i + 1]))\n",
    "\n",
    "# Alternatively, you could pair each model with a fixed reference model:\n",
    "# reference_model = models_list[0]  # or find a specific model\n",
    "# model_pairs = [(reference_model, model) for model in models_list[1:]]\n",
    "\n",
    "# --- loop over model pairs ------------------------------------------------\n",
    "for model1_info, model2_info in model_pairs:\n",
    "    anchor_model1 = model1_info[\"model\"]\n",
    "    anchor_model1_capability = float(model1_info[\"estimated_capability\"])\n",
    "    anchor_model2 = model2_info[\"model\"]\n",
    "    anchor_model2_capability = float(model2_info[\"estimated_capability\"])\n",
    "\n",
    "    # Create a key for storing results\n",
    "    pair_key = f\"{anchor_model1}_{anchor_model2}\"\n",
    "\n",
    "    try:\n",
    "        df, df_cm, df_db = fit_statistical_model(\n",
    "            scores_df,\n",
    "            anchor_mode=\"model\",\n",
    "            anchor_benchmark=anchor_benchmark,  # Keep the same benchmark\n",
    "            anchor_difficulty=anchor_difficulty,  # Keep the same difficulty\n",
    "            anchor_slope=anchor_slope,  # Keep the same slope\n",
    "            anchor_model1=anchor_model1,\n",
    "            anchor_model1_capability=anchor_model1_capability,\n",
    "            anchor_model2=anchor_model2,\n",
    "            anchor_model2_capability=anchor_model2_capability,\n",
    "        )\n",
    "\n",
    "        all_runs[pair_key] = {\n",
    "            \"df1\": df,\n",
    "            \"df_cm1\": df_cm,\n",
    "            \"df_db\": df_db,\n",
    "            # cache the anchor values for reference\n",
    "            \"anchor_model1\": anchor_model1,\n",
    "            \"anchor_model1_capability\": anchor_model1_capability,\n",
    "            \"anchor_model2\": anchor_model2,\n",
    "            \"anchor_model2_capability\": anchor_model2_capability,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        failed.append((pair_key, str(e)))\n",
    "\n",
    "# --- post-processing (optional) ----------------------------------------------\n",
    "# 1) quick glance at what failed\n",
    "if failed:\n",
    "    print(\"Model pairs that raised errors:\", failed)\n",
    "\n",
    "# 2) pull out the model capability estimates across all runs\n",
    "summary_models = pd.concat(\n",
    "    {k: v[\"df_cm1\"][[\"model\", \"estimated_capability\"]] for k, v in all_runs.items()},\n",
    "    names=[\"anchor_model_pair\"],\n",
    ").reset_index(level=0)\n",
    "\n",
    "# 3) pull out the benchmark difficulty/slope estimates across all runs\n",
    "summary_benchmarks = pd.concat(\n",
    "    {\n",
    "        k: v[\"df_db\"][[\"benchmark_name\", \"estimated_difficulty\", \"estimated_slope\"]]\n",
    "        for k, v in all_runs.items()\n",
    "    },\n",
    "    names=[\"anchor_model_pair\"],\n",
    ").reset_index(level=0)\n",
    "\n",
    "print(f\"Processed {len(all_runs)} model pair combinations\")\n",
    "print(f\"Failed: {len(failed)} combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce8f885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1680x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Capabilities and difficulties over time with std error bars (from variation tables)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Expect these to exist from earlier cells:\n",
    "# - capability_stats: index=model, columns include ['mean','std']\n",
    "# - difficulty_stats: index=benchmark_name, columns include ['mean','std']\n",
    "# - df_cm_anchor: per-model table with 'model' and 'date' (string) or 'date_obj'\n",
    "# - df_db_anchor: per-benchmark table with 'benchmark_name' and 'benchmark_release_date'\n",
    "\n",
    "# Merge stats with model release dates\n",
    "cap_stats_df = capability_stats.reset_index()  # 'model', 'mean', 'std', ...\n",
    "model_dates = df_cm_anchor[[\"model\", \"date\"]].drop_duplicates(subset=[\"model\"]).copy()\n",
    "model_dates[\"date_obj\"] = pd.to_datetime(model_dates[\"date\"], errors=\"coerce\")\n",
    "cap_plot_df = (\n",
    "    cap_stats_df.merge(model_dates, on=\"model\", how=\"left\")\n",
    "    .dropna(subset=[\"date_obj\", \"mean\"])  # require a date and mean\n",
    "    .sort_values(\"date_obj\")\n",
    ")\n",
    "cap_plot_df[\"std\"] = cap_plot_df[\"std\"].fillna(0.0)\n",
    "\n",
    "# Merge stats with benchmark release dates\n",
    "diff_stats_df = difficulty_stats.reset_index()  # 'benchmark_name', 'mean', 'std', ...\n",
    "bench_dates = (\n",
    "    df_db_anchor[[\"benchmark_name\", \"benchmark_release_date\"]]\n",
    "    .drop_duplicates(subset=[\"benchmark_name\"])\n",
    "    .copy()\n",
    ")\n",
    "bench_dates[\"benchmark_release_date\"] = pd.to_datetime(\n",
    "    bench_dates[\"benchmark_release_date\"], errors=\"coerce\"\n",
    ")\n",
    "diff_plot_df = (\n",
    "    diff_stats_df.merge(bench_dates, on=\"benchmark_name\", how=\"left\")\n",
    "    .dropna(subset=[\"benchmark_release_date\", \"mean\"])  # require a date and mean\n",
    "    .sort_values(\"benchmark_release_date\")\n",
    ")\n",
    "diff_plot_df[\"std\"] = diff_plot_df[\"std\"].fillna(0.0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "ax.errorbar(\n",
    "    cap_plot_df[\"date_obj\"],\n",
    "    cap_plot_df[\"mean\"],\n",
    "    yerr=cap_plot_df[\"std\"],\n",
    "    fmt=\"o\",\n",
    "    color=colors[0],\n",
    "    ecolor=colors[0],\n",
    "    markeredgecolor='white',\n",
    "\n",
    "    elinewidth=1,\n",
    "    capsize=3,\n",
    "    alpha=0.9,\n",
    "    label=\"Model capability (mean ± std)\",\n",
    ")\n",
    "\n",
    "ax.errorbar(\n",
    "    diff_plot_df[\"benchmark_release_date\"],\n",
    "    diff_plot_df[\"mean\"],\n",
    "    yerr=diff_plot_df[\"std\"],\n",
    "    fmt=\"o\",\n",
    "    color=colors[1],\n",
    "    ecolor=colors[1],\n",
    "    markeredgecolor='white',\n",
    "    elinewidth=1,\n",
    "    capsize=3,\n",
    "    alpha=0.9,\n",
    "    label=\"Benchmark difficulty (mean ± std)\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Release date\", fontsize=14)\n",
    "ax.set_ylabel(\"Estimated capability / difficulty\", fontsize=14)\n",
    "ax.set_title(\n",
    "    \"AI model capabilities & benchmark difficulties (with std error bars)\", fontsize=18\n",
    ")\n",
    "plt.savefig('outputs/figures/figure-15.svg', format='svg')\n",
    "\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "# fig.autofmt_xdate()\n",
    "\n",
    "ax.grid(True, alpha=0.25, linestyle=\"--\")\n",
    "ax.legend(frameon=True, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"outputs/change_anchor/capabilities_and_benchmarks_over_time.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cedf969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Variation in benchmark difficulties across model anchor pairs ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.445005</td>\n",
       "      <td>0.180947</td>\n",
       "      <td>-0.027472</td>\n",
       "      <td>0.714283</td>\n",
       "      <td>177</td>\n",
       "      <td>0.405467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>-0.209223</td>\n",
       "      <td>0.242468</td>\n",
       "      <td>-0.786074</td>\n",
       "      <td>0.120977</td>\n",
       "      <td>177</td>\n",
       "      <td>-1.155619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>1.993657</td>\n",
       "      <td>0.240381</td>\n",
       "      <td>1.295737</td>\n",
       "      <td>2.215201</td>\n",
       "      <td>177</td>\n",
       "      <td>0.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>1.628521</td>\n",
       "      <td>0.204727</td>\n",
       "      <td>0.995353</td>\n",
       "      <td>1.829792</td>\n",
       "      <td>177</td>\n",
       "      <td>0.125358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>0.096162</td>\n",
       "      <td>0.205572</td>\n",
       "      <td>-0.430775</td>\n",
       "      <td>0.357616</td>\n",
       "      <td>177</td>\n",
       "      <td>2.131733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>2.295393</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>1.542506</td>\n",
       "      <td>2.558723</td>\n",
       "      <td>177</td>\n",
       "      <td>0.121457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>1.668774</td>\n",
       "      <td>0.207797</td>\n",
       "      <td>1.028757</td>\n",
       "      <td>1.869631</td>\n",
       "      <td>177</td>\n",
       "      <td>0.124169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>2.631270</td>\n",
       "      <td>0.298282</td>\n",
       "      <td>1.864480</td>\n",
       "      <td>2.956253</td>\n",
       "      <td>177</td>\n",
       "      <td>0.113040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>2.176087</td>\n",
       "      <td>0.257995</td>\n",
       "      <td>1.453449</td>\n",
       "      <td>2.413957</td>\n",
       "      <td>177</td>\n",
       "      <td>0.118224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>3.001561</td>\n",
       "      <td>0.330927</td>\n",
       "      <td>2.204116</td>\n",
       "      <td>3.463979</td>\n",
       "      <td>177</td>\n",
       "      <td>0.109940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>1.503784</td>\n",
       "      <td>0.195601</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>1.715364</td>\n",
       "      <td>177</td>\n",
       "      <td>0.129705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>2.407025</td>\n",
       "      <td>0.289022</td>\n",
       "      <td>1.641138</td>\n",
       "      <td>2.676831</td>\n",
       "      <td>177</td>\n",
       "      <td>0.119735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>2.827374</td>\n",
       "      <td>0.289404</td>\n",
       "      <td>2.064984</td>\n",
       "      <td>3.098664</td>\n",
       "      <td>177</td>\n",
       "      <td>0.102068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.204647</td>\n",
       "      <td>0.179953</td>\n",
       "      <td>0.654319</td>\n",
       "      <td>1.453682</td>\n",
       "      <td>177</td>\n",
       "      <td>0.148960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>0.149995</td>\n",
       "      <td>0.200620</td>\n",
       "      <td>-0.368815</td>\n",
       "      <td>0.403883</td>\n",
       "      <td>177</td>\n",
       "      <td>1.333725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>3.897315</td>\n",
       "      <td>0.334724</td>\n",
       "      <td>3.134414</td>\n",
       "      <td>4.276645</td>\n",
       "      <td>177</td>\n",
       "      <td>0.085643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.545745</td>\n",
       "      <td>0.208589</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.874199</td>\n",
       "      <td>177</td>\n",
       "      <td>0.381129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>-1.277100</td>\n",
       "      <td>0.413496</td>\n",
       "      <td>-2.025997</td>\n",
       "      <td>-0.680911</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.322861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>-2.251567</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>-3.025930</td>\n",
       "      <td>-1.494260</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.218109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.143295</td>\n",
       "      <td>0.249793</td>\n",
       "      <td>-0.496269</td>\n",
       "      <td>0.517731</td>\n",
       "      <td>177</td>\n",
       "      <td>1.738279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>1.217469</td>\n",
       "      <td>0.180445</td>\n",
       "      <td>0.664201</td>\n",
       "      <td>1.462425</td>\n",
       "      <td>177</td>\n",
       "      <td>0.147794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>1.156976</td>\n",
       "      <td>0.180309</td>\n",
       "      <td>0.614179</td>\n",
       "      <td>1.413477</td>\n",
       "      <td>177</td>\n",
       "      <td>0.155404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>-0.085145</td>\n",
       "      <td>0.226228</td>\n",
       "      <td>-0.642320</td>\n",
       "      <td>0.215933</td>\n",
       "      <td>177</td>\n",
       "      <td>-2.649470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>4.025603</td>\n",
       "      <td>0.315523</td>\n",
       "      <td>3.307925</td>\n",
       "      <td>4.491442</td>\n",
       "      <td>177</td>\n",
       "      <td>0.078157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>1.840724</td>\n",
       "      <td>0.217014</td>\n",
       "      <td>1.183493</td>\n",
       "      <td>2.050757</td>\n",
       "      <td>177</td>\n",
       "      <td>0.117563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>1.649578</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>1.011869</td>\n",
       "      <td>1.850658</td>\n",
       "      <td>177</td>\n",
       "      <td>0.125079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>-0.315448</td>\n",
       "      <td>0.257197</td>\n",
       "      <td>-0.909346</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.813031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>-3.105049</td>\n",
       "      <td>0.690428</td>\n",
       "      <td>-4.072888</td>\n",
       "      <td>-2.045212</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.221728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>1.845435</td>\n",
       "      <td>0.223956</td>\n",
       "      <td>1.174546</td>\n",
       "      <td>2.056258</td>\n",
       "      <td>177</td>\n",
       "      <td>0.121014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>-0.041804</td>\n",
       "      <td>0.219852</td>\n",
       "      <td>-0.590087</td>\n",
       "      <td>0.246994</td>\n",
       "      <td>177</td>\n",
       "      <td>-5.244205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>2.007374</td>\n",
       "      <td>0.242579</td>\n",
       "      <td>1.306390</td>\n",
       "      <td>2.230985</td>\n",
       "      <td>177</td>\n",
       "      <td>0.120502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>2.509768</td>\n",
       "      <td>0.300901</td>\n",
       "      <td>1.731226</td>\n",
       "      <td>2.815842</td>\n",
       "      <td>177</td>\n",
       "      <td>0.119553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>1.983950</td>\n",
       "      <td>0.235249</td>\n",
       "      <td>1.295285</td>\n",
       "      <td>2.207785</td>\n",
       "      <td>177</td>\n",
       "      <td>0.118240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>-2.357450</td>\n",
       "      <td>0.565293</td>\n",
       "      <td>-3.221244</td>\n",
       "      <td>-1.500894</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.239112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>2.125309</td>\n",
       "      <td>0.258364</td>\n",
       "      <td>1.401340</td>\n",
       "      <td>2.364203</td>\n",
       "      <td>177</td>\n",
       "      <td>0.121222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>-1.175402</td>\n",
       "      <td>0.166353</td>\n",
       "      <td>-1.586154</td>\n",
       "      <td>-0.899407</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.141128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>2.000462</td>\n",
       "      <td>0.242446</td>\n",
       "      <td>1.299639</td>\n",
       "      <td>2.224393</td>\n",
       "      <td>177</td>\n",
       "      <td>0.120852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>-1.395620</td>\n",
       "      <td>0.436247</td>\n",
       "      <td>-2.162377</td>\n",
       "      <td>-0.763811</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.311699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean       std       min  \\\n",
       "benchmark_name                                                         \n",
       "ANLI                                    0.445005  0.180947 -0.027472   \n",
       "ARC AI2                                -0.209223  0.242468 -0.786074   \n",
       "ARC-AGI                                 1.993657  0.240381  1.295737   \n",
       "Aider polyglot                          1.628521  0.204727  0.995353   \n",
       "BBH                                     0.096162  0.205572 -0.430775   \n",
       "Balrog                                  2.295393  0.279582  1.542506   \n",
       "CadEval                                 1.668774  0.207797  1.028757   \n",
       "Cybench                                 2.631270  0.298282  1.864480   \n",
       "DeepResearch Bench                      2.176087  0.257995  1.453449   \n",
       "Factorio learning environment           3.001561  0.330927  2.204116   \n",
       "Fiction.LiveBench                       1.503784  0.195601  0.893229   \n",
       "FrontierMath-2025-02-28-Private         2.407025  0.289022  1.641138   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  2.827374  0.289404  2.064984   \n",
       "GPQA diamond                            1.204647  0.179953  0.654319   \n",
       "GSM8K                                   0.149995  0.200620 -0.368815   \n",
       "GSO-Bench                               3.897315  0.334724  3.134414   \n",
       "GeoBench                                0.545745  0.208589  0.031477   \n",
       "HellaSwag                              -1.277100  0.413496 -2.025997   \n",
       "LAMBADA                                -2.251567  0.492480 -3.025930   \n",
       "Lech Mazur Writing                      0.143295  0.249793 -0.496269   \n",
       "LiveBench                               1.217469  0.180445  0.664201   \n",
       "MATH level 5                            1.156976  0.180309  0.614179   \n",
       "MMLU                                   -0.085145  0.226228 -0.642320   \n",
       "OSUniverse                              4.025603  0.315523  3.307925   \n",
       "OSWorld                                 1.840724  0.217014  1.183493   \n",
       "OTIS Mock AIME 2024-2025                1.649578  0.206912  1.011869   \n",
       "OpenBookQA                             -0.315448  0.257197 -0.909346   \n",
       "PIQA                                   -3.105049  0.690428 -4.072888   \n",
       "SWE-Bench verified                      1.845435  0.223956  1.174546   \n",
       "ScienceQA                              -0.041804  0.219852 -0.590087   \n",
       "SimpleBench                             2.007374  0.242579  1.306390   \n",
       "Terminal Bench                          2.509768  0.300901  1.731226   \n",
       "The Agent Company                       1.983950  0.235249  1.295285   \n",
       "TriviaQA                               -2.357450  0.565293 -3.221244   \n",
       "VPCT                                    2.125309  0.258364  1.401340   \n",
       "VideoMME                               -1.175402  0.166353 -1.586154   \n",
       "WeirdML                                 2.000462  0.242446  1.299639   \n",
       "Winogrande                             -1.395620  0.436247 -2.162377   \n",
       "\n",
       "                                             max  count        cv  \n",
       "benchmark_name                                                     \n",
       "ANLI                                    0.714283    177  0.405467  \n",
       "ARC AI2                                 0.120977    177 -1.155619  \n",
       "ARC-AGI                                 2.215201    177  0.120232  \n",
       "Aider polyglot                          1.829792    177  0.125358  \n",
       "BBH                                     0.357616    177  2.131733  \n",
       "Balrog                                  2.558723    177  0.121457  \n",
       "CadEval                                 1.869631    177  0.124169  \n",
       "Cybench                                 2.956253    177  0.113040  \n",
       "DeepResearch Bench                      2.413957    177  0.118224  \n",
       "Factorio learning environment           3.463979    177  0.109940  \n",
       "Fiction.LiveBench                       1.715364    177  0.129705  \n",
       "FrontierMath-2025-02-28-Private         2.676831    177  0.119735  \n",
       "FrontierMath-Tier-4-2025-07-01-Private  3.098664    177  0.102068  \n",
       "GPQA diamond                            1.453682    177  0.148960  \n",
       "GSM8K                                   0.403883    177  1.333725  \n",
       "GSO-Bench                               4.276645    177  0.085643  \n",
       "GeoBench                                0.874199    177  0.381129  \n",
       "HellaSwag                              -0.680911    177 -0.322861  \n",
       "LAMBADA                                -1.494260    177 -0.218109  \n",
       "Lech Mazur Writing                      0.517731    177  1.738279  \n",
       "LiveBench                               1.462425    177  0.147794  \n",
       "MATH level 5                            1.413477    177  0.155404  \n",
       "MMLU                                    0.215933    177 -2.649470  \n",
       "OSUniverse                              4.491442    177  0.078157  \n",
       "OSWorld                                 2.050757    177  0.117563  \n",
       "OTIS Mock AIME 2024-2025                1.850658    177  0.125079  \n",
       "OpenBookQA                              0.039536    177 -0.813031  \n",
       "PIQA                                   -2.045212    177 -0.221728  \n",
       "SWE-Bench verified                      2.056258    177  0.121014  \n",
       "ScienceQA                               0.246994    177 -5.244205  \n",
       "SimpleBench                             2.230985    177  0.120502  \n",
       "Terminal Bench                          2.815842    177  0.119553  \n",
       "The Agent Company                       2.207785    177  0.118240  \n",
       "TriviaQA                               -1.500894    177 -0.239112  \n",
       "VPCT                                    2.364203    177  0.121222  \n",
       "VideoMME                               -0.899407    177 -0.141128  \n",
       "WeirdML                                 2.224393    177  0.120852  \n",
       "Winogrande                             -0.763811    177 -0.311699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in benchmark slopes across model anchor pairs ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.879456</td>\n",
       "      <td>0.203222</td>\n",
       "      <td>0.711752</td>\n",
       "      <td>1.255343</td>\n",
       "      <td>177</td>\n",
       "      <td>0.230423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC AI2</th>\n",
       "      <td>1.592365</td>\n",
       "      <td>0.374576</td>\n",
       "      <td>1.285759</td>\n",
       "      <td>2.331508</td>\n",
       "      <td>177</td>\n",
       "      <td>0.234567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-AGI</th>\n",
       "      <td>4.082457</td>\n",
       "      <td>0.668173</td>\n",
       "      <td>2.867661</td>\n",
       "      <td>4.902099</td>\n",
       "      <td>177</td>\n",
       "      <td>0.163206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aider polyglot</th>\n",
       "      <td>3.422722</td>\n",
       "      <td>0.580255</td>\n",
       "      <td>2.474801</td>\n",
       "      <td>4.138269</td>\n",
       "      <td>177</td>\n",
       "      <td>0.169051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBH</th>\n",
       "      <td>1.542446</td>\n",
       "      <td>0.360543</td>\n",
       "      <td>1.244027</td>\n",
       "      <td>2.230709</td>\n",
       "      <td>177</td>\n",
       "      <td>0.233086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balrog</th>\n",
       "      <td>1.165845</td>\n",
       "      <td>0.199483</td>\n",
       "      <td>0.852407</td>\n",
       "      <td>1.417430</td>\n",
       "      <td>177</td>\n",
       "      <td>0.170622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CadEval</th>\n",
       "      <td>2.337875</td>\n",
       "      <td>0.397635</td>\n",
       "      <td>1.701708</td>\n",
       "      <td>2.831359</td>\n",
       "      <td>177</td>\n",
       "      <td>0.169603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cybench</th>\n",
       "      <td>1.538184</td>\n",
       "      <td>0.220520</td>\n",
       "      <td>1.184429</td>\n",
       "      <td>1.800599</td>\n",
       "      <td>177</td>\n",
       "      <td>0.142958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepResearch Bench</th>\n",
       "      <td>0.621402</td>\n",
       "      <td>0.090118</td>\n",
       "      <td>0.443588</td>\n",
       "      <td>0.727891</td>\n",
       "      <td>177</td>\n",
       "      <td>0.144614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factorio learning environment</th>\n",
       "      <td>1.008848</td>\n",
       "      <td>0.137584</td>\n",
       "      <td>0.741167</td>\n",
       "      <td>1.170640</td>\n",
       "      <td>177</td>\n",
       "      <td>0.135992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction.LiveBench</th>\n",
       "      <td>2.939876</td>\n",
       "      <td>0.498169</td>\n",
       "      <td>2.139667</td>\n",
       "      <td>3.559272</td>\n",
       "      <td>177</td>\n",
       "      <td>0.168973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-2025-02-28-Private</th>\n",
       "      <td>3.947326</td>\n",
       "      <td>0.612986</td>\n",
       "      <td>2.759025</td>\n",
       "      <td>4.690773</td>\n",
       "      <td>177</td>\n",
       "      <td>0.154852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrontierMath-Tier-4-2025-07-01-Private</th>\n",
       "      <td>3.617946</td>\n",
       "      <td>0.264090</td>\n",
       "      <td>2.968417</td>\n",
       "      <td>3.901303</td>\n",
       "      <td>177</td>\n",
       "      <td>0.072788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPQA diamond</th>\n",
       "      <td>1.893772</td>\n",
       "      <td>0.338594</td>\n",
       "      <td>1.384955</td>\n",
       "      <td>2.332670</td>\n",
       "      <td>177</td>\n",
       "      <td>0.178287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM8K</th>\n",
       "      <td>2.746653</td>\n",
       "      <td>0.650305</td>\n",
       "      <td>2.218079</td>\n",
       "      <td>3.992363</td>\n",
       "      <td>177</td>\n",
       "      <td>0.236093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSO-Bench</th>\n",
       "      <td>1.379997</td>\n",
       "      <td>0.101633</td>\n",
       "      <td>1.155076</td>\n",
       "      <td>1.488636</td>\n",
       "      <td>177</td>\n",
       "      <td>0.073439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeoBench</th>\n",
       "      <td>0.558636</td>\n",
       "      <td>0.096803</td>\n",
       "      <td>0.402180</td>\n",
       "      <td>0.680192</td>\n",
       "      <td>177</td>\n",
       "      <td>0.172795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.880446</td>\n",
       "      <td>0.203929</td>\n",
       "      <td>0.712535</td>\n",
       "      <td>1.290910</td>\n",
       "      <td>177</td>\n",
       "      <td>0.230965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMBADA</th>\n",
       "      <td>0.435964</td>\n",
       "      <td>0.077831</td>\n",
       "      <td>0.375365</td>\n",
       "      <td>0.594484</td>\n",
       "      <td>177</td>\n",
       "      <td>0.178022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lech Mazur Writing</th>\n",
       "      <td>0.830057</td>\n",
       "      <td>0.141687</td>\n",
       "      <td>0.606940</td>\n",
       "      <td>1.007864</td>\n",
       "      <td>177</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LiveBench</th>\n",
       "      <td>1.955680</td>\n",
       "      <td>0.348978</td>\n",
       "      <td>1.434740</td>\n",
       "      <td>2.414281</td>\n",
       "      <td>177</td>\n",
       "      <td>0.177939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATH level 5</th>\n",
       "      <td>4.151868</td>\n",
       "      <td>0.747845</td>\n",
       "      <td>3.050391</td>\n",
       "      <td>5.125691</td>\n",
       "      <td>177</td>\n",
       "      <td>0.179613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMLU</th>\n",
       "      <td>1.358965</td>\n",
       "      <td>0.319037</td>\n",
       "      <td>1.090235</td>\n",
       "      <td>1.961501</td>\n",
       "      <td>177</td>\n",
       "      <td>0.234101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSUniverse</th>\n",
       "      <td>0.748225</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.619063</td>\n",
       "      <td>0.813611</td>\n",
       "      <td>177</td>\n",
       "      <td>0.079492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSWorld</th>\n",
       "      <td>3.584613</td>\n",
       "      <td>0.512299</td>\n",
       "      <td>2.776790</td>\n",
       "      <td>4.208805</td>\n",
       "      <td>177</td>\n",
       "      <td>0.142512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTIS Mock AIME 2024-2025</th>\n",
       "      <td>5.220368</td>\n",
       "      <td>0.904502</td>\n",
       "      <td>3.805288</td>\n",
       "      <td>6.348569</td>\n",
       "      <td>177</td>\n",
       "      <td>0.172774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenBookQA</th>\n",
       "      <td>1.132334</td>\n",
       "      <td>0.269165</td>\n",
       "      <td>0.913824</td>\n",
       "      <td>1.664553</td>\n",
       "      <td>177</td>\n",
       "      <td>0.237035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIQA</th>\n",
       "      <td>0.457429</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.381025</td>\n",
       "      <td>0.646224</td>\n",
       "      <td>177</td>\n",
       "      <td>0.206442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE-Bench verified</th>\n",
       "      <td>1.145962</td>\n",
       "      <td>0.187329</td>\n",
       "      <td>0.814405</td>\n",
       "      <td>1.374243</td>\n",
       "      <td>177</td>\n",
       "      <td>0.163007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScienceQA</th>\n",
       "      <td>1.541982</td>\n",
       "      <td>0.362612</td>\n",
       "      <td>1.242333</td>\n",
       "      <td>2.230473</td>\n",
       "      <td>177</td>\n",
       "      <td>0.234494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimpleBench</th>\n",
       "      <td>1.622019</td>\n",
       "      <td>0.276231</td>\n",
       "      <td>1.165875</td>\n",
       "      <td>1.964021</td>\n",
       "      <td>177</td>\n",
       "      <td>0.169819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terminal Bench</th>\n",
       "      <td>0.977582</td>\n",
       "      <td>0.153870</td>\n",
       "      <td>0.687102</td>\n",
       "      <td>1.163788</td>\n",
       "      <td>177</td>\n",
       "      <td>0.156953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Agent Company</th>\n",
       "      <td>3.096878</td>\n",
       "      <td>0.482356</td>\n",
       "      <td>2.269831</td>\n",
       "      <td>3.687385</td>\n",
       "      <td>177</td>\n",
       "      <td>0.155315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriviaQA</th>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.090385</td>\n",
       "      <td>0.356985</td>\n",
       "      <td>0.602580</td>\n",
       "      <td>177</td>\n",
       "      <td>0.209408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPCT</th>\n",
       "      <td>1.020855</td>\n",
       "      <td>0.176196</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>1.240529</td>\n",
       "      <td>177</td>\n",
       "      <td>0.172108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoMME</th>\n",
       "      <td>0.353101</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.321715</td>\n",
       "      <td>0.419518</td>\n",
       "      <td>177</td>\n",
       "      <td>0.077068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeirdML</th>\n",
       "      <td>1.606031</td>\n",
       "      <td>0.277275</td>\n",
       "      <td>1.159927</td>\n",
       "      <td>1.953926</td>\n",
       "      <td>177</td>\n",
       "      <td>0.172158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.658081</td>\n",
       "      <td>0.154351</td>\n",
       "      <td>0.531708</td>\n",
       "      <td>0.960179</td>\n",
       "      <td>177</td>\n",
       "      <td>0.233884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean       std       min  \\\n",
       "benchmark_name                                                         \n",
       "ANLI                                    0.879456  0.203222  0.711752   \n",
       "ARC AI2                                 1.592365  0.374576  1.285759   \n",
       "ARC-AGI                                 4.082457  0.668173  2.867661   \n",
       "Aider polyglot                          3.422722  0.580255  2.474801   \n",
       "BBH                                     1.542446  0.360543  1.244027   \n",
       "Balrog                                  1.165845  0.199483  0.852407   \n",
       "CadEval                                 2.337875  0.397635  1.701708   \n",
       "Cybench                                 1.538184  0.220520  1.184429   \n",
       "DeepResearch Bench                      0.621402  0.090118  0.443588   \n",
       "Factorio learning environment           1.008848  0.137584  0.741167   \n",
       "Fiction.LiveBench                       2.939876  0.498169  2.139667   \n",
       "FrontierMath-2025-02-28-Private         3.947326  0.612986  2.759025   \n",
       "FrontierMath-Tier-4-2025-07-01-Private  3.617946  0.264090  2.968417   \n",
       "GPQA diamond                            1.893772  0.338594  1.384955   \n",
       "GSM8K                                   2.746653  0.650305  2.218079   \n",
       "GSO-Bench                               1.379997  0.101633  1.155076   \n",
       "GeoBench                                0.558636  0.096803  0.402180   \n",
       "HellaSwag                               0.880446  0.203929  0.712535   \n",
       "LAMBADA                                 0.435964  0.077831  0.375365   \n",
       "Lech Mazur Writing                      0.830057  0.141687  0.606940   \n",
       "LiveBench                               1.955680  0.348978  1.434740   \n",
       "MATH level 5                            4.151868  0.747845  3.050391   \n",
       "MMLU                                    1.358965  0.319037  1.090235   \n",
       "OSUniverse                              0.748225  0.059647  0.619063   \n",
       "OSWorld                                 3.584613  0.512299  2.776790   \n",
       "OTIS Mock AIME 2024-2025                5.220368  0.904502  3.805288   \n",
       "OpenBookQA                              1.132334  0.269165  0.913824   \n",
       "PIQA                                    0.457429  0.094700  0.381025   \n",
       "SWE-Bench verified                      1.145962  0.187329  0.814405   \n",
       "ScienceQA                               1.541982  0.362612  1.242333   \n",
       "SimpleBench                             1.622019  0.276231  1.165875   \n",
       "Terminal Bench                          0.977582  0.153870  0.687102   \n",
       "The Agent Company                       3.096878  0.482356  2.269831   \n",
       "TriviaQA                                0.430400  0.090385  0.356985   \n",
       "VPCT                                    1.020855  0.176196  0.736667   \n",
       "VideoMME                                0.353101  0.027290  0.321715   \n",
       "WeirdML                                 1.606031  0.277275  1.159927   \n",
       "Winogrande                              0.658081  0.154351  0.531708   \n",
       "\n",
       "                                             max  count        cv  \n",
       "benchmark_name                                                     \n",
       "ANLI                                    1.255343    177  0.230423  \n",
       "ARC AI2                                 2.331508    177  0.234567  \n",
       "ARC-AGI                                 4.902099    177  0.163206  \n",
       "Aider polyglot                          4.138269    177  0.169051  \n",
       "BBH                                     2.230709    177  0.233086  \n",
       "Balrog                                  1.417430    177  0.170622  \n",
       "CadEval                                 2.831359    177  0.169603  \n",
       "Cybench                                 1.800599    177  0.142958  \n",
       "DeepResearch Bench                      0.727891    177  0.144614  \n",
       "Factorio learning environment           1.170640    177  0.135992  \n",
       "Fiction.LiveBench                       3.559272    177  0.168973  \n",
       "FrontierMath-2025-02-28-Private         4.690773    177  0.154852  \n",
       "FrontierMath-Tier-4-2025-07-01-Private  3.901303    177  0.072788  \n",
       "GPQA diamond                            2.332670    177  0.178287  \n",
       "GSM8K                                   3.992363    177  0.236093  \n",
       "GSO-Bench                               1.488636    177  0.073439  \n",
       "GeoBench                                0.680192    177  0.172795  \n",
       "HellaSwag                               1.290910    177  0.230965  \n",
       "LAMBADA                                 0.594484    177  0.178022  \n",
       "Lech Mazur Writing                      1.007864    177  0.170213  \n",
       "LiveBench                               2.414281    177  0.177939  \n",
       "MATH level 5                            5.125691    177  0.179613  \n",
       "MMLU                                    1.961501    177  0.234101  \n",
       "OSUniverse                              0.813611    177  0.079492  \n",
       "OSWorld                                 4.208805    177  0.142512  \n",
       "OTIS Mock AIME 2024-2025                6.348569    177  0.172774  \n",
       "OpenBookQA                              1.664553    177  0.237035  \n",
       "PIQA                                    0.646224    177  0.206442  \n",
       "SWE-Bench verified                      1.374243    177  0.163007  \n",
       "ScienceQA                               2.230473    177  0.234494  \n",
       "SimpleBench                             1.964021    177  0.169819  \n",
       "Terminal Bench                          1.163788    177  0.156953  \n",
       "The Agent Company                       3.687385    177  0.155315  \n",
       "TriviaQA                                0.602580    177  0.209408  \n",
       "VPCT                                    1.240529    177  0.172108  \n",
       "VideoMME                                0.419518    177  0.077068  \n",
       "WeirdML                                 1.953926    177  0.172158  \n",
       "Winogrande                              0.960179    177  0.233884  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in model capabilities (all models) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.212023</td>\n",
       "      <td>-0.497349</td>\n",
       "      <td>0.312467</td>\n",
       "      <td>177</td>\n",
       "      <td>5.409241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>-0.286963</td>\n",
       "      <td>0.253613</td>\n",
       "      <td>-0.876870</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.881284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-7B</th>\n",
       "      <td>-0.484209</td>\n",
       "      <td>0.283143</td>\n",
       "      <td>-1.107004</td>\n",
       "      <td>-0.092251</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.583099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.788568</td>\n",
       "      <td>0.331105</td>\n",
       "      <td>-1.459439</td>\n",
       "      <td>-0.322091</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.418694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeQwen1.5-7B</th>\n",
       "      <td>-0.279393</td>\n",
       "      <td>0.252255</td>\n",
       "      <td>-0.867247</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.900316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b</th>\n",
       "      <td>0.156478</td>\n",
       "      <td>0.200260</td>\n",
       "      <td>-0.361150</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>177</td>\n",
       "      <td>1.276179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b</th>\n",
       "      <td>-0.521076</td>\n",
       "      <td>0.288639</td>\n",
       "      <td>-1.149261</td>\n",
       "      <td>-0.120970</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.552361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-7b</th>\n",
       "      <td>-0.331446</td>\n",
       "      <td>0.259741</td>\n",
       "      <td>-0.927926</td>\n",
       "      <td>0.025103</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.781443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.352927</td>\n",
       "      <td>0.262798</td>\n",
       "      <td>-0.953014</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.742520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.471034</td>\n",
       "      <td>0.280382</td>\n",
       "      <td>-1.090519</td>\n",
       "      <td>-0.081835</td>\n",
       "      <td>177</td>\n",
       "      <td>-0.593563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       std       min       max  count        cv\n",
       "model                                                                       \n",
       "Baichuan-2-13B-Base  0.039085  0.212023 -0.497349  0.312467    177  5.409241\n",
       "Baichuan-2-7B-Base  -0.286963  0.253613 -0.876870  0.060078    177 -0.881284\n",
       "Baichuan-7B         -0.484209  0.283143 -1.107004 -0.092251    177 -0.583099\n",
       "Cerebras-GPT-13B    -0.788568  0.331105 -1.459439 -0.322091    177 -0.418694\n",
       "CodeQwen1.5-7B      -0.279393  0.252255 -0.867247  0.065227    177 -0.900316\n",
       "...                       ...       ...       ...       ...    ...       ...\n",
       "starcoder2-15b       0.156478  0.200260 -0.361150  0.409836    177  1.276179\n",
       "starcoder2-3b       -0.521076  0.288639 -1.149261 -0.120970    177 -0.552361\n",
       "starcoder2-7b       -0.331446  0.259741 -0.927926  0.025103    177 -0.781443\n",
       "vicuna-13b-v1.1     -0.352927  0.262798 -0.953014  0.008753    177 -0.742520\n",
       "xgen-7b-8k-base     -0.471034  0.280382 -1.090519 -0.081835    177 -0.593563\n",
       "\n",
       "[178 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Variation in model capabilities (excluding anchored models) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base</th>\n",
       "      <td>0.036313</td>\n",
       "      <td>0.211627</td>\n",
       "      <td>-0.497349</td>\n",
       "      <td>0.312467</td>\n",
       "      <td>175</td>\n",
       "      <td>5.811181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base</th>\n",
       "      <td>-0.289645</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>-0.876870</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.873762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-7B</th>\n",
       "      <td>-0.486841</td>\n",
       "      <td>0.283681</td>\n",
       "      <td>-1.107004</td>\n",
       "      <td>-0.092251</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.581031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B</th>\n",
       "      <td>-0.791106</td>\n",
       "      <td>0.332141</td>\n",
       "      <td>-1.459439</td>\n",
       "      <td>-0.322091</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.418643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeQwen1.5-7B</th>\n",
       "      <td>-0.282070</td>\n",
       "      <td>0.252440</td>\n",
       "      <td>-0.867247</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.892396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b</th>\n",
       "      <td>0.153672</td>\n",
       "      <td>0.199661</td>\n",
       "      <td>-0.361150</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>175</td>\n",
       "      <td>1.295547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b</th>\n",
       "      <td>-0.523689</td>\n",
       "      <td>0.289244</td>\n",
       "      <td>-1.149261</td>\n",
       "      <td>-0.120970</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.550740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-7b</th>\n",
       "      <td>-0.334110</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>-0.927926</td>\n",
       "      <td>0.025103</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.776014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1</th>\n",
       "      <td>-0.355588</td>\n",
       "      <td>0.263109</td>\n",
       "      <td>-0.953014</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.737808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base</th>\n",
       "      <td>-0.473667</td>\n",
       "      <td>0.280893</td>\n",
       "      <td>-1.090519</td>\n",
       "      <td>-0.081835</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.591321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       std       min       max  count        cv\n",
       "model                                                                       \n",
       "Baichuan-2-13B-Base  0.036313  0.211627 -0.497349  0.312467    175  5.811181\n",
       "Baichuan-2-7B-Base  -0.289645  0.253807 -0.876870  0.060078    175 -0.873762\n",
       "Baichuan-7B         -0.486841  0.283681 -1.107004 -0.092251    175 -0.581031\n",
       "Cerebras-GPT-13B    -0.791106  0.332141 -1.459439 -0.322091    175 -0.418643\n",
       "CodeQwen1.5-7B      -0.282070  0.252440 -0.867247  0.065227    175 -0.892396\n",
       "...                       ...       ...       ...       ...    ...       ...\n",
       "starcoder2-15b       0.153672  0.199661 -0.361150  0.409836    175  1.295547\n",
       "starcoder2-3b       -0.523689  0.289244 -1.149261 -0.120970    175 -0.550740\n",
       "starcoder2-7b       -0.334110  0.260018 -0.927926  0.025103    175 -0.776014\n",
       "vicuna-13b-v1.1     -0.355588  0.263109 -0.953014  0.008753    175 -0.737808\n",
       "xgen-7b-8k-base     -0.473667  0.280893 -1.090519 -0.081835    175 -0.591321\n",
       "\n",
       "[178 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model pair stability (lower deviation = more stable) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_difficulty_deviation</th>\n",
       "      <th>mean_capability_deviation</th>\n",
       "      <th>combined_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct</th>\n",
       "      <td>0.092486</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.079060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-32B_Phi-3-small-8k-instruct</th>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.088097</td>\n",
       "      <td>0.084195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM 2-L_Qwen2.5-Coder-7B</th>\n",
       "      <td>0.129693</td>\n",
       "      <td>0.080396</td>\n",
       "      <td>0.089150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon.nova-pro-v1:0_gpt-4-0314</th>\n",
       "      <td>0.084807</td>\n",
       "      <td>0.104302</td>\n",
       "      <td>0.100840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-Coder-14B_Phi-3-mini-4k-instruct</th>\n",
       "      <td>0.107852</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.104931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B-v0.1_Llama-3.1-8B-Instruct</th>\n",
       "      <td>0.097677</td>\n",
       "      <td>0.111821</td>\n",
       "      <td>0.109310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-8B-Instruct_Qwen2.5-Coder-14B</th>\n",
       "      <td>0.101737</td>\n",
       "      <td>0.112891</td>\n",
       "      <td>0.110911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-2.1_gemini-1.0-pro-001</th>\n",
       "      <td>0.101287</td>\n",
       "      <td>0.126695</td>\n",
       "      <td>0.122183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125_StableBeluga2</th>\n",
       "      <td>0.132054</td>\n",
       "      <td>0.122492</td>\n",
       "      <td>0.124190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.0-pro-001_Mixtral-8x7B-v0.1</th>\n",
       "      <td>0.106213</td>\n",
       "      <td>0.129080</td>\n",
       "      <td>0.125019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mean_difficulty_deviation  \\\n",
       "Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct                   0.092486   \n",
       "Qwen2.5-Coder-32B_Phi-3-small-8k-instruct                        0.066124   \n",
       "PaLM 2-L_Qwen2.5-Coder-7B                                        0.129693   \n",
       "amazon.nova-pro-v1:0_gpt-4-0314                                  0.084807   \n",
       "Qwen2.5-Coder-14B_Phi-3-mini-4k-instruct                         0.107852   \n",
       "Mixtral-8x7B-v0.1_Llama-3.1-8B-Instruct                          0.097677   \n",
       "Llama-3.1-8B-Instruct_Qwen2.5-Coder-14B                          0.101737   \n",
       "claude-2.1_gemini-1.0-pro-001                                    0.101287   \n",
       "gpt-3.5-turbo-0125_StableBeluga2                                 0.132054   \n",
       "gemini-1.0-pro-001_Mixtral-8x7B-v0.1                             0.106213   \n",
       "\n",
       "                                                mean_capability_deviation  \\\n",
       "Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct                   0.076161   \n",
       "Qwen2.5-Coder-32B_Phi-3-small-8k-instruct                        0.088097   \n",
       "PaLM 2-L_Qwen2.5-Coder-7B                                        0.080396   \n",
       "amazon.nova-pro-v1:0_gpt-4-0314                                  0.104302   \n",
       "Qwen2.5-Coder-14B_Phi-3-mini-4k-instruct                         0.104300   \n",
       "Mixtral-8x7B-v0.1_Llama-3.1-8B-Instruct                          0.111821   \n",
       "Llama-3.1-8B-Instruct_Qwen2.5-Coder-14B                          0.112891   \n",
       "claude-2.1_gemini-1.0-pro-001                                    0.126695   \n",
       "gpt-3.5-turbo-0125_StableBeluga2                                 0.122492   \n",
       "gemini-1.0-pro-001_Mixtral-8x7B-v0.1                             0.129080   \n",
       "\n",
       "                                                combined_deviation  \n",
       "Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct            0.079060  \n",
       "Qwen2.5-Coder-32B_Phi-3-small-8k-instruct                 0.084195  \n",
       "PaLM 2-L_Qwen2.5-Coder-7B                                 0.089150  \n",
       "amazon.nova-pro-v1:0_gpt-4-0314                           0.100840  \n",
       "Qwen2.5-Coder-14B_Phi-3-mini-4k-instruct                  0.104931  \n",
       "Mixtral-8x7B-v0.1_Llama-3.1-8B-Instruct                   0.109310  \n",
       "Llama-3.1-8B-Instruct_Qwen2.5-Coder-14B                   0.110911  \n",
       "claude-2.1_gemini-1.0-pro-001                             0.122183  \n",
       "gpt-3.5-turbo-0125_StableBeluga2                          0.124190  \n",
       "gemini-1.0-pro-001_Mixtral-8x7B-v0.1                      0.125019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# 1)  DIFFICULTY  ––  variation of each benchmark's difficulty estimate\n",
    "#     across different model anchor pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "difficulty_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]  # difficulty table from that fit\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_difficulty\"]].copy()\n",
    "    out[\"anchor_model_pair\"] = anchor_pair  # remember which model pair this came from\n",
    "    # Also store the individual models for more detailed analysis if needed\n",
    "    out[\"anchor_model1\"] = run[\"anchor_model1\"]\n",
    "    out[\"anchor_model2\"] = run[\"anchor_model2\"]\n",
    "    difficulty_rows.append(out)\n",
    "\n",
    "difficulty_long = pd.concat(difficulty_rows, ignore_index=True)\n",
    "\n",
    "# No need to drop trivial rows since we're not anchoring on benchmarks\n",
    "# All benchmark estimates are free to vary\n",
    "\n",
    "difficulty_stats = (\n",
    "    difficulty_long.groupby(\"benchmark_name\")[\"estimated_difficulty\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        count=\"count\",  # how many model pairs estimated this\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan,\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2)  CAPABILITY  ––  variation of each model's capability estimate\n",
    "#     across different model anchor pairs\n",
    "# ---------------------------------------------------------------------------\n",
    "capability_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_cm = run[\"df_cm1\"]  # capability table from that fit\n",
    "    # Check the actual column name - might be 'model' or 'model_name'\n",
    "    model_col = \"model_name\" if \"model_name\" in df_cm.columns else \"model\"\n",
    "    out = df_cm[[model_col, \"estimated_capability\"]].copy()\n",
    "    out.rename(columns={model_col: \"model\"}, inplace=True)  # standardize column name\n",
    "    out[\"anchor_model_pair\"] = anchor_pair\n",
    "    # Also store the individual anchor models\n",
    "    out[\"anchor_model1\"] = run[\"anchor_model1\"]\n",
    "    out[\"anchor_model2\"] = run[\"anchor_model2\"]\n",
    "    capability_rows.append(out)\n",
    "\n",
    "capability_long = pd.concat(capability_rows, ignore_index=True)\n",
    "\n",
    "# For model capabilities, we might want to exclude rows where the model\n",
    "# was one of the anchors (since those were fixed)\n",
    "capability_long_free = capability_long[\n",
    "    (capability_long[\"model\"] != capability_long[\"anchor_model1\"])\n",
    "    & (capability_long[\"model\"] != capability_long[\"anchor_model2\"])\n",
    "]\n",
    "\n",
    "# Stats for all models (including anchored ones)\n",
    "capability_stats_all = (\n",
    "    capability_long.groupby(\"model\")[\"estimated_capability\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        count=\"count\",\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan,\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Stats for non-anchored models only (more meaningful variation)\n",
    "capability_stats_free = (\n",
    "    capability_long_free.groupby(\"model\")[\"estimated_capability\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        count=\"count\",\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan,\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3)  SLOPE  ––  variation of each benchmark's slope estimate\n",
    "# ---------------------------------------------------------------------------\n",
    "slope_rows = []\n",
    "\n",
    "for anchor_pair, run in all_runs.items():\n",
    "    df_db = run[\"df_db\"]\n",
    "    out = df_db[[\"benchmark_name\", \"estimated_slope\"]].copy()\n",
    "    out[\"anchor_model_pair\"] = anchor_pair\n",
    "    slope_rows.append(out)\n",
    "\n",
    "slope_long = pd.concat(slope_rows, ignore_index=True)\n",
    "\n",
    "slope_stats = (\n",
    "    slope_long.groupby(\"benchmark_name\")[\"estimated_slope\"]\n",
    "    .agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        min=\"min\",\n",
    "        max=\"max\",\n",
    "        count=\"count\",\n",
    "        cv=lambda s: s.std(ddof=0) / s.mean() if s.mean() != 0 else np.nan,\n",
    "    )\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4)  Quick look at results\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"=== Variation in benchmark difficulties across model anchor pairs ===\")\n",
    "display(difficulty_stats)\n",
    "\n",
    "print(\"\\n=== Variation in benchmark slopes across model anchor pairs ===\")\n",
    "display(slope_stats)\n",
    "\n",
    "print(\"\\n=== Variation in model capabilities (all models) ===\")\n",
    "display(capability_stats_all)\n",
    "\n",
    "print(\"\\n=== Variation in model capabilities (excluding anchored models) ===\")\n",
    "display(capability_stats_free)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5)  Additional analysis: which model pairs give most stable estimates?\n",
    "# ---------------------------------------------------------------------------\n",
    "# Calculate overall stability metric for each model pair\n",
    "stability_by_pair = {}\n",
    "\n",
    "for anchor_pair in all_runs.keys():\n",
    "    # Get difficulty variations for this pair\n",
    "    diff_subset = difficulty_long[difficulty_long[\"anchor_model_pair\"] == anchor_pair]\n",
    "    cap_subset = capability_long_free[\n",
    "        capability_long_free[\"anchor_model_pair\"] == anchor_pair\n",
    "    ]\n",
    "\n",
    "    # Calculate average deviation from overall means\n",
    "    diff_devs = []\n",
    "    for bench in diff_subset[\"benchmark_name\"].unique():\n",
    "        estimate = diff_subset[diff_subset[\"benchmark_name\"] == bench][\n",
    "            \"estimated_difficulty\"\n",
    "        ].iloc[0]\n",
    "        overall_mean = difficulty_stats.loc[bench, \"mean\"]\n",
    "        diff_devs.append(abs(estimate - overall_mean))\n",
    "\n",
    "    cap_devs = []\n",
    "    for model in cap_subset[\"model\"].unique():\n",
    "        if model in capability_stats_free.index:\n",
    "            estimate = cap_subset[cap_subset[\"model\"] == model][\n",
    "                \"estimated_capability\"\n",
    "            ].iloc[0]\n",
    "            overall_mean = capability_stats_free.loc[model, \"mean\"]\n",
    "            cap_devs.append(abs(estimate - overall_mean))\n",
    "\n",
    "    stability_by_pair[anchor_pair] = {\n",
    "        \"mean_difficulty_deviation\": np.mean(diff_devs) if diff_devs else np.nan,\n",
    "        \"mean_capability_deviation\": np.mean(cap_devs) if cap_devs else np.nan,\n",
    "        \"combined_deviation\": (\n",
    "            np.mean(diff_devs + cap_devs) if (diff_devs or cap_devs) else np.nan\n",
    "        ),\n",
    "    }\n",
    "\n",
    "stability_df = pd.DataFrame(stability_by_pair).T.sort_values(\"combined_deviation\")\n",
    "\n",
    "print(\"\\n=== Model pair stability (lower deviation = more stable) ===\")\n",
    "display(stability_df.head(10))  # Show top 10 most stable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f156dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spearman across anchor model pairs (benchmark difficulties) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor</th>\n",
       "      <th>Baichuan-2-13B-Base_Llama-2-13b</th>\n",
       "      <th>Baichuan-2-7B-Base_starcoder2-7b</th>\n",
       "      <th>Baichuan-7B_deepseek-coder-6.7b-base</th>\n",
       "      <th>Cerebras-GPT-13B_deepseek-coder-1.3b-base</th>\n",
       "      <th>CodeQwen1.5-7B_Baichuan-2-7B-Base</th>\n",
       "      <th>DeepSeek-Coder-V2-Lite-Base_gemma-7b</th>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-1-20250805_16K</th>\n",
       "      <th>DeepSeek-R1-Distill-Llama-70B_claude-sonnet-4-20250514</th>\n",
       "      <th>DeepSeek-R1_claude-3-7-sonnet-20250219_16K</th>\n",
       "      <th>DeepSeek-V2_gpt-4o-mini-2024-07-18</th>\n",
       "      <th>...</th>\n",
       "      <th>qwen-max-2025-01-25_DeepSeek-V3</th>\n",
       "      <th>qwen2-72b-instruct_Llama-3.1-70B-Instruct</th>\n",
       "      <th>qwen2.5-72b-instruct_gpt-4o-2024-08-06</th>\n",
       "      <th>qwen3-235b-a22b_mistral-medium-2505</th>\n",
       "      <th>qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06</th>\n",
       "      <th>starcoder2-15b_Nemotron-4 15B</th>\n",
       "      <th>starcoder2-3b_phi-1_5</th>\n",
       "      <th>starcoder2-7b_vicuna-13b-v1.1</th>\n",
       "      <th>vicuna-13b-v1.1_LLaMA-7B</th>\n",
       "      <th>xgen-7b-8k-base_Baichuan-7B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base_Llama-2-13b</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.997593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base_starcoder2-7b</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-7B_deepseek-coder-6.7b-base</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B_deepseek-coder-1.3b-base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.997593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeQwen1.5-7B_Baichuan-2-7B-Base</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b_Nemotron-4 15B</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.997593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b_phi-1_5</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-7b_vicuna-13b-v1.1</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1_LLaMA-7B</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base_Baichuan-7B</th>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor                                     Baichuan-2-13B-Base_Llama-2-13b  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                   1.000000   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                  0.999781   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                              0.999781   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                         1.000000   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                 0.999781   \n",
       "...                                                                    ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                     1.000000   \n",
       "starcoder2-3b_phi-1_5                                             0.999781   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                     0.999781   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                          0.999781   \n",
       "xgen-7b-8k-base_Baichuan-7B                                       0.999781   \n",
       "\n",
       "anchor                                     Baichuan-2-7B-Base_starcoder2-7b  \\\n",
       "anchor                                                                        \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                    0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                   1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                               1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                          0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                  1.000000   \n",
       "...                                                                     ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                      0.999781   \n",
       "starcoder2-3b_phi-1_5                                              1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                      1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                           1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                        1.000000   \n",
       "\n",
       "anchor                                     Baichuan-7B_deepseek-coder-6.7b-base  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                        0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                       1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                   1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                              0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                      1.000000   \n",
       "...                                                                         ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                          0.999781   \n",
       "starcoder2-3b_phi-1_5                                                  1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                          1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                               1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                            1.000000   \n",
       "\n",
       "anchor                                     Cerebras-GPT-13B_deepseek-coder-1.3b-base  \\\n",
       "anchor                                                                                 \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                             1.000000   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                            0.999781   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                        0.999781   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                   1.000000   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                           0.999781   \n",
       "...                                                                              ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                               1.000000   \n",
       "starcoder2-3b_phi-1_5                                                       0.999781   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                               0.999781   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                    0.999781   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                 0.999781   \n",
       "\n",
       "anchor                                     CodeQwen1.5-7B_Baichuan-2-7B-Base  \\\n",
       "anchor                                                                         \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                     0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                    1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                           0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                   1.000000   \n",
       "...                                                                      ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                       0.999781   \n",
       "starcoder2-3b_phi-1_5                                               1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                       1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                            1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                         1.000000   \n",
       "\n",
       "anchor                                     DeepSeek-Coder-V2-Lite-Base_gemma-7b  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                        1.000000   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                       0.999781   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                   0.999781   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                              1.000000   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                      0.999781   \n",
       "...                                                                         ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                          1.000000   \n",
       "starcoder2-3b_phi-1_5                                                  0.999781   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                          0.999781   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                               0.999781   \n",
       "xgen-7b-8k-base_Baichuan-7B                                            0.999781   \n",
       "\n",
       "anchor                                     DeepSeek-R1-0528_claude-opus-4-1-20250805_16K  \\\n",
       "anchor                                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                 0.998906   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                0.998687   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                            0.998687   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                       0.998906   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                               0.998687   \n",
       "...                                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                   0.998906   \n",
       "starcoder2-3b_phi-1_5                                                           0.998687   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                   0.998687   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                        0.998687   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                     0.998687   \n",
       "\n",
       "anchor                                     DeepSeek-R1-Distill-Llama-70B_claude-sonnet-4-20250514  \\\n",
       "anchor                                                                                              \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                     0.998468        \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                    0.998249        \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                                0.998249        \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                           0.998468        \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                                   0.998249        \n",
       "...                                                                                      ...        \n",
       "starcoder2-15b_Nemotron-4 15B                                                       0.998468        \n",
       "starcoder2-3b_phi-1_5                                                               0.998249        \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                       0.998249        \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                            0.998249        \n",
       "xgen-7b-8k-base_Baichuan-7B                                                         0.998249        \n",
       "\n",
       "anchor                                     DeepSeek-R1_claude-3-7-sonnet-20250219_16K  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                              0.998906   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                             0.998687   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                         0.998687   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                    0.998906   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                            0.998687   \n",
       "...                                                                               ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                0.998906   \n",
       "starcoder2-3b_phi-1_5                                                        0.998687   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                0.998687   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                     0.998687   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                  0.998687   \n",
       "\n",
       "anchor                                     DeepSeek-V2_gpt-4o-mini-2024-07-18  \\\n",
       "anchor                                                                          \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                      0.998468   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                     0.998249   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                 0.998249   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                            0.998468   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                    0.998249   \n",
       "...                                                                       ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                        0.998468   \n",
       "starcoder2-3b_phi-1_5                                                0.998249   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                        0.998249   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                             0.998249   \n",
       "xgen-7b-8k-base_Baichuan-7B                                          0.998249   \n",
       "\n",
       "anchor                                     ...  \\\n",
       "anchor                                     ...   \n",
       "Baichuan-2-13B-Base_Llama-2-13b            ...   \n",
       "Baichuan-2-7B-Base_starcoder2-7b           ...   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base       ...   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base  ...   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base          ...   \n",
       "...                                        ...   \n",
       "starcoder2-15b_Nemotron-4 15B              ...   \n",
       "starcoder2-3b_phi-1_5                      ...   \n",
       "starcoder2-7b_vicuna-13b-v1.1              ...   \n",
       "vicuna-13b-v1.1_LLaMA-7B                   ...   \n",
       "xgen-7b-8k-base_Baichuan-7B                ...   \n",
       "\n",
       "anchor                                     qwen-max-2025-01-25_DeepSeek-V3  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                   0.998468   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                  0.998249   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                              0.998249   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                         0.998468   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                 0.998249   \n",
       "...                                                                    ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                     0.998468   \n",
       "starcoder2-3b_phi-1_5                                             0.998249   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                     0.998249   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                          0.998249   \n",
       "xgen-7b-8k-base_Baichuan-7B                                       0.998249   \n",
       "\n",
       "anchor                                     qwen2-72b-instruct_Llama-3.1-70B-Instruct  \\\n",
       "anchor                                                                                 \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                             0.998687   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                            0.998468   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                        0.998468   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                   0.998687   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                           0.998468   \n",
       "...                                                                              ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                               0.998687   \n",
       "starcoder2-3b_phi-1_5                                                       0.998468   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                               0.998468   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                    0.998468   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                 0.998468   \n",
       "\n",
       "anchor                                     qwen2.5-72b-instruct_gpt-4o-2024-08-06  \\\n",
       "anchor                                                                              \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                          0.998468   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                         0.998249   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                     0.998249   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                0.998468   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                        0.998249   \n",
       "...                                                                           ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                            0.998468   \n",
       "starcoder2-3b_phi-1_5                                                    0.998249   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                            0.998249   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                 0.998249   \n",
       "xgen-7b-8k-base_Baichuan-7B                                              0.998249   \n",
       "\n",
       "anchor                                     qwen3-235b-a22b_mistral-medium-2505  \\\n",
       "anchor                                                                           \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                       0.998468   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                      0.998249   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                  0.998249   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                             0.998468   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                     0.998249   \n",
       "...                                                                        ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                         0.998468   \n",
       "starcoder2-3b_phi-1_5                                                 0.998249   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                         0.998249   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                              0.998249   \n",
       "xgen-7b-8k-base_Baichuan-7B                                           0.998249   \n",
       "\n",
       "anchor                                     qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06  \\\n",
       "anchor                                                                                         \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                     0.997593   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                    0.998249   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                                0.998249   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                           0.997593   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                                   0.998249   \n",
       "...                                                                                      ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                       0.997593   \n",
       "starcoder2-3b_phi-1_5                                                               0.998249   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                       0.998249   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                            0.998249   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                         0.998249   \n",
       "\n",
       "anchor                                     starcoder2-15b_Nemotron-4 15B  \\\n",
       "anchor                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                 1.000000   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                0.999781   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                            0.999781   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                       1.000000   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                               0.999781   \n",
       "...                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                   1.000000   \n",
       "starcoder2-3b_phi-1_5                                           0.999781   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                   0.999781   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                        0.999781   \n",
       "xgen-7b-8k-base_Baichuan-7B                                     0.999781   \n",
       "\n",
       "anchor                                     starcoder2-3b_phi-1_5  \\\n",
       "anchor                                                             \n",
       "Baichuan-2-13B-Base_Llama-2-13b                         0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                        1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                    1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base               0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                       1.000000   \n",
       "...                                                          ...   \n",
       "starcoder2-15b_Nemotron-4 15B                           0.999781   \n",
       "starcoder2-3b_phi-1_5                                   1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                           1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                             1.000000   \n",
       "\n",
       "anchor                                     starcoder2-7b_vicuna-13b-v1.1  \\\n",
       "anchor                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                 0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                            1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                       0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                               1.000000   \n",
       "...                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                   0.999781   \n",
       "starcoder2-3b_phi-1_5                                           1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                   1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                        1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                     1.000000   \n",
       "\n",
       "anchor                                     vicuna-13b-v1.1_LLaMA-7B  \\\n",
       "anchor                                                                \n",
       "Baichuan-2-13B-Base_Llama-2-13b                            0.999781   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                           1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                       1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                  0.999781   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                          1.000000   \n",
       "...                                                             ...   \n",
       "starcoder2-15b_Nemotron-4 15B                              0.999781   \n",
       "starcoder2-3b_phi-1_5                                      1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                              1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                   1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                1.000000   \n",
       "\n",
       "anchor                                     xgen-7b-8k-base_Baichuan-7B  \n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_Llama-2-13b                               0.999781  \n",
       "Baichuan-2-7B-Base_starcoder2-7b                              1.000000  \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                          1.000000  \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                     0.999781  \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                             1.000000  \n",
       "...                                                                ...  \n",
       "starcoder2-15b_Nemotron-4 15B                                 0.999781  \n",
       "starcoder2-3b_phi-1_5                                         1.000000  \n",
       "starcoder2-7b_vicuna-13b-v1.1                                 1.000000  \n",
       "vicuna-13b-v1.1_LLaMA-7B                                      1.000000  \n",
       "xgen-7b-8k-base_Baichuan-7B                                   1.000000  \n",
       "\n",
       "[177 rows x 177 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per model-pair fit (difficulties):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-5-mini-2025-08-07_medium_gpt-5-nano-2025-08-07_high</th>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-pro-preview-03-25_o1-2024-12-17_medium</th>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash-preview-04-17_claude-opus-4-1-20250805</th>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-nano-2025-08-07_high_gemini-2.5-pro-preview-03-25</th>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-nano-2025-08-07_medium_claude-3-7-sonnet-20250219_32K</th>\n",
       "      <td>0.999448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpt-30b_CodeQwen1.5-7B</th>\n",
       "      <td>0.998694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-13B_chatglm2-6b</th>\n",
       "      <td>0.998694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm2-6b_deepseek-coder-33b-base</th>\n",
       "      <td>0.998694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen-1_8B_Qwen2.5-Coder-0.5B</th>\n",
       "      <td>0.998694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06</th>\n",
       "      <td>0.998262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rho\n",
       "anchor                                                      \n",
       "gpt-5-mini-2025-08-07_medium_gpt-5-nano-2025-08...  0.999448\n",
       "gemini-2.5-pro-preview-03-25_o1-2024-12-17_medium   0.999448\n",
       "gemini-2.5-flash-preview-04-17_claude-opus-4-1-...  0.999448\n",
       "gpt-5-nano-2025-08-07_high_gemini-2.5-pro-previ...  0.999448\n",
       "gpt-5-nano-2025-08-07_medium_claude-3-7-sonnet-...  0.999448\n",
       "...                                                      ...\n",
       "mpt-30b_CodeQwen1.5-7B                              0.998694\n",
       "LLaMA-13B_chatglm2-6b                               0.998694\n",
       "chatglm2-6b_deepseek-coder-33b-base                 0.998694\n",
       "Qwen-1_8B_Qwen2.5-Coder-0.5B                        0.998694\n",
       "qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06   0.998262\n",
       "\n",
       "[177 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spearman across anchor model pairs (model capabilities) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>anchor</th>\n",
       "      <th>Baichuan-2-13B-Base_Llama-2-13b</th>\n",
       "      <th>Baichuan-2-7B-Base_starcoder2-7b</th>\n",
       "      <th>Baichuan-7B_deepseek-coder-6.7b-base</th>\n",
       "      <th>Cerebras-GPT-13B_deepseek-coder-1.3b-base</th>\n",
       "      <th>CodeQwen1.5-7B_Baichuan-2-7B-Base</th>\n",
       "      <th>DeepSeek-Coder-V2-Lite-Base_gemma-7b</th>\n",
       "      <th>DeepSeek-R1-0528_claude-opus-4-1-20250805_16K</th>\n",
       "      <th>DeepSeek-R1-Distill-Llama-70B_claude-sonnet-4-20250514</th>\n",
       "      <th>DeepSeek-R1_claude-3-7-sonnet-20250219_16K</th>\n",
       "      <th>DeepSeek-V2_gpt-4o-mini-2024-07-18</th>\n",
       "      <th>...</th>\n",
       "      <th>qwen-max-2025-01-25_DeepSeek-V3</th>\n",
       "      <th>qwen2-72b-instruct_Llama-3.1-70B-Instruct</th>\n",
       "      <th>qwen2.5-72b-instruct_gpt-4o-2024-08-06</th>\n",
       "      <th>qwen3-235b-a22b_mistral-medium-2505</th>\n",
       "      <th>qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06</th>\n",
       "      <th>starcoder2-15b_Nemotron-4 15B</th>\n",
       "      <th>starcoder2-3b_phi-1_5</th>\n",
       "      <th>starcoder2-7b_vicuna-13b-v1.1</th>\n",
       "      <th>vicuna-13b-v1.1_LLaMA-7B</th>\n",
       "      <th>xgen-7b-8k-base_Baichuan-7B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-13B-Base_Llama-2-13b</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-2-7B-Base_starcoder2-7b</th>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan-7B_deepseek-coder-6.7b-base</th>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cerebras-GPT-13B_deepseek-coder-1.3b-base</th>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeQwen1.5-7B_Baichuan-2-7B-Base</th>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-15b_Nemotron-4 15B</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-3b_phi-1_5</th>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starcoder2-7b_vicuna-13b-v1.1</th>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicuna-13b-v1.1_LLaMA-7B</th>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgen-7b-8k-base_Baichuan-7B</th>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "anchor                                     Baichuan-2-13B-Base_Llama-2-13b  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                   1.000000   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                  0.999962   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                              0.999932   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                         0.999960   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                 0.999955   \n",
       "...                                                                    ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                     0.999981   \n",
       "starcoder2-3b_phi-1_5                                             0.999947   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                     0.999979   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                          0.999966   \n",
       "xgen-7b-8k-base_Baichuan-7B                                       0.999928   \n",
       "\n",
       "anchor                                     Baichuan-2-7B-Base_starcoder2-7b  \\\n",
       "anchor                                                                        \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                    0.999962   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                   1.000000   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                               0.999930   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                          0.999957   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                  0.999977   \n",
       "...                                                                     ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                      0.999945   \n",
       "starcoder2-3b_phi-1_5                                              0.999949   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                      0.999966   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                           0.999964   \n",
       "xgen-7b-8k-base_Baichuan-7B                                        0.999930   \n",
       "\n",
       "anchor                                     Baichuan-7B_deepseek-coder-6.7b-base  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                        0.999932   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                       0.999930   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                   1.000000   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                              0.999957   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                      0.999915   \n",
       "...                                                                         ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                          0.999915   \n",
       "starcoder2-3b_phi-1_5                                                  0.999940   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                          0.999951   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                               0.999957   \n",
       "xgen-7b-8k-base_Baichuan-7B                                            0.999947   \n",
       "\n",
       "anchor                                     Cerebras-GPT-13B_deepseek-coder-1.3b-base  \\\n",
       "anchor                                                                                 \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                             0.999960   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                            0.999957   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                        0.999957   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                   1.000000   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                           0.999940   \n",
       "...                                                                              ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                               0.999943   \n",
       "starcoder2-3b_phi-1_5                                                       0.999983   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                               0.999979   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                    0.999987   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                 0.999964   \n",
       "\n",
       "anchor                                     CodeQwen1.5-7B_Baichuan-2-7B-Base  \\\n",
       "anchor                                                                         \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                     0.999955   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                    0.999977   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                0.999915   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                           0.999940   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                   1.000000   \n",
       "...                                                                      ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                       0.999938   \n",
       "starcoder2-3b_phi-1_5                                               0.999932   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                       0.999955   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                            0.999949   \n",
       "xgen-7b-8k-base_Baichuan-7B                                         0.999913   \n",
       "\n",
       "anchor                                     DeepSeek-Coder-V2-Lite-Base_gemma-7b  \\\n",
       "anchor                                                                            \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                        0.999968   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                       0.999932   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                   0.999902   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                              0.999934   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                      0.999926   \n",
       "...                                                                         ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                          0.999966   \n",
       "starcoder2-3b_phi-1_5                                                  0.999917   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                          0.999949   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                               0.999936   \n",
       "xgen-7b-8k-base_Baichuan-7B                                            0.999898   \n",
       "\n",
       "anchor                                     DeepSeek-R1-0528_claude-opus-4-1-20250805_16K  \\\n",
       "anchor                                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                 0.999870   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                0.999832   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                            0.999808   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                       0.999843   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                               0.999828   \n",
       "...                                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                   0.999862   \n",
       "starcoder2-3b_phi-1_5                                                           0.999821   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                   0.999847   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                        0.999838   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                     0.999802   \n",
       "\n",
       "anchor                                     DeepSeek-R1-Distill-Llama-70B_claude-sonnet-4-20250514  \\\n",
       "anchor                                                                                              \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                     0.999906        \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                    0.999866        \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                                0.999840        \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                           0.999877        \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                                   0.999862        \n",
       "...                                                                                      ...        \n",
       "starcoder2-15b_Nemotron-4 15B                                                       0.999900        \n",
       "starcoder2-3b_phi-1_5                                                               0.999853        \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                       0.999883        \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                            0.999870        \n",
       "xgen-7b-8k-base_Baichuan-7B                                                         0.999834        \n",
       "\n",
       "anchor                                     DeepSeek-R1_claude-3-7-sonnet-20250219_16K  \\\n",
       "anchor                                                                                  \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                              0.999906   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                             0.999868   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                         0.999840   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                    0.999874   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                            0.999864   \n",
       "...                                                                               ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                0.999900   \n",
       "starcoder2-3b_phi-1_5                                                        0.999853   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                0.999883   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                     0.999870   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                  0.999834   \n",
       "\n",
       "anchor                                     DeepSeek-V2_gpt-4o-mini-2024-07-18  \\\n",
       "anchor                                                                          \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                      0.999838   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                     0.999781   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                 0.999730   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                            0.999760   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                    0.999779   \n",
       "...                                                                       ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                        0.999832   \n",
       "starcoder2-3b_phi-1_5                                                0.999740   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                        0.999798   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                             0.999762   \n",
       "xgen-7b-8k-base_Baichuan-7B                                          0.999721   \n",
       "\n",
       "anchor                                     ...  \\\n",
       "anchor                                     ...   \n",
       "Baichuan-2-13B-Base_Llama-2-13b            ...   \n",
       "Baichuan-2-7B-Base_starcoder2-7b           ...   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base       ...   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base  ...   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base          ...   \n",
       "...                                        ...   \n",
       "starcoder2-15b_Nemotron-4 15B              ...   \n",
       "starcoder2-3b_phi-1_5                      ...   \n",
       "starcoder2-7b_vicuna-13b-v1.1              ...   \n",
       "vicuna-13b-v1.1_LLaMA-7B                   ...   \n",
       "xgen-7b-8k-base_Baichuan-7B                ...   \n",
       "\n",
       "anchor                                     qwen-max-2025-01-25_DeepSeek-V3  \\\n",
       "anchor                                                                       \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                   0.999921   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                  0.999879   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                              0.999845   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                         0.999879   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                 0.999874   \n",
       "...                                                                    ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                     0.999915   \n",
       "starcoder2-3b_phi-1_5                                             0.999857   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                     0.999894   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                          0.999879   \n",
       "xgen-7b-8k-base_Baichuan-7B                                       0.999838   \n",
       "\n",
       "anchor                                     qwen2-72b-instruct_Llama-3.1-70B-Instruct  \\\n",
       "anchor                                                                                 \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                             0.999896   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                            0.999851   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                        0.999815   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                   0.999845   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                           0.999849   \n",
       "...                                                                              ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                               0.999889   \n",
       "starcoder2-3b_phi-1_5                                                       0.999828   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                               0.999868   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                    0.999849   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                 0.999808   \n",
       "\n",
       "anchor                                     qwen2.5-72b-instruct_gpt-4o-2024-08-06  \\\n",
       "anchor                                                                              \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                          0.999915   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                         0.999877   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                     0.999849   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                0.999881   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                        0.999872   \n",
       "...                                                                           ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                            0.999909   \n",
       "starcoder2-3b_phi-1_5                                                    0.999864   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                            0.999894   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                 0.999881   \n",
       "xgen-7b-8k-base_Baichuan-7B                                              0.999845   \n",
       "\n",
       "anchor                                     qwen3-235b-a22b_mistral-medium-2505  \\\n",
       "anchor                                                                           \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                       0.999915   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                      0.999874   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                  0.999845   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                             0.999877   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                     0.999870   \n",
       "...                                                                        ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                         0.999909   \n",
       "starcoder2-3b_phi-1_5                                                 0.999857   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                         0.999889   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                              0.999874   \n",
       "xgen-7b-8k-base_Baichuan-7B                                           0.999838   \n",
       "\n",
       "anchor                                     qwen3-max-2025-09-23_gemini-2.5-pro-preview-05-06  \\\n",
       "anchor                                                                                         \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                                     0.999891   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                                    0.999853   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                                                0.999834   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                                           0.999868   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                                                   0.999851   \n",
       "...                                                                                      ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                                       0.999885   \n",
       "starcoder2-3b_phi-1_5                                                               0.999847   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                                       0.999868   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                                            0.999864   \n",
       "xgen-7b-8k-base_Baichuan-7B                                                         0.999828   \n",
       "\n",
       "anchor                                     starcoder2-15b_Nemotron-4 15B  \\\n",
       "anchor                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                 0.999981   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                0.999945   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                            0.999915   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                       0.999943   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                               0.999938   \n",
       "...                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                   1.000000   \n",
       "starcoder2-3b_phi-1_5                                           0.999930   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                   0.999962   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                        0.999949   \n",
       "xgen-7b-8k-base_Baichuan-7B                                     0.999911   \n",
       "\n",
       "anchor                                     starcoder2-3b_phi-1_5  \\\n",
       "anchor                                                             \n",
       "Baichuan-2-13B-Base_Llama-2-13b                         0.999947   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                        0.999949   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                    0.999940   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base               0.999983   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                       0.999932   \n",
       "...                                                          ...   \n",
       "starcoder2-15b_Nemotron-4 15B                           0.999930   \n",
       "starcoder2-3b_phi-1_5                                   1.000000   \n",
       "starcoder2-7b_vicuna-13b-v1.1                           0.999970   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                0.999979   \n",
       "xgen-7b-8k-base_Baichuan-7B                             0.999943   \n",
       "\n",
       "anchor                                     starcoder2-7b_vicuna-13b-v1.1  \\\n",
       "anchor                                                                     \n",
       "Baichuan-2-13B-Base_Llama-2-13b                                 0.999979   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                                0.999966   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                            0.999951   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                       0.999979   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                               0.999955   \n",
       "...                                                                  ...   \n",
       "starcoder2-15b_Nemotron-4 15B                                   0.999962   \n",
       "starcoder2-3b_phi-1_5                                           0.999970   \n",
       "starcoder2-7b_vicuna-13b-v1.1                                   1.000000   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                        0.999983   \n",
       "xgen-7b-8k-base_Baichuan-7B                                     0.999951   \n",
       "\n",
       "anchor                                     vicuna-13b-v1.1_LLaMA-7B  \\\n",
       "anchor                                                                \n",
       "Baichuan-2-13B-Base_Llama-2-13b                            0.999966   \n",
       "Baichuan-2-7B-Base_starcoder2-7b                           0.999964   \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                       0.999957   \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                  0.999987   \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                          0.999949   \n",
       "...                                                             ...   \n",
       "starcoder2-15b_Nemotron-4 15B                              0.999949   \n",
       "starcoder2-3b_phi-1_5                                      0.999979   \n",
       "starcoder2-7b_vicuna-13b-v1.1                              0.999983   \n",
       "vicuna-13b-v1.1_LLaMA-7B                                   1.000000   \n",
       "xgen-7b-8k-base_Baichuan-7B                                0.999960   \n",
       "\n",
       "anchor                                     xgen-7b-8k-base_Baichuan-7B  \n",
       "anchor                                                                  \n",
       "Baichuan-2-13B-Base_Llama-2-13b                               0.999928  \n",
       "Baichuan-2-7B-Base_starcoder2-7b                              0.999930  \n",
       "Baichuan-7B_deepseek-coder-6.7b-base                          0.999947  \n",
       "Cerebras-GPT-13B_deepseek-coder-1.3b-base                     0.999964  \n",
       "CodeQwen1.5-7B_Baichuan-2-7B-Base                             0.999913  \n",
       "...                                                                ...  \n",
       "starcoder2-15b_Nemotron-4 15B                                 0.999911  \n",
       "starcoder2-3b_phi-1_5                                         0.999943  \n",
       "starcoder2-7b_vicuna-13b-v1.1                                 0.999951  \n",
       "vicuna-13b-v1.1_LLaMA-7B                                      0.999960  \n",
       "xgen-7b-8k-base_Baichuan-7B                                   1.000000  \n",
       "\n",
       "[177 rows x 177 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean off-diagonal Spearman per model-pair fit (capabilities):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rho</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-pro-002_gemma-3-27b-it</th>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma-3-27b-it_gemini-2.0-flash-exp</th>\n",
       "      <td>0.999914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.0-flash-thinking-exp-01-21_o1-mini-2024-09-12_medium</th>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-11-20_gpt-4o-2024-05-13</th>\n",
       "      <td>0.999911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-medium-2505_gpt-4.1-mini-2025-04-14</th>\n",
       "      <td>0.999910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-pro-001_DeepSeek-V2</th>\n",
       "      <td>0.999674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-2.1_gemini-1.0-pro-001</th>\n",
       "      <td>0.999652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM 2-L_Qwen2.5-Coder-7B</th>\n",
       "      <td>0.999631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon.nova-pro-v1:0_gpt-4-0314</th>\n",
       "      <td>0.999586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct</th>\n",
       "      <td>0.999296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rho\n",
       "anchor                                                      \n",
       "gemini-1.5-pro-002_gemma-3-27b-it                   0.999916\n",
       "gemma-3-27b-it_gemini-2.0-flash-exp                 0.999914\n",
       "gemini-2.0-flash-thinking-exp-01-21_o1-mini-202...  0.999913\n",
       "gpt-4o-2024-11-20_gpt-4o-2024-05-13                 0.999911\n",
       "mistral-medium-2505_gpt-4.1-mini-2025-04-14         0.999910\n",
       "...                                                      ...\n",
       "gemini-1.5-pro-001_DeepSeek-V2                      0.999674\n",
       "claude-2.1_gemini-1.0-pro-001                       0.999652\n",
       "PaLM 2-L_Qwen2.5-Coder-7B                           0.999631\n",
       "amazon.nova-pro-v1:0_gpt-4-0314                     0.999586\n",
       "Qwen2.5-72B_Llama-4-Maverick-17B-128E-Instruct      0.999296\n",
       "\n",
       "[177 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Spearman rank correlation across anchor model pairs\n",
    "# - Difficulties (by benchmark)\n",
    "# - Capabilities (by model)\n",
    "# Robust to duplicates and missing values\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def _spearman_corr_from_long(\n",
    "    df_long: pd.DataFrame, index_col: str, columns_col: str, values_col: str\n",
    ") -> pd.DataFrame:\n",
    "    wide = df_long.pivot_table(\n",
    "        index=index_col,\n",
    "        columns=columns_col,\n",
    "        values=values_col,\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    wide = wide.apply(pd.to_numeric, errors=\"coerce\").dropna(axis=0, how=\"all\")\n",
    "    if wide.shape[1] < 2:\n",
    "        return pd.DataFrame()\n",
    "    ranks = wide.rank(axis=0, method=\"average\", na_option=\"keep\")\n",
    "    return ranks.corr(method=\"pearson\", min_periods=2)\n",
    "\n",
    "\n",
    "# --- Difficulties across anchor model pairs ---------------------------------\n",
    "print(\"=== Spearman across anchor model pairs (benchmark difficulties) ===\")\n",
    "spearman_difficulty_pairs = _spearman_corr_from_long(\n",
    "    summary_benchmarks.rename(columns={\"anchor_model_pair\": \"anchor\"}),\n",
    "    index_col=\"benchmark_name\",\n",
    "    columns_col=\"anchor\",\n",
    "    values_col=\"estimated_difficulty\",\n",
    ")\n",
    "if spearman_difficulty_pairs.empty:\n",
    "    print(\n",
    "        \"Not enough comparable fits to compute correlations for difficulties across model pairs.\"\n",
    "    )\n",
    "else:\n",
    "    display(spearman_difficulty_pairs)\n",
    "    mean_rho_difficulty_pairs = (\n",
    "        spearman_difficulty_pairs.apply(lambda s: s.drop(labels=s.name).mean(), axis=0)\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame(\"mean_rho\")\n",
    "    )\n",
    "    print(\"\\nMean off-diagonal Spearman per model-pair fit (difficulties):\")\n",
    "    display(mean_rho_difficulty_pairs)\n",
    "\n",
    "# --- Capabilities across anchor model pairs ---------------------------------\n",
    "print(\"\\n=== Spearman across anchor model pairs (model capabilities) ===\")\n",
    "spearman_capability_pairs = _spearman_corr_from_long(\n",
    "    summary_models.rename(columns={\"anchor_model_pair\": \"anchor\"}),\n",
    "    index_col=\"model\",\n",
    "    columns_col=\"anchor\",\n",
    "    values_col=\"estimated_capability\",\n",
    ")\n",
    "if spearman_capability_pairs.empty:\n",
    "    print(\n",
    "        \"Not enough comparable fits to compute correlations for capabilities across model pairs.\"\n",
    "    )\n",
    "else:\n",
    "    display(spearman_capability_pairs)\n",
    "    mean_rho_capability_pairs = (\n",
    "        spearman_capability_pairs.apply(lambda s: s.drop(labels=s.name).mean(), axis=0)\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame(\"mean_rho\")\n",
    "    )\n",
    "    print(\"\\nMean off-diagonal Spearman per model-pair fit (capabilities):\")\n",
    "    display(mean_rho_capability_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8ab8f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
